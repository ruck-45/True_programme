{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515068ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 456\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5eec4f",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad76c8c",
   "metadata": {},
   "source": [
    "- Gradient Descent is uses to find out the change in loss function wrt all the intercepts and biases\n",
    "- Here we are going to do an ANN for Insurance dataset and then going to try implementing Gradient function From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cde88",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93dadb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/Csv_insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a9c52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "affordibility       0\n",
       "bought_insurance    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No Null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05afdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('bought_insurance',axis = 1),df['bought_insurance'],stratify=df['bought_insurance'], train_size=0.8,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b186b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train2 = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test2 = pd.DataFrame(scaler.transform(X_test),columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129cfc3",
   "metadata": {},
   "source": [
    "# Tensorflow ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60832ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb07586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5000\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 903us/step - loss: 0.6660 - accuracy: 0.5000\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.5000\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.5000\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.5000\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.5000\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 975us/step - loss: 0.6638 - accuracy: 0.5000\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.5000\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6631 - accuracy: 0.5000\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6624 - accuracy: 0.5000\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6621 - accuracy: 0.5000\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5000\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5000\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5000\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5000\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5000\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6596 - accuracy: 0.5000\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5000\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 901us/step - loss: 0.6589 - accuracy: 0.5000\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.5000\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.5455\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5455\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.5455\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.5455\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.5455\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 961us/step - loss: 0.6566 - accuracy: 0.5455\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6562 - accuracy: 0.5455\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.5455\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6556 - accuracy: 0.5455\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5455\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.5455\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.5455\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.5455\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6539 - accuracy: 0.5455\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.5455\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.5455\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.5455\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.5455\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.5455\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.5455\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 777us/step - loss: 0.6516 - accuracy: 0.5455\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.5455\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.5455\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.5455\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6504 - accuracy: 0.5455\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6501 - accuracy: 0.5455\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.5455\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.5455\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.6491 - accuracy: 0.5455\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.5455\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.5455\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 756us/step - loss: 0.6482 - accuracy: 0.5455\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.5455\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6476 - accuracy: 0.5455\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.5455\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6470 - accuracy: 0.5455\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.5455\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.5455\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.5455\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.5455\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.6455 - accuracy: 0.5455\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.6452 - accuracy: 0.5455\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.5455\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 556us/step - loss: 0.6446 - accuracy: 0.5455\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 655us/step - loss: 0.6443 - accuracy: 0.5455\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.5455\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6437 - accuracy: 0.5455\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.5455\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.5455\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.5455\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 762us/step - loss: 0.6425 - accuracy: 0.5455\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.5455\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.5455\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.5455\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6414 - accuracy: 0.5455\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6411 - accuracy: 0.5455\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.5455\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.5455\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6402 - accuracy: 0.5455\n",
      "Epoch 83/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.6399 - accuracy: 0.5455\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.5455\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.5455\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 915us/step - loss: 0.6391 - accuracy: 0.5455\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6388 - accuracy: 0.5455\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.5455\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.5455\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6380 - accuracy: 0.5455\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6377 - accuracy: 0.5455\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.6374 - accuracy: 0.5455\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6372 - accuracy: 0.5455\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6369 - accuracy: 0.5455\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 880us/step - loss: 0.6366 - accuracy: 0.5455\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.5455\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6361 - accuracy: 0.5455\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6358 - accuracy: 0.5455\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.5455\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6353 - accuracy: 0.5455\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.6350 - accuracy: 0.5455\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.5455\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6345 - accuracy: 0.5455\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6342 - accuracy: 0.5455\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 895us/step - loss: 0.6340 - accuracy: 0.5455\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.6337 - accuracy: 0.5455\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 622us/step - loss: 0.6334 - accuracy: 0.5455\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.5455\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6329 - accuracy: 0.5455\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.5455\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.5455\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 586us/step - loss: 0.6321 - accuracy: 0.5455\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 722us/step - loss: 0.6319 - accuracy: 0.5455\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.5455\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6314 - accuracy: 0.5455\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.5455\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6309 - accuracy: 0.5455\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.5455\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.5455\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6301 - accuracy: 0.5455\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.6299 - accuracy: 0.5455\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 862us/step - loss: 0.6296 - accuracy: 0.5455\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.6294 - accuracy: 0.5455\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 777us/step - loss: 0.6291 - accuracy: 0.5455\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.6289 - accuracy: 0.5455\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6286 - accuracy: 0.5455\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6284 - accuracy: 0.5455\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.5455\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6279 - accuracy: 0.5455\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.5455\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.5455\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6271 - accuracy: 0.5455\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6269 - accuracy: 0.5455\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.5455\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.5455\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.5455\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.6259 - accuracy: 0.5455\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 941us/step - loss: 0.6257 - accuracy: 0.5455\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6254 - accuracy: 0.5455\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.5455\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 910us/step - loss: 0.6250 - accuracy: 0.5455\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6247 - accuracy: 0.5455\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.5455\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6242 - accuracy: 0.5455\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6240 - accuracy: 0.5455\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.5455\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6235 - accuracy: 0.5455\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 600us/step - loss: 0.6233 - accuracy: 0.5455\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 910us/step - loss: 0.6231 - accuracy: 0.5455\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6228 - accuracy: 0.5455\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.5455\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.5455\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6221 - accuracy: 0.5455\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 797us/step - loss: 0.6219 - accuracy: 0.5455\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.5455\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.5455\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.5455\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.5455\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.6207 - accuracy: 0.5455\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6205 - accuracy: 0.5455\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 617us/step - loss: 0.6203 - accuracy: 0.5455\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6200 - accuracy: 0.5455\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6198 - accuracy: 0.5455\n",
      "Epoch 164/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.6196 - accuracy: 0.5455\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.5455\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6191 - accuracy: 0.5455\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.6189 - accuracy: 0.5455\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6187 - accuracy: 0.5455\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 889us/step - loss: 0.6184 - accuracy: 0.5455\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.5455\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6180 - accuracy: 0.5455\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.5455\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.5455\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.5455\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.6171 - accuracy: 0.5455\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6169 - accuracy: 0.5455\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.5455\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.5455\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.5455\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 912us/step - loss: 0.6160 - accuracy: 0.5455\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6158 - accuracy: 0.5455\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 919us/step - loss: 0.6155 - accuracy: 0.5455\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.6153 - accuracy: 0.5455\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.5455\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.5455\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6147 - accuracy: 0.5455\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.5455\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6142 - accuracy: 0.5455\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6140 - accuracy: 0.5455\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 742us/step - loss: 0.6138 - accuracy: 0.5455\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6136 - accuracy: 0.5455\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6133 - accuracy: 0.5455\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6131 - accuracy: 0.5455\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 715us/step - loss: 0.6129 - accuracy: 0.5455\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.6127 - accuracy: 0.5455\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.6125 - accuracy: 0.5455\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6123 - accuracy: 0.5455\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.5455\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6118 - accuracy: 0.5455\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6116 - accuracy: 0.5455\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6114 - accuracy: 0.5455\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.5455\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 925us/step - loss: 0.6110 - accuracy: 0.5455\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.5455\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.5455\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6103 - accuracy: 0.5455\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6101 - accuracy: 0.5455\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.5455\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6097 - accuracy: 0.5455\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.5455\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6092 - accuracy: 0.5455\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 945us/step - loss: 0.6090 - accuracy: 0.5455\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.5455\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6086 - accuracy: 0.5455\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 868us/step - loss: 0.6084 - accuracy: 0.5455\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6082 - accuracy: 0.5455\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 901us/step - loss: 0.6080 - accuracy: 0.5455\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 273us/step - loss: 0.6078 - accuracy: 0.5455\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6076 - accuracy: 0.5455\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.5909\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.5909\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.5909\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.5909\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.5909\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.5909\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 759us/step - loss: 0.6061 - accuracy: 0.5909\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6059 - accuracy: 0.5909\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.5909\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.5909\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6053 - accuracy: 0.5909\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6051 - accuracy: 0.5909\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.5909\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.5909\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.5909\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6042 - accuracy: 0.5909\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6040 - accuracy: 0.5909\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6038 - accuracy: 0.5909\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.5909\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6034 - accuracy: 0.5909\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 592us/step - loss: 0.6032 - accuracy: 0.5909\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 685us/step - loss: 0.6030 - accuracy: 0.5909\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.5909\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.5909\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6024 - accuracy: 0.5909\n",
      "Epoch 245/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.5909\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.5909\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.5909\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.5909\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6014 - accuracy: 0.5909\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.5909\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6010 - accuracy: 0.5909\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6008 - accuracy: 0.5909\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.5909\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.5909\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.6002 - accuracy: 0.5909\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.5909\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5998 - accuracy: 0.5909\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5996 - accuracy: 0.5909\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.5909\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5992 - accuracy: 0.5909\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5990 - accuracy: 0.5909\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5988 - accuracy: 0.5909\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5986 - accuracy: 0.5909\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.5909\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.5909\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.5909\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5978 - accuracy: 0.5909\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5976 - accuracy: 0.5909\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5974 - accuracy: 0.5909\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5972 - accuracy: 0.5909\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.5909\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5968 - accuracy: 0.5909\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5966 - accuracy: 0.5909\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5964 - accuracy: 0.5909\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.5909\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.5909\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5958 - accuracy: 0.5909\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.5909\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.5909\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.5909\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.5909\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5948 - accuracy: 0.5909\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5946 - accuracy: 0.5909\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5945 - accuracy: 0.5909\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5943 - accuracy: 0.5909\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5941 - accuracy: 0.5909\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.5909\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.5937 - accuracy: 0.5909\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5935 - accuracy: 0.5909\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5933 - accuracy: 0.5909\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.5909\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.5909\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5927 - accuracy: 0.5909\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.5909\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.5923 - accuracy: 0.5909\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.5909\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5920 - accuracy: 0.5909\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5918 - accuracy: 0.5909\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 648us/step - loss: 0.5916 - accuracy: 0.5909\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.5909\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5912 - accuracy: 0.5909\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5910 - accuracy: 0.5909\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6364\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5906 - accuracy: 0.6364\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6364\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5903 - accuracy: 0.6364\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.6364\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6364\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 448us/step - loss: 0.5897 - accuracy: 0.6364\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6364\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6364\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6364\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5889 - accuracy: 0.6364\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.5888 - accuracy: 0.6364\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.5886 - accuracy: 0.6364\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6364\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6364\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5880 - accuracy: 0.6364\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6364\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5877 - accuracy: 0.6364\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.6364\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6364\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6364\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 578us/step - loss: 0.5869 - accuracy: 0.6364\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5867 - accuracy: 0.6364\n",
      "Epoch 326/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 989us/step - loss: 0.5865 - accuracy: 0.6364\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6364\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5862 - accuracy: 0.6364\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5860 - accuracy: 0.6364\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.6364\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.5856 - accuracy: 0.6364\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6364\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5853 - accuracy: 0.6364\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5851 - accuracy: 0.6364\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6364\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5847 - accuracy: 0.6364\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5845 - accuracy: 0.6364\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5844 - accuracy: 0.6364\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6364\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6364\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6364\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6364\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6364\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6364\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5831 - accuracy: 0.6364\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6364\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6364\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6364\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6364\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5822 - accuracy: 0.6364\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6364\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 843us/step - loss: 0.5819 - accuracy: 0.6364\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6364\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5815 - accuracy: 0.6364\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6364\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6364\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 838us/step - loss: 0.5810 - accuracy: 0.6364\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5808 - accuracy: 0.6364\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6364\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6364\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6364\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6364\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6364\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6364\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6364\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5794 - accuracy: 0.6364\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 894us/step - loss: 0.5792 - accuracy: 0.6364\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5791 - accuracy: 0.6364\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6364\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.5787 - accuracy: 0.6364\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 922us/step - loss: 0.5786 - accuracy: 0.6364\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.6364\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5782 - accuracy: 0.6364\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5780 - accuracy: 0.6364\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6364\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6364\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 819us/step - loss: 0.5775 - accuracy: 0.6364\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5773 - accuracy: 0.6364\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6364\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5770 - accuracy: 0.6364\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5768 - accuracy: 0.6364\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 539us/step - loss: 0.5767 - accuracy: 0.6364\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5765 - accuracy: 0.6364\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 894us/step - loss: 0.5763 - accuracy: 0.6364\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6364\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.6364\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.6364\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 572us/step - loss: 0.5757 - accuracy: 0.6364\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 612us/step - loss: 0.5755 - accuracy: 0.6364\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 771us/step - loss: 0.5753 - accuracy: 0.6364\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5751 - accuracy: 0.6364\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5750 - accuracy: 0.6364\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5748 - accuracy: 0.6364\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5746 - accuracy: 0.6364\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5745 - accuracy: 0.6364\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5743 - accuracy: 0.6364\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5741 - accuracy: 0.6364\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5740 - accuracy: 0.6364\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.5738 - accuracy: 0.6364\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6364\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5735 - accuracy: 0.6364\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 852us/step - loss: 0.5733 - accuracy: 0.6364\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6364\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.5730 - accuracy: 0.6364\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.6364\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5727 - accuracy: 0.6364\n",
      "Epoch 407/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 761us/step - loss: 0.5725 - accuracy: 0.6364\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6364\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5722 - accuracy: 0.6364\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5720 - accuracy: 0.6364\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.6364\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 590us/step - loss: 0.5717 - accuracy: 0.6364\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 940us/step - loss: 0.5715 - accuracy: 0.6364\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 568us/step - loss: 0.5713 - accuracy: 0.6364\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 881us/step - loss: 0.5712 - accuracy: 0.6364\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5710 - accuracy: 0.6364\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5709 - accuracy: 0.6364\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.6364\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 796us/step - loss: 0.5705 - accuracy: 0.6364\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5704 - accuracy: 0.6364\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5702 - accuracy: 0.6364\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.6364\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.6364\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5697 - accuracy: 0.6364\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5696 - accuracy: 0.6364\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.6364\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5692 - accuracy: 0.6364\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 714us/step - loss: 0.5691 - accuracy: 0.6364\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 819us/step - loss: 0.5689 - accuracy: 0.6364\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.5688 - accuracy: 0.6364\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 741us/step - loss: 0.5686 - accuracy: 0.6364\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5685 - accuracy: 0.6364\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.6364\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 881us/step - loss: 0.5681 - accuracy: 0.6364\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.6364\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5678 - accuracy: 0.6364\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5677 - accuracy: 0.6364\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.6364\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 852us/step - loss: 0.5673 - accuracy: 0.6364\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 839us/step - loss: 0.5672 - accuracy: 0.6364\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.6364\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5669 - accuracy: 0.6364\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5667 - accuracy: 0.6364\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.5666 - accuracy: 0.6364\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5664 - accuracy: 0.6364\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 538us/step - loss: 0.5662 - accuracy: 0.6364\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6364\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.6364\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.6364\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.6364\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.5655 - accuracy: 0.6364\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.5653 - accuracy: 0.6364\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 791us/step - loss: 0.5652 - accuracy: 0.6364\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5650 - accuracy: 0.6364\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5649 - accuracy: 0.6364\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.6364\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.5645 - accuracy: 0.6364\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5644 - accuracy: 0.6364\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5642 - accuracy: 0.6364\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6364\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6364\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.6364\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5636 - accuracy: 0.6364\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6364\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.5633 - accuracy: 0.6364\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.6364\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.6364\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.6364\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.6364\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.6364\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.6364\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.6364\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6364\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.6364\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.6364\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5617 - accuracy: 0.6364\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 931us/step - loss: 0.5615 - accuracy: 0.6364\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5614 - accuracy: 0.6364\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 772us/step - loss: 0.5612 - accuracy: 0.6364\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5611 - accuracy: 0.6364\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6364\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6364\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5606 - accuracy: 0.6364\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5605 - accuracy: 0.6364\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.5603 - accuracy: 0.6364\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.6364\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6364\n",
      "Epoch 488/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 775us/step - loss: 0.5599 - accuracy: 0.6364\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5597 - accuracy: 0.6364\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5596 - accuracy: 0.6364\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.6364\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6364\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.6364\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.6364\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5589 - accuracy: 0.6364\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5587 - accuracy: 0.6364\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5586 - accuracy: 0.6364\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5584 - accuracy: 0.6364\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 603us/step - loss: 0.5583 - accuracy: 0.6364\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 727us/step - loss: 0.5581 - accuracy: 0.6364\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.6364\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5578 - accuracy: 0.6364\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.6364\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.6364\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 431us/step - loss: 0.5574 - accuracy: 0.6364\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5573 - accuracy: 0.6364\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5571 - accuracy: 0.6364\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5570 - accuracy: 0.6364\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.6364\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5567 - accuracy: 0.6364\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5565 - accuracy: 0.6364\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5564 - accuracy: 0.6364\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.6364\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.6364\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.5560 - accuracy: 0.6364\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.6364\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 899us/step - loss: 0.5557 - accuracy: 0.6364\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5555 - accuracy: 0.6364\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5554 - accuracy: 0.6364\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.6364\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.6364\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5550 - accuracy: 0.6364\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5548 - accuracy: 0.6364\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 982us/step - loss: 0.5547 - accuracy: 0.6364\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.6364\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5544 - accuracy: 0.6364\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5543 - accuracy: 0.6364\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 942us/step - loss: 0.5541 - accuracy: 0.6364\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.5540 - accuracy: 0.6364\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.6364\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 969us/step - loss: 0.5537 - accuracy: 0.6364\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 748us/step - loss: 0.5536 - accuracy: 0.6364\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5534 - accuracy: 0.6364\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5533 - accuracy: 0.6364\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.6364\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5530 - accuracy: 0.6364\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.5529 - accuracy: 0.6364\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5528 - accuracy: 0.6364\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 930us/step - loss: 0.5526 - accuracy: 0.6364\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 877us/step - loss: 0.5525 - accuracy: 0.6364\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5523 - accuracy: 0.6364\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.6364\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.6364\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5519 - accuracy: 0.6364\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.6364\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.6364\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 782us/step - loss: 0.5515 - accuracy: 0.6364\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 347us/step - loss: 0.5514 - accuracy: 0.6364\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.5512 - accuracy: 0.6364\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 366us/step - loss: 0.5511 - accuracy: 0.6364\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5510 - accuracy: 0.6364\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5508 - accuracy: 0.6364\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.5507 - accuracy: 0.6364\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 220us/step - loss: 0.5506 - accuracy: 0.6364\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 963us/step - loss: 0.5504 - accuracy: 0.6364\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5503 - accuracy: 0.6364\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5502 - accuracy: 0.6364\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.6364\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.6364\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.6364\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.6364\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5495 - accuracy: 0.6364\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.6364\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.6364\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.6364\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.6364\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.5488 - accuracy: 0.6364\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.6364\n",
      "Epoch 569/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.5486 - accuracy: 0.6364\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 444us/step - loss: 0.5484 - accuracy: 0.6364\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.6364\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 892us/step - loss: 0.5482 - accuracy: 0.6364\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5480 - accuracy: 0.6364\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5479 - accuracy: 0.6364\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5478 - accuracy: 0.6364\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.5476 - accuracy: 0.6364\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.6364\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 817us/step - loss: 0.5474 - accuracy: 0.6364\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.6364\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.6364\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.6364\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 316us/step - loss: 0.5469 - accuracy: 0.6364\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 767us/step - loss: 0.5467 - accuracy: 0.6364\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5466 - accuracy: 0.6364\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5465 - accuracy: 0.6364\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.6364\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.6364\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5461 - accuracy: 0.6364\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 903us/step - loss: 0.5459 - accuracy: 0.6364\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 618us/step - loss: 0.5458 - accuracy: 0.6364\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.6364\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.5456 - accuracy: 0.6364\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.5454 - accuracy: 0.6364\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.5453 - accuracy: 0.6364\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 684us/step - loss: 0.5452 - accuracy: 0.6364\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 680us/step - loss: 0.5450 - accuracy: 0.6364\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 929us/step - loss: 0.5449 - accuracy: 0.6364\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5448 - accuracy: 0.6364\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 782us/step - loss: 0.5447 - accuracy: 0.6364\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.6364\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.5444 - accuracy: 0.6364\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.6364\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 688us/step - loss: 0.5442 - accuracy: 0.6364\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5440 - accuracy: 0.6364\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 832us/step - loss: 0.5439 - accuracy: 0.6364\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.6364\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.6364\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.5435 - accuracy: 0.6364\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.6364\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 750us/step - loss: 0.5433 - accuracy: 0.6364\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 706us/step - loss: 0.5431 - accuracy: 0.6364\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 747us/step - loss: 0.5430 - accuracy: 0.6364\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5429 - accuracy: 0.6364\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 533us/step - loss: 0.5428 - accuracy: 0.6364\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 739us/step - loss: 0.5426 - accuracy: 0.6364\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.6364\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 946us/step - loss: 0.5424 - accuracy: 0.6364\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 891us/step - loss: 0.5423 - accuracy: 0.6364\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5421 - accuracy: 0.6364\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 192us/step - loss: 0.5420 - accuracy: 0.6364\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 850us/step - loss: 0.5419 - accuracy: 0.6364\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.6364\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 775us/step - loss: 0.5416 - accuracy: 0.6364\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.5415 - accuracy: 0.6364\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5414 - accuracy: 0.6364\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 906us/step - loss: 0.5413 - accuracy: 0.6364\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.5412 - accuracy: 0.6364\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 351us/step - loss: 0.5410 - accuracy: 0.6364\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 931us/step - loss: 0.5409 - accuracy: 0.6364\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 809us/step - loss: 0.5408 - accuracy: 0.6364\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 880us/step - loss: 0.5407 - accuracy: 0.6364\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 607us/step - loss: 0.5405 - accuracy: 0.6364\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5404 - accuracy: 0.6364\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.6364\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5402 - accuracy: 0.6364\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5401 - accuracy: 0.6364\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 619us/step - loss: 0.5399 - accuracy: 0.6364\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 589us/step - loss: 0.5398 - accuracy: 0.6364\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.5397 - accuracy: 0.6364\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 826us/step - loss: 0.5396 - accuracy: 0.6364\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5394 - accuracy: 0.6364\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 650us/step - loss: 0.5393 - accuracy: 0.6364\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5392 - accuracy: 0.6364\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.5391 - accuracy: 0.6364\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.6364\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.5388 - accuracy: 0.6364\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5387 - accuracy: 0.6364\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5386 - accuracy: 0.6364\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 159us/step - loss: 0.5385 - accuracy: 0.6364\n",
      "Epoch 650/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.5384 - accuracy: 0.6364\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 456us/step - loss: 0.5382 - accuracy: 0.6364\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 899us/step - loss: 0.5381 - accuracy: 0.6364\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5380 - accuracy: 0.7273\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 851us/step - loss: 0.5379 - accuracy: 0.7273\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 591us/step - loss: 0.5378 - accuracy: 0.7273\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7273\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7273\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7273\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7273\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7273\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 741us/step - loss: 0.5371 - accuracy: 0.7273\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.7273\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 612us/step - loss: 0.5368 - accuracy: 0.7273\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 700us/step - loss: 0.5367 - accuracy: 0.7273\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7273\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5365 - accuracy: 0.7273\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 925us/step - loss: 0.5363 - accuracy: 0.7273\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.5362 - accuracy: 0.7273\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 547us/step - loss: 0.5361 - accuracy: 0.7273\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 819us/step - loss: 0.5360 - accuracy: 0.7273\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 634us/step - loss: 0.5359 - accuracy: 0.7273\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5358 - accuracy: 0.7273\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7273\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 682us/step - loss: 0.5355 - accuracy: 0.7273\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 734us/step - loss: 0.5354 - accuracy: 0.7273\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 670us/step - loss: 0.5353 - accuracy: 0.7273\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5352 - accuracy: 0.7273\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7273\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 631us/step - loss: 0.5349 - accuracy: 0.7273\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 345us/step - loss: 0.5348 - accuracy: 0.7273\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 524us/step - loss: 0.5347 - accuracy: 0.7273\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 195us/step - loss: 0.5346 - accuracy: 0.7273\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5345 - accuracy: 0.7273\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 785us/step - loss: 0.5344 - accuracy: 0.7273\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5343 - accuracy: 0.7273\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5341 - accuracy: 0.7273\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 757us/step - loss: 0.5340 - accuracy: 0.7273\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 471us/step - loss: 0.5339 - accuracy: 0.7273\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5338 - accuracy: 0.7273\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 417us/step - loss: 0.5337 - accuracy: 0.7273\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 586us/step - loss: 0.5336 - accuracy: 0.7273\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 474us/step - loss: 0.5335 - accuracy: 0.7273\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 746us/step - loss: 0.5333 - accuracy: 0.7273\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7273\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7273\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 564us/step - loss: 0.5330 - accuracy: 0.7273\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7273\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 910us/step - loss: 0.5328 - accuracy: 0.7273\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5327 - accuracy: 0.7273\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7273\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 436us/step - loss: 0.5324 - accuracy: 0.7273\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7273\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.5322 - accuracy: 0.7273\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5321 - accuracy: 0.7273\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5320 - accuracy: 0.7273\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.5319 - accuracy: 0.7273\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7273\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 907us/step - loss: 0.5316 - accuracy: 0.7273\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5315 - accuracy: 0.7273\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5314 - accuracy: 0.7273\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.5313 - accuracy: 0.7273\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7273\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7273\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7273\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7273\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5308 - accuracy: 0.7273\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5306 - accuracy: 0.7273\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5305 - accuracy: 0.7273\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.5304 - accuracy: 0.7273\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 960us/step - loss: 0.5303 - accuracy: 0.7273\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 623us/step - loss: 0.5302 - accuracy: 0.7273\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7273\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7273\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.5299 - accuracy: 0.7273\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 575us/step - loss: 0.5298 - accuracy: 0.7273\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7273\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7273\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 896us/step - loss: 0.5294 - accuracy: 0.7273\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5293 - accuracy: 0.7273\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 882us/step - loss: 0.5292 - accuracy: 0.7273\n",
      "Epoch 731/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.5291 - accuracy: 0.7273\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7273\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5289 - accuracy: 0.7273\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.5288 - accuracy: 0.7273\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7273\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5286 - accuracy: 0.7273\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 982us/step - loss: 0.5285 - accuracy: 0.7273\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7273\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 698us/step - loss: 0.5282 - accuracy: 0.7273\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 721us/step - loss: 0.5281 - accuracy: 0.7273\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.5280 - accuracy: 0.7273\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 770us/step - loss: 0.5279 - accuracy: 0.7273\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7273\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7273\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 734us/step - loss: 0.5276 - accuracy: 0.7273\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5275 - accuracy: 0.7273\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5274 - accuracy: 0.7273\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5273 - accuracy: 0.7273\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7273\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7273\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 905us/step - loss: 0.5269 - accuracy: 0.7273\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5268 - accuracy: 0.7273\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 909us/step - loss: 0.5267 - accuracy: 0.7273\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 679us/step - loss: 0.5266 - accuracy: 0.7273\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5265 - accuracy: 0.7273\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7273\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7273\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 688us/step - loss: 0.5262 - accuracy: 0.7273\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 380us/step - loss: 0.5261 - accuracy: 0.7273\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.5260 - accuracy: 0.7273\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5259 - accuracy: 0.7273\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5258 - accuracy: 0.7273\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5257 - accuracy: 0.7273\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 750us/step - loss: 0.5256 - accuracy: 0.7273\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.5255 - accuracy: 0.7273\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 673us/step - loss: 0.5254 - accuracy: 0.7727\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5253 - accuracy: 0.7727\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 247us/step - loss: 0.5251 - accuracy: 0.7727\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 802us/step - loss: 0.5250 - accuracy: 0.7727\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 663us/step - loss: 0.5249 - accuracy: 0.7727\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5248 - accuracy: 0.7727\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7727\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7727\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5245 - accuracy: 0.7727\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.5244 - accuracy: 0.7727\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5243 - accuracy: 0.7727\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 699us/step - loss: 0.5242 - accuracy: 0.7727\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5241 - accuracy: 0.7727\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7727\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5239 - accuracy: 0.7727\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5238 - accuracy: 0.7727\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5237 - accuracy: 0.7727\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.5236 - accuracy: 0.7727\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7727\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.5234 - accuracy: 0.7727\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5233 - accuracy: 0.7727\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7727\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5231 - accuracy: 0.7727\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5230 - accuracy: 0.7727\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.5229 - accuracy: 0.7727\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7727\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7727\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 740us/step - loss: 0.5226 - accuracy: 0.7727\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5225 - accuracy: 0.7727\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 314us/step - loss: 0.5224 - accuracy: 0.7727\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7727\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.5222 - accuracy: 0.7727\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 832us/step - loss: 0.5221 - accuracy: 0.7727\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 847us/step - loss: 0.5220 - accuracy: 0.7727\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 718us/step - loss: 0.5219 - accuracy: 0.7727\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7727\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 815us/step - loss: 0.5216 - accuracy: 0.7727\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 714us/step - loss: 0.5215 - accuracy: 0.7727\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.5214 - accuracy: 0.7727\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5213 - accuracy: 0.7727\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7727\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 143us/step - loss: 0.5211 - accuracy: 0.7727\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7727\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.5209 - accuracy: 0.7727\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.5208 - accuracy: 0.7727\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 697us/step - loss: 0.5207 - accuracy: 0.7727\n",
      "Epoch 812/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.5206 - accuracy: 0.8182\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 936us/step - loss: 0.5205 - accuracy: 0.8182\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.5204 - accuracy: 0.8182\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8182\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 906us/step - loss: 0.5202 - accuracy: 0.8182\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5201 - accuracy: 0.8182\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8182\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5199 - accuracy: 0.8182\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 329us/step - loss: 0.5198 - accuracy: 0.8182\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.5197 - accuracy: 0.8182\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 424us/step - loss: 0.5196 - accuracy: 0.8182\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 745us/step - loss: 0.5195 - accuracy: 0.8182\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.8182\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5193 - accuracy: 0.8182\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.5192 - accuracy: 0.8182\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8182\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 674us/step - loss: 0.5191 - accuracy: 0.8182\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5190 - accuracy: 0.8182\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 700us/step - loss: 0.5189 - accuracy: 0.8182\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.8182\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5187 - accuracy: 0.8182\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.8182\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.8182\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 571us/step - loss: 0.5184 - accuracy: 0.8182\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5183 - accuracy: 0.8182\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5182 - accuracy: 0.8182\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 844us/step - loss: 0.5181 - accuracy: 0.8182\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.8182\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.5179 - accuracy: 0.8182\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 607us/step - loss: 0.5178 - accuracy: 0.8182\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8182\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8182\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5175 - accuracy: 0.8182\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.5174 - accuracy: 0.8182\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8182\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5172 - accuracy: 0.8182\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5171 - accuracy: 0.8182\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8182\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 777us/step - loss: 0.5169 - accuracy: 0.8182\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5168 - accuracy: 0.8182\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.8182\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5166 - accuracy: 0.8182\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.8182\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 753us/step - loss: 0.5164 - accuracy: 0.8182\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5163 - accuracy: 0.8182\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5162 - accuracy: 0.8182\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 969us/step - loss: 0.5161 - accuracy: 0.8182\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 355us/step - loss: 0.5160 - accuracy: 0.8182\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5159 - accuracy: 0.8182\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5158 - accuracy: 0.8182\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5158 - accuracy: 0.8182\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 425us/step - loss: 0.5157 - accuracy: 0.8182\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 745us/step - loss: 0.5156 - accuracy: 0.8182\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.5155 - accuracy: 0.8636\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 943us/step - loss: 0.5154 - accuracy: 0.8636\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5153 - accuracy: 0.8636\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5152 - accuracy: 0.8636\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8636\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.8636\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5149 - accuracy: 0.8636\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8636\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5147 - accuracy: 0.8636\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.8636\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 719us/step - loss: 0.5145 - accuracy: 0.8636\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5144 - accuracy: 0.8636\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 901us/step - loss: 0.5143 - accuracy: 0.8636\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5142 - accuracy: 0.8636\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.8636\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 847us/step - loss: 0.5140 - accuracy: 0.8636\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5140 - accuracy: 0.8636\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 752us/step - loss: 0.5139 - accuracy: 0.8636\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5138 - accuracy: 0.8636\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.8636\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8636\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5135 - accuracy: 0.8636\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5134 - accuracy: 0.8636\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 846us/step - loss: 0.5133 - accuracy: 0.8636\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.8636\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 720us/step - loss: 0.5131 - accuracy: 0.8636\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 882us/step - loss: 0.5130 - accuracy: 0.8636\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.5129 - accuracy: 0.8636\n",
      "Epoch 893/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 736us/step - loss: 0.5128 - accuracy: 0.8636\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8636\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 290us/step - loss: 0.5127 - accuracy: 0.8636\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 634us/step - loss: 0.5126 - accuracy: 0.8636\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5125 - accuracy: 0.8636\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 713us/step - loss: 0.5124 - accuracy: 0.8636\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 970us/step - loss: 0.5123 - accuracy: 0.8636\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5122 - accuracy: 0.8636\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5121 - accuracy: 0.8636\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5120 - accuracy: 0.8636\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 155us/step - loss: 0.5119 - accuracy: 0.8636\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8636\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5117 - accuracy: 0.8636\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5116 - accuracy: 0.8636\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.8636\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5115 - accuracy: 0.8636\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 725us/step - loss: 0.5114 - accuracy: 0.8636\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5113 - accuracy: 0.8636\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 812us/step - loss: 0.5112 - accuracy: 0.8636\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 351us/step - loss: 0.5111 - accuracy: 0.8636\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5110 - accuracy: 0.8636\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8636\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5108 - accuracy: 0.8636\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.8636\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5106 - accuracy: 0.8636\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.5105 - accuracy: 0.8636\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 930us/step - loss: 0.5105 - accuracy: 0.8636\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8636\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8636\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8636\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5101 - accuracy: 0.8636\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8636\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.5099 - accuracy: 0.8636\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8636\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8636\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.5096 - accuracy: 0.8636\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5095 - accuracy: 0.8636\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5095 - accuracy: 0.8636\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 943us/step - loss: 0.5094 - accuracy: 0.8636\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.8636\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.5092 - accuracy: 0.8636\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 684us/step - loss: 0.5091 - accuracy: 0.8636\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 698us/step - loss: 0.5090 - accuracy: 0.8636\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5089 - accuracy: 0.8636\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.8636\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 781us/step - loss: 0.5087 - accuracy: 0.8636\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5087 - accuracy: 0.8636\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 889us/step - loss: 0.5086 - accuracy: 0.8636\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8636\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8636\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5083 - accuracy: 0.8636\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.8636\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5081 - accuracy: 0.8636\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.5080 - accuracy: 0.8636\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8636\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.5077 - accuracy: 0.8636\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 977us/step - loss: 0.5076 - accuracy: 0.8636\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 412us/step - loss: 0.5075 - accuracy: 0.8636\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8636\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5073 - accuracy: 0.8636\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8636\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8636\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8636\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5070 - accuracy: 0.8636\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5069 - accuracy: 0.8636\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5068 - accuracy: 0.8636\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 295us/step - loss: 0.5067 - accuracy: 0.8636\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 459us/step - loss: 0.5066 - accuracy: 0.8636\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 929us/step - loss: 0.5065 - accuracy: 0.8636\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5064 - accuracy: 0.8636\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8636\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 927us/step - loss: 0.5063 - accuracy: 0.8636\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5062 - accuracy: 0.8636\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5061 - accuracy: 0.8636\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5060 - accuracy: 0.8636\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5059 - accuracy: 0.8636\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5058 - accuracy: 0.8636\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 814us/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 974/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.5056 - accuracy: 0.8636\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 124us/step - loss: 0.5055 - accuracy: 0.8636\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5054 - accuracy: 0.8636\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5053 - accuracy: 0.8636\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8636\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 428us/step - loss: 0.5051 - accuracy: 0.8636\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8636\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5050 - accuracy: 0.8636\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 450us/step - loss: 0.5049 - accuracy: 0.8636\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5048 - accuracy: 0.8636\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5047 - accuracy: 0.8636\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5046 - accuracy: 0.8636\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.8636\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5045 - accuracy: 0.8636\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5044 - accuracy: 0.8636\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5043 - accuracy: 0.8636\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8636\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8636\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.5040 - accuracy: 0.8636\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8636\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 920us/step - loss: 0.5037 - accuracy: 0.8636\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8636\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.5035 - accuracy: 0.8636\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5034 - accuracy: 0.8636\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 379us/step - loss: 0.5032 - accuracy: 0.8636\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5031 - accuracy: 0.8636\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 378us/step - loss: 0.5030 - accuracy: 0.8636\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5029 - accuracy: 0.8636\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5028 - accuracy: 0.8636\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5028 - accuracy: 0.8636\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 671us/step - loss: 0.5027 - accuracy: 0.8636\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5026 - accuracy: 0.8636\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 805us/step - loss: 0.5025 - accuracy: 0.8636\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5024 - accuracy: 0.8636\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8636\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.8636\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8636\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8636\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 841us/step - loss: 0.5020 - accuracy: 0.8636\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5019 - accuracy: 0.8636\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.8636\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5017 - accuracy: 0.8636\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.8636\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.8636\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5015 - accuracy: 0.8636\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 626us/step - loss: 0.5014 - accuracy: 0.8636\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 919us/step - loss: 0.5013 - accuracy: 0.8636\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5012 - accuracy: 0.8636\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5012 - accuracy: 0.8636\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 822us/step - loss: 0.5011 - accuracy: 0.8636\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5010 - accuracy: 0.8636\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5009 - accuracy: 0.8636\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 938us/step - loss: 0.5008 - accuracy: 0.8636\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 301us/step - loss: 0.5007 - accuracy: 0.8636\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5007 - accuracy: 0.8636\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8636\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8636\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5004 - accuracy: 0.8636\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8636\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 652us/step - loss: 0.5002 - accuracy: 0.8636\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 620us/step - loss: 0.5002 - accuracy: 0.8636\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 327us/step - loss: 0.5001 - accuracy: 0.8636\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 760us/step - loss: 0.5000 - accuracy: 0.8636\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 161us/step - loss: 0.4999 - accuracy: 0.8636\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8636\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 897us/step - loss: 0.4998 - accuracy: 0.8636\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4997 - accuracy: 0.8636\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.4996 - accuracy: 0.8636\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 317us/step - loss: 0.4995 - accuracy: 0.8636\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 297us/step - loss: 0.4994 - accuracy: 0.8636\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4993 - accuracy: 0.8636\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8636\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 879us/step - loss: 0.4992 - accuracy: 0.8636\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4991 - accuracy: 0.8636\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 891us/step - loss: 0.4990 - accuracy: 0.8636\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8636\n",
      "Epoch 1054/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8636\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4988 - accuracy: 0.8636\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8636\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4986 - accuracy: 0.8636\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8636\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.8636\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8636\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 682us/step - loss: 0.4981 - accuracy: 0.8636\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 621us/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 718us/step - loss: 0.4979 - accuracy: 0.8636\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4978 - accuracy: 0.8636\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4977 - accuracy: 0.8636\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.8636\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8636\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4973 - accuracy: 0.8636\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4972 - accuracy: 0.8636\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4971 - accuracy: 0.8636\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.8636\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8636\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 938us/step - loss: 0.4969 - accuracy: 0.8636\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 572us/step - loss: 0.4968 - accuracy: 0.8636\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4967 - accuracy: 0.8636\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4967 - accuracy: 0.8636\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 895us/step - loss: 0.4966 - accuracy: 0.8636\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4965 - accuracy: 0.8636\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 964us/step - loss: 0.4964 - accuracy: 0.8636\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8636\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.4961 - accuracy: 0.8636\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4960 - accuracy: 0.8636\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 951us/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 807us/step - loss: 0.4958 - accuracy: 0.8636\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8636\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8636\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4954 - accuracy: 0.8636\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8636\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8636\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 709us/step - loss: 0.4952 - accuracy: 0.8636\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4951 - accuracy: 0.8636\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8636\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8636\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 288us/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4947 - accuracy: 0.8636\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.4946 - accuracy: 0.8636\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4945 - accuracy: 0.8636\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 328us/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.4943 - accuracy: 0.8636\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.8636\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.4940 - accuracy: 0.8636\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8636\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4938 - accuracy: 0.8636\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 639us/step - loss: 0.4936 - accuracy: 0.8636\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8636\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8636\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 376us/step - loss: 0.4934 - accuracy: 0.8636\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 750us/step - loss: 0.4933 - accuracy: 0.8636\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.4932 - accuracy: 0.8636\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4931 - accuracy: 0.8636\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8636\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.4930 - accuracy: 0.8636\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8636\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 690us/step - loss: 0.4928 - accuracy: 0.8636\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4927 - accuracy: 0.8636\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 460us/step - loss: 0.4927 - accuracy: 0.8636\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8636\n",
      "Epoch 1134/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.4925 - accuracy: 0.8636\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4924 - accuracy: 0.8636\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4923 - accuracy: 0.8636\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 249us/step - loss: 0.4923 - accuracy: 0.8636\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4922 - accuracy: 0.8636\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 982us/step - loss: 0.4921 - accuracy: 0.8636\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 750us/step - loss: 0.4920 - accuracy: 0.8636\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8636\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8636\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 468us/step - loss: 0.4918 - accuracy: 0.8636\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4917 - accuracy: 0.8636\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8636\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4916 - accuracy: 0.8636\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8636\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8636\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8636\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8636\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 355us/step - loss: 0.4912 - accuracy: 0.8636\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4911 - accuracy: 0.8636\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.4910 - accuracy: 0.8636\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4910 - accuracy: 0.8636\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4909 - accuracy: 0.8636\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 894us/step - loss: 0.4908 - accuracy: 0.8636\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4907 - accuracy: 0.8636\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.4907 - accuracy: 0.8636\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8636\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8636\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4904 - accuracy: 0.8636\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4903 - accuracy: 0.8636\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 851us/step - loss: 0.4903 - accuracy: 0.8636\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4902 - accuracy: 0.8636\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4901 - accuracy: 0.8636\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4900 - accuracy: 0.8636\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4900 - accuracy: 0.8636\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8636\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4898 - accuracy: 0.8636\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4897 - accuracy: 0.8636\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8636\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8636\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4895 - accuracy: 0.8636\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 813us/step - loss: 0.4894 - accuracy: 0.8636\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4894 - accuracy: 0.8636\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4893 - accuracy: 0.8636\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8636\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4891 - accuracy: 0.8636\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4891 - accuracy: 0.8636\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4890 - accuracy: 0.8636\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8636\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8636\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.4888 - accuracy: 0.8636\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8636\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 918us/step - loss: 0.4886 - accuracy: 0.8636\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8636\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4885 - accuracy: 0.8636\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4884 - accuracy: 0.8636\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4883 - accuracy: 0.8636\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4882 - accuracy: 0.8636\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 755us/step - loss: 0.4882 - accuracy: 0.8636\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8636\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 754us/step - loss: 0.4880 - accuracy: 0.8636\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4879 - accuracy: 0.8636\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4879 - accuracy: 0.8636\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8636\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4877 - accuracy: 0.8636\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 456us/step - loss: 0.4876 - accuracy: 0.8636\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 463us/step - loss: 0.4876 - accuracy: 0.8636\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 389us/step - loss: 0.4875 - accuracy: 0.8636\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4874 - accuracy: 0.8636\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 633us/step - loss: 0.4873 - accuracy: 0.8636\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8636\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 362us/step - loss: 0.4872 - accuracy: 0.8636\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 669us/step - loss: 0.4871 - accuracy: 0.8636\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8636\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8636\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 733us/step - loss: 0.4869 - accuracy: 0.8636\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8636\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8636\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.4867 - accuracy: 0.8636\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8636\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8636\n",
      "Epoch 1214/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8636\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 633us/step - loss: 0.4864 - accuracy: 0.8636\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 736us/step - loss: 0.4863 - accuracy: 0.8636\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 103us/step - loss: 0.4862 - accuracy: 0.8636\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4862 - accuracy: 0.8636\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.8636\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4860 - accuracy: 0.8636\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 164us/step - loss: 0.4859 - accuracy: 0.8636\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 344us/step - loss: 0.4859 - accuracy: 0.8636\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4858 - accuracy: 0.8636\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8636\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4857 - accuracy: 0.8636\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8636\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4855 - accuracy: 0.8636\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4854 - accuracy: 0.8636\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 548us/step - loss: 0.4854 - accuracy: 0.8636\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4853 - accuracy: 0.8636\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.8636\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8636\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.4851 - accuracy: 0.8636\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8636\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4849 - accuracy: 0.8636\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4848 - accuracy: 0.8636\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8636\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.8636\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4846 - accuracy: 0.8636\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4846 - accuracy: 0.8636\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8636\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4844 - accuracy: 0.8636\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.8636\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 760us/step - loss: 0.4843 - accuracy: 0.8636\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4842 - accuracy: 0.8636\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8636\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8636\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 537us/step - loss: 0.4840 - accuracy: 0.8636\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8636\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.8636\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 937us/step - loss: 0.4838 - accuracy: 0.8636\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 714us/step - loss: 0.4837 - accuracy: 0.8636\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4836 - accuracy: 0.8636\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 964us/step - loss: 0.4835 - accuracy: 0.8636\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.8636\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4834 - accuracy: 0.8636\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 734us/step - loss: 0.4833 - accuracy: 0.8636\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4833 - accuracy: 0.8636\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.8636\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4831 - accuracy: 0.8636\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4830 - accuracy: 0.8636\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.8636\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.8636\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4828 - accuracy: 0.8636\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.8636\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 775us/step - loss: 0.4827 - accuracy: 0.8636\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 590us/step - loss: 0.4826 - accuracy: 0.8636\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4825 - accuracy: 0.8636\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4825 - accuracy: 0.8636\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 747us/step - loss: 0.4824 - accuracy: 0.8636\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 715us/step - loss: 0.4823 - accuracy: 0.8636\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 803us/step - loss: 0.4823 - accuracy: 0.8636\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 238us/step - loss: 0.4822 - accuracy: 0.8636\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 823us/step - loss: 0.4821 - accuracy: 0.8636\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 899us/step - loss: 0.4820 - accuracy: 0.8636\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4820 - accuracy: 0.8636\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 790us/step - loss: 0.4819 - accuracy: 0.8636\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 650us/step - loss: 0.4818 - accuracy: 0.8636\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4818 - accuracy: 0.8636\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 715us/step - loss: 0.4817 - accuracy: 0.8636\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.4816 - accuracy: 0.8636\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.8636\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4815 - accuracy: 0.8636\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.4814 - accuracy: 0.8636\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 600us/step - loss: 0.4813 - accuracy: 0.8636\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 916us/step - loss: 0.4813 - accuracy: 0.8636\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8636\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4811 - accuracy: 0.8636\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4811 - accuracy: 0.8636\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.4810 - accuracy: 0.8636\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.4809 - accuracy: 0.8636\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 692us/step - loss: 0.4808 - accuracy: 0.8636\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4808 - accuracy: 0.8636\n",
      "Epoch 1294/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 523us/step - loss: 0.4807 - accuracy: 0.8636\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4806 - accuracy: 0.8636\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 947us/step - loss: 0.4806 - accuracy: 0.8636\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4805 - accuracy: 0.8636\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8636\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 664us/step - loss: 0.4803 - accuracy: 0.8636\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8636\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4802 - accuracy: 0.8636\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4801 - accuracy: 0.8636\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 474us/step - loss: 0.4801 - accuracy: 0.8636\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.8636\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8636\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8636\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4798 - accuracy: 0.8636\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 777us/step - loss: 0.4797 - accuracy: 0.8636\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4796 - accuracy: 0.8636\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 956us/step - loss: 0.4796 - accuracy: 0.8636\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 925us/step - loss: 0.4795 - accuracy: 0.8636\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4794 - accuracy: 0.8636\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 689us/step - loss: 0.4794 - accuracy: 0.8636\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 567us/step - loss: 0.4793 - accuracy: 0.8636\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8636\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 858us/step - loss: 0.4792 - accuracy: 0.8636\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 635us/step - loss: 0.4791 - accuracy: 0.8636\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4790 - accuracy: 0.8636\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4789 - accuracy: 0.8636\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 871us/step - loss: 0.4789 - accuracy: 0.8636\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 926us/step - loss: 0.4788 - accuracy: 0.8636\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4787 - accuracy: 0.8636\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8636\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4786 - accuracy: 0.8636\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.8636\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 773us/step - loss: 0.4785 - accuracy: 0.8636\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.4784 - accuracy: 0.8636\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8636\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4783 - accuracy: 0.8636\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.4782 - accuracy: 0.8636\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8636\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8636\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4780 - accuracy: 0.8636\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8636\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.4778 - accuracy: 0.8636\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.8636\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.8636\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 943us/step - loss: 0.4776 - accuracy: 0.8636\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.4776 - accuracy: 0.8636\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 909us/step - loss: 0.4775 - accuracy: 0.8636\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4774 - accuracy: 0.8636\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4774 - accuracy: 0.8636\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 796us/step - loss: 0.4773 - accuracy: 0.8636\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4772 - accuracy: 0.8636\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.4772 - accuracy: 0.8636\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4771 - accuracy: 0.8636\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8636\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8636\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4769 - accuracy: 0.8636\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4768 - accuracy: 0.8636\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 580us/step - loss: 0.4767 - accuracy: 0.8636\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 827us/step - loss: 0.4767 - accuracy: 0.8636\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 885us/step - loss: 0.4766 - accuracy: 0.8636\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4765 - accuracy: 0.8636\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8636\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8636\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.8636\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 950us/step - loss: 0.4763 - accuracy: 0.8636\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4762 - accuracy: 0.8636\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4761 - accuracy: 0.8636\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.8636\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4760 - accuracy: 0.8636\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.4759 - accuracy: 0.8636\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.4759 - accuracy: 0.8636\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 354us/step - loss: 0.4758 - accuracy: 0.8636\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4757 - accuracy: 0.8636\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.8636\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8636\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4755 - accuracy: 0.8636\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8636\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.8636\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 701us/step - loss: 0.4753 - accuracy: 0.8636\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 762us/step - loss: 0.4752 - accuracy: 0.8636\n",
      "Epoch 1374/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8636\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4751 - accuracy: 0.8636\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8636\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 386us/step - loss: 0.4750 - accuracy: 0.8636\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8636\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 439us/step - loss: 0.4748 - accuracy: 0.8636\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 743us/step - loss: 0.4748 - accuracy: 0.8636\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.8636\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.8636\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4746 - accuracy: 0.8636\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.8636\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 789us/step - loss: 0.4744 - accuracy: 0.8636\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 866us/step - loss: 0.4744 - accuracy: 0.8636\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4743 - accuracy: 0.8636\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 606us/step - loss: 0.4742 - accuracy: 0.8636\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 917us/step - loss: 0.4742 - accuracy: 0.8636\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4741 - accuracy: 0.8636\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4740 - accuracy: 0.8636\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 588us/step - loss: 0.4740 - accuracy: 0.8636\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.8636\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 934us/step - loss: 0.4738 - accuracy: 0.8636\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8636\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8636\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4736 - accuracy: 0.8636\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4736 - accuracy: 0.8636\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4735 - accuracy: 0.8636\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4734 - accuracy: 0.8636\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.4734 - accuracy: 0.8636\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8636\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8636\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 553us/step - loss: 0.4732 - accuracy: 0.8636\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.4731 - accuracy: 0.8636\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 884us/step - loss: 0.4730 - accuracy: 0.8636\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4730 - accuracy: 0.8636\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.8636\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4728 - accuracy: 0.8636\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 230us/step - loss: 0.4728 - accuracy: 0.8636\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.8636\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 877us/step - loss: 0.4726 - accuracy: 0.8636\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8636\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8636\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 937us/step - loss: 0.4724 - accuracy: 0.8636\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 795us/step - loss: 0.4724 - accuracy: 0.8636\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 724us/step - loss: 0.4723 - accuracy: 0.8636\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4722 - accuracy: 0.8636\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 747us/step - loss: 0.4722 - accuracy: 0.8636\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.4721 - accuracy: 0.8636\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4720 - accuracy: 0.8636\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4720 - accuracy: 0.8636\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 768us/step - loss: 0.4719 - accuracy: 0.8636\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4718 - accuracy: 0.8636\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8636\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4717 - accuracy: 0.8636\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4716 - accuracy: 0.8636\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4716 - accuracy: 0.8636\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4715 - accuracy: 0.8636\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8636\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8636\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8636\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 895us/step - loss: 0.4713 - accuracy: 0.8636\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4712 - accuracy: 0.8636\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4711 - accuracy: 0.8636\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8636\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4710 - accuracy: 0.8636\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8636\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4709 - accuracy: 0.8636\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.4708 - accuracy: 0.8636\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.4707 - accuracy: 0.8636\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.8636\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4706 - accuracy: 0.8636\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.4705 - accuracy: 0.8636\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.8636\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4704 - accuracy: 0.8636\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4703 - accuracy: 0.8636\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8636\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.4702 - accuracy: 0.8636\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4701 - accuracy: 0.8636\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 618us/step - loss: 0.4701 - accuracy: 0.8636\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.8636\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4699 - accuracy: 0.8636\n",
      "Epoch 1454/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 996us/step - loss: 0.4699 - accuracy: 0.8636\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 843us/step - loss: 0.4698 - accuracy: 0.8636\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4697 - accuracy: 0.8636\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4697 - accuracy: 0.8636\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4696 - accuracy: 0.8636\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 781us/step - loss: 0.4696 - accuracy: 0.8636\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4695 - accuracy: 0.8636\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.4694 - accuracy: 0.8636\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4694 - accuracy: 0.8636\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 709us/step - loss: 0.4693 - accuracy: 0.8636\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 576us/step - loss: 0.4692 - accuracy: 0.8636\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4692 - accuracy: 0.8636\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8636\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4690 - accuracy: 0.8636\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4690 - accuracy: 0.8636\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8636\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 967us/step - loss: 0.4688 - accuracy: 0.8636\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8636\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 546us/step - loss: 0.4687 - accuracy: 0.8636\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.8636\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 808us/step - loss: 0.4686 - accuracy: 0.8636\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 888us/step - loss: 0.4685 - accuracy: 0.8636\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 706us/step - loss: 0.4685 - accuracy: 0.8636\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 961us/step - loss: 0.4684 - accuracy: 0.8636\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4683 - accuracy: 0.8636\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4683 - accuracy: 0.8636\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8636\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4681 - accuracy: 0.8636\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 821us/step - loss: 0.4681 - accuracy: 0.8636\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.8636\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.8636\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.8636\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4678 - accuracy: 0.8636\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4678 - accuracy: 0.8636\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8636\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 642us/step - loss: 0.4676 - accuracy: 0.8636\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 868us/step - loss: 0.4676 - accuracy: 0.8636\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.8636\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8636\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8636\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 534us/step - loss: 0.4673 - accuracy: 0.8636\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8636\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.4672 - accuracy: 0.8636\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4671 - accuracy: 0.8636\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 593us/step - loss: 0.4671 - accuracy: 0.8636\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8636\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 887us/step - loss: 0.4669 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27109fcfa30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel_initializer: initialize all weights as 1\n",
    "# bias_initializer: initialize all biases as 1\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape = (2,), activation = 'sigmoid',kernel_initializer = 'ones',bias_initializer = 'zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train2,y_train,epochs = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f583eee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4891429841518402, 0.8333333134651184]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2a02d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights : [[2.4544168 ]\n",
      " [0.54251766]]\n",
      "\n",
      "biases : [-1.1430072]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Weights and biases set : \n",
    "\n",
    "weights , biases = model.get_weights()\n",
    "print(f'weights : {weights}\\n')\n",
    "print(f'biases : {biases}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a6ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./models/Insurance_prediction_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Saving Tensorflow Model\n",
    "\n",
    "model.save('./models/Insurance_prediction_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0434de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tensorflow model\n",
    "\n",
    "model = keras.models.load_model('./models/Insurance_prediction_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eeb24ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.4891 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4891429841518402, 0.8333333134651184]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bbeb6",
   "metadata": {},
   "source": [
    "# Gradient Descent From Scratch"
   ]
  },
  {
   "attachments": {
    "img_17.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAUFBQUFBQUGBgUICAcICAsKCQkKCxEMDQwNDBEaEBMQEBMQGhcbFhUWGxcpIBwcICkvJyUnLzkzMzlHREddXX0BBQUFBQUFBQYGBQgIBwgICwoJCQoLEQwNDA0MERoQExAQExAaFxsWFRYbFykgHBwgKS8nJScvOTMzOUdER11dff/CABEIAIUD6AMBIgACEQEDEQH/xAAvAAEAAgMBAQEBAAAAAAAAAAAABgcEBQgDAQIJAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAADssAAAAAAAAAAAAAAAAAAAAAABFfUkqJS0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVdaMLIlcNBX6AARGsbE0BM5IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABrPUznz6AAACPG4yYFPQAAA5+6BMfIq+xDMAAAAAAiMugJAL9556GGDnDnffc2dekV/F2CgNX0nVxJtvzZ0MQm2IfMAAAh8qPYAADH0WrJyQUnSuLHHj7VEW6/P6AABWZYeTrPczAAAAAMbJjhI0EnYaD0N2AABiZNTFtmIZYAABS5dDVbU+fj0p8tKtbYq0tID59/JxP05z52CcfdfcsXYT4AACiL3oAv76xjJc222TdEZcMDPpUsDZaaBF10heVBl+FeFhqqFqqqtM/QAAGj3gjckADS/z/wD6NVMWn7cO9xAGh85FoDXTCHy0/bmm9zfq0ss5d6c5gvslSpNIXsqHPLPcm9YlEXvQN/iM73nguGX1jMTe67Y/CnLkoC/xDJnVZagFF3pzydBcU9tcqHVYAABzSdLPCnC6gUXenPPQxS8ppnpgzVJak6DQuFl0OUOmirLaonoQqWNWrVpfgAAEWyqhLSldJXaKotfWnjBdbnFrAVBb3JpZV01hqCkeyIntiROXpqXZ8rzNJu5ztcmvPfQlBF+g5fuWor2N76w6tC/IHPNWU5Y9HdQH2gL+oEv+v7A+FXrQFX2f8/Zh1xaYqxaY0sEtUUcvEUcvEU1coCuTm/smtbXAGg3+gNdMIfMDlu9aeuQ3fzUVwR6H3DHDoLji8NoVJZUEwSVXpptyc69FUJfY5e6h5gLgn+ljpPAc/wB80TfpVlb9N1WN9Ng556FoIv7lTqrlM6t1/wC80q1aQq2f7MKMvOpjOlNfWqZyIS85u6QoS5zm78fqbFsco9AaI1MixqsN50xCpqc7dE0LfRFatsGuy/67sQVYtMQibg5d6i5PLvsHGhhPPz+omV7s8z8FpAAAUxc8VKR2tu70yIj47Mqa6tHIDNp64fhjVTIJ8RSWhiRuXiDaizw+hooZm2GAAAAAAYlJ3twud01dK4iWFsnmaOoqJuE6Sc2+J0w5bp86sm3OPRxgxeQzYhszCnrfjskAGk3Y5xsexRUVvhTVvesCI1PpL9FPXDGiSwWc16bCZg1uyACkrt0ZvEdkQAABWeZP/p8rC0NAZux/MQIFd+HmAHx9HL10TnyKIvwIJlzCvCwwAAPD3FJWxtPop+4IySalbqr4ntY2lVRaoAAAAAAAAAAAAAAAAAAAIji6W0TlG3aA6mJWDyeuhNy9R5efpVxaf49hXthAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABhRScAAAAAAAAAAAAAAAAAAAB+f0KrtP6ItKQAUxc8CNdgW6I5XlxwIsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH/xAAzEAABBAIBAgMHBAEEAwAAAAAFAwQGBwECAAgQESAwEhQVFhchNxMxNmAzGCUycEBBUP/aAAgBAQABCAD/AKrmZ8nGABE0xhkqRmMVDH20bOyQs7L6P/7naMinEbjhcnHaKkZuWQFEqb8snzl26jIjWJP29dSmzIy9iAxcTHRLZ1/c7QTxmupzjPTR+LWfmbYOuJss9dWFAdpUdgxRvj+t4Jj9SOg3b0WxEe4ePGWnrWhjGK4nPOmj8Ws+5YikJGkSK7DqYhZRzq1YfW9nz63s+ZvQdx51HxQf4++56qa85BZyHnoHU2HkL9YWAOP29dk7POoAzZv1tSg74l8Nz5WRRg82eaNfQYkx5DLv3T1FibBs8ZMl/TeFWDFVki59TbONcZzlgRYkWTZ6xOpmtxD3ASHyGeYnZKMSvtnOMYznKcijmfvsiZDOs+yhjOM+jLpKxiEdLHX0ABPhwxUqb82eP+oeMDpPuK312xvjGcWSyei0EZwGDFWJgYPKMfVtd+2aVzNtl+mV42UrNJDTvdEAI1ZLmMwjFYz4ZYkXalkfDHPDHM4xnGccmFNwGZILYdU+DM1VOjMHLzL+HSvlV/jiE+Y3YsGjSqiJcaWZGBrIgw80ylDOHRosddwKPPA4rd8X5P54wgIls+c1xZQix2BFwz7T7ZSFE2c/YoqaLJ6KpeaxpE/ZphY0DBBR0dEsRY98UHDdUdn3pzCNISgG4HZruWLS0B+q+4dmEYjOMfGo1KQcsYqEAfmduUGrdZdeu/15c6e2A/ztjHGJJgTTWVY+ewrpEQEt8K5HJCPkwIYYGdtHGa9nzQdzHGX52K98/fHJ+HGTLqNABG7qq63eI5RUkL8108y8Nhq0ct3bZBy289nrJn53VsKzjzmGS5Aa8ZoYhEU+WdYttGhKkeDtBWVkk1klE1aNeasmUxhu/qlYlFDrjVyWYQiGC3aL1h3kQAZKAxEMVEPz/TzZq7R6LIsCTBqRY9zcdZHFwjhaZ48IfK+VX+OIT5uo7OTjqvIU1Zt27Js3atvNYy+JDZdXQ7mO28WZOJLrIXuYUMRlScpH9jQpmbEExTyiTaxav2LN32mMkdRxWH6t+2eRXfeT3PPTCjhJRVBZNO3I38Ct6sXGPUYq5jF8l2GOdQZpsFrE9jNVR7aL1/FRanmvko8aQjAZiLHthQ1gOa27GtzELlznfpf/ABjjz7ePh9gURGBEye+0Vhw6H7lEBHa7RKpKvDLltFzKMgjoMymy/OxXu4WTQRWVU6ekl5ZPLCnrrnVl7HyvGOVXlfNbwbK/nZb6k+pEz48eaO926urNnMp8DvEZEpHYiMzWiRPEMrU0TPwKLFy3a4n9ix6LFj0er2RqyyERo0tFitltrZk4SQ8iefh/UFZbXThixkgxJ0wz9WkefVpHmbaR42cYcN0VserctZoWNGtkUenmy3MZLKQKQ48k1/iEr5Vf44hPHWF9kFcISaYWLELYgYkjK9Dy0bM6R6ojMlOQpm4k2eB/Gb9SJglpMpiDgwNyZMRz55nI5A0Ui08PBLQI1xJLYtNOvWo1qxaRScuhOFScAtO45koSGMPv4cEOcEeo6WdiSJDZtnVhDprOULnOwqT26rOWkMcvoZFCD4tGY8Rf8zyoc+5zy7hWO1p/56u5jtt+2edOe6j4HNTCnL/xjFm0x588uyV2bAWoQyzTV95Z4Xb1AWsFyrNBE47Wu73FWhRz/TH7cunwl9lVlA9H5BkJYunz6MSqUWpu7fhpLMj9UTKLMi0/m42ARp4dIQpKeTgI2kR3WxrXD2ESrlqD3M7iWG5u018vbRpIT2sjHhAJpzpc/GGfOfayVy120AUPO5LK20vGyeyydlBJNC38ex2lDDQnHTzDbpyc7uanj3tNN9MXsV73tIk47WUj250/R3AGsQm2eXIsva1nx2CghzFqLYMmDXtuppprnbfxx5I54p9SFiYz2t7Kg27aaI6SpdcyujEmDVBuybINm3a0m+XNdTdLFIGWYylAhF9ERT3GSB4twLrnPUfMdscMWpXgAk6GFPrZVPPrZVPPrZVPGyyThFJdEqwfERjxsw+Q7M58h2Zz5DszkfGFhQ3RsWkkFmZg08fDPplYvPplYvPplYvPplYvBtdTxkQYOHPe9oINkVjx9jFwzRyPEjWjvvNf4hK+VX+OIT26kfbYP6rNpysq9T0ahA4cWyBjGAxkcLIhA5Yot01C18xg/KHtk7/Pt9xGFOv2xjwjWNZv1MmjLK6IqaRn0BnbeQWcIzHFnMToqsH1fhSDkxyJ+OnUXaOu3aQeIzqfhi/JJnaTktIm31xjTHhjmeVfjP1YvJTBNg8fDXrdn8h2ZyxIlPGSsAw91gdmZ1xnkcjUvEEd1zW//HPOmffX5BJ6dr/zjNmUx2OCypMW4bDPkOzOfIdmc+Q7M4DYEh4xq1J86kmX69UFVOBZRljWsOJZi4PIIZ+kv2u7Gd51RmmuM/bHKyziZXZZEs36oDr7A6LRNjHgrKNgxQZjevsTe1a+hjPqGhRqZQxt8GjtlxLEVYbZqyASF/OjdmSrliZ9i8adU35ZGPCATTnS5+MM9ikLnzsk9cMPkOzOfIdmcjkYmQgj7ya5n9uUr7bO2brY5aa/N0l0Jd3+MaMHuc9M+ucVQL4003+vpTfspv7Gu22L3E2NYeQ4wENl0hYDGDNAgrcEtT3YNIJXsegDBVsKmxEcLip9+/ZxyNxWj2jwu9nhqD1THysgAQRDLJJzLRUJHBJW+MMYMKjJqRWtKiIGHR8ObdnxHCmch+omPOs9r8GlHsxp9yHjgLYO2XUdWO+lI6Gm3kVpWaT8s6Lgp1w+xwUCGh+3T3GDDmGh1jWOZ5W/tGbcuI9jmzdvtnO2/ubXnubXmzVr/wCvWsqfoQQNoolV0AcRVs9MnfJNf4hK+VX+OIT26mRbwvEI21YxgG8Y4cki8wNAwwMhsYtMHIsU25CBarFSVvG4q3JzKDGAlsgLKDySRSuSCVRsMrWuhNbgvh7O5DMydFgjKHiupEIM3RHyaNScLKxKBYJxxlMJ1GMt9+1uhjry3asdAAIZIEw931m7sO7bNI64xzb9uUT/ALkvZ0n72n/nq7vn9uUi2yELWxG91NvY02zy2A05lc4g5cONe7v2+Fd/NejbDqqphpypYwYax2MvpGSJsBLRV4/gjZpgHl0y5NkkDd3VQMyc2f6BDGw2ho5NRsaWFPrrrorMG8cNAVJ2SdjFMCa3q5aMkikokdxlZDrG9w0QC3wtCmzUZKIVYcSnzddcDy69ExkhqGSb45ZC5RxFZAKF0KNk8QjGY7IPNngmMSFa9bOTGMmbQc0bNGbxwHNTII0bcsElkXBpg81pMKoErCINlWX52K+e599yzCLQ1G4RQWEIxUzD7r8GUipow9xt9seEslTYFD5JIEIRUEWUruOolhhVkXRVcMuXMNdICgUuHMHzUkxaPWb65gTGbk4bwCHfe9KHDnCbh20ZqLNI3HnTB+ZNlbFnw6uo9k0+Zl1LMQQ9xST0R00TT5KpA0i8eMm3dQRx7HoWz2J+o+3fptldmLS6H7ax2UGkHJ/O5FCNxWW4lcyu39styVScTDwRA2WrWMF5MaUsyYeQ9L8kp/G4SFmX8OlXKr/HEJ5Jrgj8Umo6KPgo0iTfpyA7y099Cr+AxPmudd9dd9e8mQLuY6dRC05MYxFoq0i8kNzyuXDNRk5pSGPYXHzGHXLkYuWjOOTVk2ct3jRq6bJ3UIXlUkirGPBHTPZySK8KKYN3EAa55ZUl3isMNkUK8i2IbDAALPYuCFmvhWX/AHKofJlyCD2PQsO0QtcLR5MmyTeTR2gRf4xy4iS7KBlmbMIxZixI0eyzyuUcSeazqfZ7+HM8gZ/SBTKfoz95YlepN9srVvDk0Z9LZoP5ZsVzNYQfCp17J8SuHgi+fO/eIsGTt4tF7d+orBRKKBAzUGxw2b55At9Dc2sqSb8uXKp9tHIGybIJNUEUEWX52K+ctAIsXLtS75rBIqOLaGEywkUYHORpNhAQo5HRohIoTGpSL0GGXNeRhZnuzXEBxwMYxGDuKJ6K6b6KQ4GTiDl7H9NUUvbyp5VEUltc6KeGMdz4AjLZCPaP8ernlpAHhsGYtFjC5MjLomCOoG8fG7TiQvbjt03ZNl3DiQXHEphP2z6SY6pq65/qorvmeqivsZ+zjquhumm+W0v6m5idQXaBOlqOLpCJFK3cz+0OlfKvV9muoRrjKCWymFc9ikSBGDIsy98qqCC2vsK6Nm6GM4S7LIprpKpKwsOViSjyN51QS133317IREC3kb+SJ8Vj5KRTFAmY88ri46VgnYl/F1T+4vVGQefdBJTOmd/DtIIuGk+g3Uo3QSbpJIozRofLsUQggMHYAhbAax8uyem+M67Js2iGc5R8O2eNABGLy98+E+gmikjr7KfaNQ6PRJFwkH2+2uc4ikdIbFiUtP8A7cab4xeZXbH/AJPh609PZjcNkRXRlCWCdeNIY76bTDwO6mFela5x8WL2BKO26eimu2m/wIJz4EE58CCc+BBOfAgnNgoPw+yDdBtphNB+zbP2bpk4jlVQaJk0igb+inQo0+JdiScXriHQx65egf8A48/UTJyGvItnl1pkaztEJPQ8Dj+YvEI6Hz3J/MuC8dyM7OtXCiCuranT56Qxwy5Of3BZPZVJVPRap2a8mQlO6KeyaSem0thwaZNRbcp3zyJt2pi1p+dblS0eRIvkl/jkX5GHTF4P3UZULvjSLyj+8Z5CoUpEsmsq9nDd2o2Vw0gEFJQVqSZLf9kf/8QAWBAAAgIABAIECAcKBwwLAAAAAQIDBAAFERITMQYQIUEHFCAiMFFhsyMyVXGRkpUVQlJWgYKUtNHSM2ByorGy0yRDUFNUYmNwdJOj4iU0RWRzg4ShpMHC/9oACAEBAAk/AP8AVXSq2hRglnlinnaAuqDXbGVR9XPIDEPCF2vvMRbfwpAdjproNdrAjGVUq1OnblqRTQ2WmM7xaBmCmNNFDEr/ACgf46ZRQkiqVTLLZtTMXUd5ihRdG2DvZsX3t3ZL9pTKwA7FI0AC+VDvFvM455/UkFAeNFj7DIiJ+dgCDK44pek2W+parj4dE9Wxxhy9sxce4/4VmwTNMfyyOf46fId/3DY+UbnlZJYgy2HLPFakzS12+Ekk4kzMqSMwDbEC4BD0MxMeYaMBxcvlUmWNvWCVA/i5bi8daBrArbhxOErBC+3uXU6a+itxPZqCMzwBhvjEg3IWXmAw5en+Qsw9w2PlG51pI0NOtLYkWMbnKxKXIUHTUnTHR7pLbsOCRDBTilc6exJceDvpv9kf8+PB103+yP8Anx4P+mv2T/z46LdKa3r41BI/60uMsz39Hg/tsLMtczSQFJ1VZEePmGClsBTNUoWbEYcaqWijLjXTTs1GLuQHJ79FbPAqxWEsjjJuQEuSvp7cXjor+M+LbgZOFu2byO5dfKtRTSVZzBOiMCYpVAJRx3HQ6+htxWPFrD1puGwYJMgBZG05Muo1HpbccVi2JTWiY6NLwgGfYO8gHU+ktxQyW5uBWR20Msm0ttUd50BPpToANTizFYrTxiSGaJg6Op5FSOYxLUizLaPFmuK7Q7tRrvEejcsT5PPwsjTMYpMujmT48xh0JmPkZ/l36VF+3Gb0pTz2x2EZvoB9FqYaUBcIvORydqRj2uxAxo/SHOSlvNJPwGI8ysnqjgU7QPQZVbfLo8yFB86BAqCUab/yJggg8jiHXNMiTdYiXs8cy7XWeu/r2jz0xLxa1yvHPA2mmqSDcD6aZYw+TXIk3HTVpYyijE6GWLM7YkTvXXQ+Rvq5fPaE0Jh5U7XMx/yHwAltNIb9Yf3mcc/zW5p5GRw1Lj9ovUkWCYH1naNH/OxLxqWbV/HcptpqIp3rfHAHc+w+eMfI9/3DY+RqXuV8rpRl9eeM6NAZg0qnn2ourYlMlW1Ck0Mm0rujkG5SAwBGo8tC8dOLVIgdDLIx2xxj2sxwwlz/ADZxczaf/SkebCvqjhXzFHVUmuWLVqOtTo1/4axI/cmKk1O1RscGzTnIMsfqbrRhWjeGp0ihT+/UnOxJ9O+Suxw4dHUMrjtBB7QR5djh570ismrWlHa1WBBuntf+UmIBFVqxhI15k95Zj3sx7WPecXoKyzSpDEZpFj3ySHaqLuI1YnkPSTmCypE9K4uu+tai7Ypk9qHCLDm9CxLQzaAfeW6x2vp7G5jqz6jQJTeqTzojsvLVUJ1OLwt1FmeHjKjqpdACQu8DXnzHlyrHDCjSSSMdFREGpYnuAGI2Au762RV351cuRtN2ndJORufqvQWY4pWhd4ZFkCyJ8ZCVJ0I7x6DJLuaWYqgtXPFiAKsbkKhkOJN1W9AsyHvGvNW05Mp7D1tt6OdKZJTVXQiOnmi9rxp+CljmB+H1fiZX/XX8jLoeFXjqDMgEAWfgg2n3/PGQmOg+TKp5mKpHC31ogpxmNq90KzUv/wBH2ZDK9TQjeISeRUEFcSrJDNGskci9oZHGoI9hHoCXgmvvm9+P1xUgTGrexiG9BflpyTxmMWYtOLGG7GaPXk+nxT3HGRVmyURhPFGBI9e7Xnv79/PGYzW46q8KCWbTi8FfiI5Hxii9m7EYeN1KujDUMCNCDid3PRnPLNeAMeVWZy0XpujOVXplQRrLbpwzyBAddoaRScdEMmqWojrFPBQgikQ8tVZVBHkVxNTuRGORe8d4ZT3Mp7Qcb5suk0WwE7BcpOTsmT1OuLKWK1mJZYJUOqujjUEeQ8sNjK78d2rPCQrhkBVkJIPmSKSHGPke/wC4bHyNS9yvlAGzm2biU+tANIF94cRLFBBEkUUajQIiDaqj2ADy0MleO1Jnl5e7bUU8HXrItWq0PAy5WXzKaMPhGQd8kh5v6gBjWlmEkbQ3xEPMvRHkJl/DUgFX6499e7Vmryj2SqVJxIWu5LZmyqxr/wB2I2fQhA668cozbpFTyuXfr5kdhXYuuneNnkTB63R2pBktMDkHlJkmPzhlIxO8LshCyoFLISNAwDhgSPaCMZtmN0XbdEk3ZjMVeKyAdnIAelA8T6VZNHdX/aqeqH6UBJ6iglvmGjACNdTI24/zFOIRHOlJJbC94mn1lcH2gt5evjvSK/WymH5pzq+IwlenXighUdyRKEUfQMZ9mkKwZXNNFWrzCKEtAhk88KusgfkQxx8q2/6E8vniNLV3NJGlzO3KmrWmbuIOukag7UTkBhzFldqbxiOiRqlaZuyThHuR+ezuPXKYr2UGLNacw5xyUzvJH5muANL1GCzoOQMqBiv5Dj8TK/66/W4SONC7seQVRqScc5JGhhHttvvP1EQDq+VG90ca7/uPV+rt830Ca/cjomkaex5nR/6JeqeGGwR5kk0RmRT7UVkJ+kYzqtbyvMaTy1RXqCumhRmVubvruiK9r4mjjzoGMwl9naobVwpl1UMRgDx+3SSSYhQu/uD6d28aN19IKEEFPY7weI62OEzBCRLK7oSCfwBggzW6SGcgaAzJ5kn84HDwzZHPTmvZW8QTSOFJhHF2poQSCQwfq02XMooXPyxpEn/76uh3Si2YCBx6eWPNA+oB8xwcdAemf2NJjoD0z+xpMdAemf2NJiN0EkavtkUq67hrowPIjvHplRM4o7pculPr74X9kmHeCGay8dLj6qatvXRoG15Bz5PyPf8AcNj5Gpe5XDokxRhGzoXVWI7CygqSAeY1GM/o2skzmwkIirUhXGsr8Eht5lfVS4IO/E0cecNVcUmk02iX87swd2aRW7lWd9EG815TFqdnm9XbS6K0DXRv9KBwiPryPixsgjIRI10Mk0h5RxgkascZrP0ap2l4lLLaCQvYELdqPZmsxyasfUgGL4zDdD4xleZGNYJZAY+NwpRGAhxQ8fz7M32Uafbt57d77ceEW/BnUse4rTr0xTgc9uwI8TM6p6y2pxlPRy1Zylo4bticyxFySV3jY4B+J1f9ldGYKyH1GUxTH3nVar17BI2yTwNYQDv8xJIj/OxnFW7XFIyVTBWECAhVmUr+YTqCTiykF6rMJ7DMI9TVjRjJs4uq64jCW7eW1Z51C7AJJYw7ADrI2R5+ttB/tRlJ6/x6yv3c3ka78x6UXJS/e42I/V/l6frUXoOkNA5ZLmCwTQQ0BG+uhkCO0rzaghMMCJIlkiYjsIcaqTiVJr2U34ESZBHoRPFxdoMQAI00PXzbM7VQ/wAiwYoj/X6teCZ/H738j9oSJsWo69WvE0s0sh2qiKNSTiaTIOi0UxigucJHv32TmY+MHjijGM+lzjo7nrtCXuRxJPSkjIBfiQJGGTz8I0gjIiggU6NNO+u2MHHSa1k0d9OLSy3K4q6CKA/EeR7EczMz4fJ87uxOZKtu8hgd4jCJwrmAomoTEVaPMzFrajqkmFX9SFiSQMdqJmc95x7YdhQ9XyHf9w2Pla1/Qnl5tRpWNjaNaptaBbu02yx7fyhsWhPmuUZgI3cIkeiSgps0jAHY0Zw8L9Hmu1amYV9EMjy2ZxH27u3Qg9mzrJ/unLrUOo7uJEVw2vAktw/RO5x+Jdf9dfrfbPfjGXwD1mz2P/w92Idk+ZGS/N7eN2R/8MDq+FjyveLthO1YnlIMzH2RKMR7K9WCOCFPwUjUKo63CqOZPYB5PN+j1Rh7QBXHWF1lmSt/x9D73EzpLei35lYTnVoa7X+aSf4kf5W7sQpFBCixxRoNFREGgVQOQA6xqfuNbb6kZfE2yvTFwSNzPZYfQADmTiIx5rmzI8kJOvitePXgVR7UBJf1uT1cl6MVwfymDq6U1K12uQJYWDkqSAw12qcdNKX1Jf3MdNKX1Jf3MdNaX1Jf3MOrxSIro68mVhqCMZo+XWpI9sNtI0lMTfhBJNQceGq79kU8eGq79kU8eGq79kU8dIJc4th3ZrkkEcBIPJdkQA0GPCnmWU1JdmyjDXR0i2oFOhLY8N2cfoifv48N2cfoifv48N2cfoifv48N2cfoifv48MOa24IZ45Jaz1UCzIh1MZIbk3kMD0lzNNcwrINIo0Tlalb7zF+S5PXrRRSWpAA0zooBcgd7HyPke/7hsfI1L3K9QGtHOX+nWKQe7xKFznNN6QSDQ+Kwr/C22B7ogfNHe5AxHsrVIVijB7Tovex72PNj3nBHBo1JrL/NChc41e9n2aSyvL+GkJ/fZ8OTleXbJZ4O53MXjcn1kAHUd9DJll3zJyJhg8UH0vjLLOY5Zlj1UvQ1kMssIgnMu8IMSSZ9mlmIpQrZdE9giZh2GbQfBBObb8ODnGaPG9hA+8QpHrsTXvftJY9XN8posPaBFB19iXsndT/up0w39xqqT57Ip5VydUqfyrGnn+qPGgA5DrGqC/RX3uMxehaliKw2kjWRoWPJwr6g6eo48NV37Ip48KVq8ZullCGvrltaPxaZ0l2zjbzK48NNz7Ip48IdnOoOEUWtJQr1grkgh90Q16ucef3Fceo7Iur/AC9P1qLqzt8puPt4dxIUnaPRgT5kmqnUdmPDVd+yKePDVd+yKePDVd+yKeM6kzS1Hu4t2SJIWlJJI8yMADQdnVzr3Kcw+vsxB4zfuZTl8VWoh0Nm3NCNIx7O9j96oJxOti/Yme1mFoJs49mbtd9O5R8VB3KAOvmekJ97B1aSwZYPufSfmvPghl+dIjiUg5xbL2AO8QlRGnzFnxHtrUa0cEY9ewdrH2se04JklgOtvZziFpw7/Uij34hexay2540aqc5oyhQ7B3uMSyRXadSGGfJ44Ha9DKiBeCK4G/FF6Ni48py2hKdZoklGzWX1bY/MA6hsUrdT8uzq+Q7/ALhsfK1r+hOrwsW6FWWQtFVGWVZREv4AdhqceGq79kU8eGq79kU8eEeznNYRMPFHoV66hzyffGNevQE32m+ieT9/Hbk2RzSJR5gWb+hjln9qQglEPexbrPKFyfmAx33LnvMAaDoTEPpunqBOgJ0A1J09WOhGYjLKbvPLLMYYzNMw0Gg38kGPBT0hR4K0UKx7qQjGxdANxnxllLojUkBE16ayL13Q/wCIWHRFOIneec77d2c77Fl/W7YghlqU6M0zxzAMjlF1CkHUHcdAMAwZ9Zyp7Na4hMV83LIMkEcLjR9wJC6YqvZ6S2a8FaGowIknuTfEDgd4Ha+OFnudzaSWZraCaGF++KrG+qxRr7AC2IBBXkyyGtBVjOkETmRnmaOPlGXCprpjK6IySLNPEqvjMSGCJaCaTzLuGgDntJxRSmL9CCE141MaDaxcsIz8QtqAeqPbBnvRuemG9clZjMR9CDroG5eTNJzFByB4Jhl7W7lxOLOaXJOPmFvbpxZSNNFHdEg82Ne5cUjZzeKIGtGI+KfjjeVT75gupAxQkjvwVIL9d5YBBKYJyU0kRAOrXbaoWYD80sZTEHCymvelv5bWPOzK+gWxJ/mR84h1xHgwzVMqif2wLskA/LH1RKxPeRiun0Yrp9GII/o9PB43nF6TxbKqC6lrE7ewdy4seOdKs5ImzO2dDs17RAndsTyfke/7hsfI1L3K9VV57kvSCCKCKMas7yxS4kSXOr4Q2ijFo4EQeZWh1+8j/nMS2M9OVV5q8kfjaEiSLeNm+PaCdwJ7MHMc5u8CpBJIwL254kcF3I5s2MsfJKuV0RElDiBpbUzDz559ANi6klY8ZVLmUCRmHNKVYA2RrAa4mjUkb9EOMhzGtbt6wvmeZ15MvipKebhZwJHf1bVw5ntTsJb1xxo08n/0i9wxUfOqmWyNZz3LKgeTfsI2QWTH3ONfgcdBs0yHboiqE3on5hERAxfjt05SyrImo2svNWVtCrew9Q0TPujLwI/c01Z9/wDUi66iT30hlb4XUQolaTeXlI5IN+Jnnnkkae3ak/hLNiT48r/PyA5KAAMdK7WTX8ztQR1ZKRYWXYOG2JsB0B7z1qdmb9KLPAY98UBJX3nX+PWV+7m8jsNHpK86A8zDbB2H8ojwpOgJ0HaTjoLmktHIpIppDKYI2lYTCVgg34oWqba6GKyqq4+oWHl81ghkH5k6NiHhXKeWR1aFL/JIio3O4PKeXv8AUui4tpXrRKWeVzoqhRqSfmAx0lzDOql+1Pcgt3mJcRyt2Im4KQg07OoB/uZVvZrMPdn68WIuJfFGwaiagbpxGeGNT62xkVrI68matctXJyYrVgKFAgiiIBQEp57nEMcub5Ha40VZ2CeMxkoSm494KY6DZ7JnGzQVLlR6cUch/wAZYm0jKD/MJxfTMulWaMzWLC68KAP2mOHF4jpJekQJWrHW2avKV00+J7ZDjwXZjk6R9kskCEB375AkwTUnGaCYwbePA6GOaLdy1VurVYsu6SRwTn1R29uvu+ro/fzC1fyyxXh8XEYjDTqY/PaRlx0TzGnL90JZks/BSQlJVHMq+o9AZK2W2asEN++Do8SWkhsFIf8ATPyB+8xWjgrQRrFDDGNqIiDQKoHcBjpZcgzDKIrNqfK6zlYrMUmkOtjs0IRuXU+ww5RcKNrp55iIXHZJJTNp/wD1Tmcf+z4/Eyv+uv5Y1l6SZ1Xgl9lSuRNO+Mvr5X0mfN4a1OOlEENqOT48Txr2OmHCZRT6Qjx1z8SN3aMxO/sGw4OJ43FCpO0bfeNOmqIvt1fQYyapNmtiCC5ZtSQgzb5XFggtz1GuzEwlgSxLBxR8V3hbY+094DArr6x1Jxb3RTMY8x2AamStysR4mWWtZhSaGVTqHSQblYewg4yjMp79aBTHwIuIbE7AOIY1Hsb47aLjhNm88ZjSJDviowE7uBEdBqTzlf79vYB1ZdJdmBUJAjpHuLEDUtIQAo5k4nimzfM2jExh1MMEEAIirxFgCVXUksQCzEnFOeyhnSCKGHmzvqe0nsUaDFezW6LyRqbU86GGW/uGprRKe0Q90snfyXCBUVQqqo0CgdgAA6mUQ0KzzEMdN7D4qD2u2gGCxzXNZ5c0zDcNCJ7Z3aH2hdAfS14JrA+JHPM0CN87okhH1cdDhldiy+yK2mYCxGxdSYinwUeok6uiEGbRZjmEdCoIcxMMzTSglQUaAjGW1Kc5A+Cr2mtAfOzRRdU/DqVU1IHazuexY0HezHFfZmFuPbklA9ooUzyP8t/JvkWIZTmOdyw9phrV11Wu3tmYgNj5Hve4bHyNS9yuKF957NbjGaCEygFgSkaomruX0xXME6hhl2XFgwpRuNC76EhrDjsYjsUeaO8nGm3M85W5c3fF8SywceXdhwwYAgjtBB8iYRZpJQsLSkJ02zlDsOp9uLQyLPak9g3IMzHipmkkkLcUSS6B8ZpQzsTLoMtphczln9ghi34qGk2aZpNdioF95qQNoscTHvcAdUIls9FcyS7LGB50lKTRLCjEyywzxJLFIp1VkcblYfODjIszt5tl0pggSKPstTI2xxryiRe+R8TpYzm6qizKmvCiRe1a8AblEmvzsdWPUwSt0aymW9I5OgNvMm8Wij+faNV6jreeLxahGBq0lux8HEEHeQTrhw0tauDO3cZ5TxJfybj11uMcvvxX6x3suyxCCFfzSNdNx7D5COmW9Kqf3LtP3Lfg7YC3tkQbB6GpZmGaWGjDwjshSMqHdvm38hipLVyGtKstClOmyW5Kh1WzOjdqxrzijPbr5zdWpv5w0WU0kHN5bzcIj6hOGQ1qVeOrFsOoAgHD0+cbe3qTWpNIMnydydda1M6SyL7JHHlSy0MxzbMRNVzSyCKtqsmoREl5KqY6X5PMjg/BRWop3f2COMsWxkT5Nkt6olOhTeIwPP2o0lng84kYp5oPUimzLBxKhPdYhIkj+bUjTC7LEsAjtJ3pYh+DlX649Bu4NeGSV9qlm2xqWOgHaToMZPZizEzvE8lyPWtSiHKeV17HJ+8iB1JwzyMztLPPLoZbEz9rzSEAAs3VICPH0yWj/wCBlq6SlPWGkfqlcWekd9BZ2c4qFUiWeTEYSKJFSNByVVGgA+YY/Eyv+uv5cN98wqhxWnjzO5AYBL8cRiKVAm7GWtNmaJsS7csTXZ0X1JJZeRlxSit1bC7ZYJV3Iw11xazfxBF2JRfNLTQKnLYFL67O7aTpijJNRUIBUjsz1otI+1QVgdAQuJM6kqtHwjA2eZkUKctpHH5YqivSqRLFBEpJCIvIasST856kDIwKspGoIPYQcIZ+jy77GU2N43VVdtWpyAncQpOsTfg4jUOQAX0GpA7ifJRXQ81YAg/kPkQCLo3lcsVx0LgnMba9sakDlDDzIPx29OSLNfpRKkE6PyoVitSF1+aWLChReqJI6g67JB5sifmuCMDdWyTLbWczDmDPOfFYN3tUbmHVMkMEMbSSyOdFREGpZj3ADEV+borkzl8soQQh/G5/8fYDsmMvzv8AR4v7XGX53+jxf2uMqzv/AHEP9rjo5m8z9wfgxD+u+KcOSQSc5Y3M1r8khAC41ebMrIrRO/a5SE75H/Pc4+R73uGx8i0vcriNd4G0PoN2nq166jyXKEMsMDCV0XZN8ZXRSA4PqbyoUkXXXRlDDEKRr6kUL/R1orpIpV0YaqysNCCPbiNp8giBmym2XBeGNm7akoJ1JjJ+DbvXEaqz6bmAALaes9dN/uncSFZ5DK5Q8BDGhEZOwMFOmvVX4OVZFKTlNUsGNi0Robkm3kEB2xKfQF0E2jRTR9ksEqHVJYz3Oh7RiuiZjWkMEk0TAxWgnKxGOahxzU6EH0EasUOqlgDofWNeuvK/iF2K7VaKeSBkni1CsGiKnvxEscUaKiIo0VVUaAADkBj4BcyLw3cx3AGpW+/MY5mZwdqdw5nFdYKdOFIYIh3KnlKCDzB7QcVooye9EC/0eRXE2S59PxsyqgqpqXAv/Wo9dNUl00lHPd6GNUHqUADt9g66JhWaWSRi8skxBkbcQpkLbV17hgE6DliFVzm/EsEFYEOMupIdyVgw5uT50rDsLdX4l1v11/8ABH8NBTcVh655fg4h9dhhVkrjKBQmP+ds0Z19u7zhjVLuV25J4k+YiGYDHbFmOcmnTk5h6uWLwFZfYz7+pQysCGUjUEHmDjJqX6On7MZNS/R0/ZjJqX6On7MZNS/R0/ZjJqX6On7MZPS+fgJ+zEKRRjXREUKo19gxHxK9iGSGVNSNySKVYaroRqDjJTWtxo6I/jViTRXGhG2R2H8RoONTtKFmiDsmoBDabkIIxlJq2J4RDK5sTS6pru00ldv8ENql3NTmNpR3wZWnHCn2NJt6qx2ZlXkjlGpCvOkfBYH50IODrJVpRidvXMw3yn8rk+Q9Jct4033U44fjGPZ5nA29mu7nr1zJFMRojuhkVT6yoZdfpxmAt24M9vVeKIxGNkG0AKq/xxleJmQqJE2lkJGm4bgw1HtBGOmXSQ51DEYorPGq6JGQRsEYg2bcStIyqAXbQMxA5naANT7BiNmWjmVa/F7XgbXYfWrqSp8msi18sr1slikC6b5z8PZPzg6AnHhk+50qSsHpm5lKcA/gaTQF8eHj/wCfkv8AYY6W/d+ITsvjfGqzbDoDw9aiRpj8as0/jznUl43c0uXh8GIVBtsGO4Anew059c8UM5HwcksZlRT6yishP0jHSCDMK9u9PeOlI15EmnI3dvFcbP8AWT//xAAUEQEAAAAAAAAAAAAAAAAAAACQ/9oACAECAQE/AA3/AP/EABQRAQAAAAAAAAAAAAAAAAAAAJD/2gAIAQMBAT8ADf8A/9k="
    }
   },
   "cell_type": "markdown",
   "id": "c6b93c46",
   "metadata": {},
   "source": [
    "![img_17.jpg](attachment:img_17.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127eb30",
   "metadata": {},
   "source": [
    "- Here we are using 'Log Loss/ Binary Cross entropy' loss function\n",
    "- Its Gradient function wrt weights and biases looks like :"
   ]
  },
  {
   "attachments": {
    "img_18.jpg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "65866984",
   "metadata": {},
   "source": [
    "![img_18.jpg.png](attachment:img_18.jpg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56b330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(nums):\n",
    "    nums = np.array(nums)    \n",
    "    for i in range(len(nums)):\n",
    "        nums[i] = 1/(math.exp(-nums[i])+1)\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a773dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Loss function\n",
    "def log_loss(y,_y):\n",
    "    y = list(y)\n",
    "    _y = list(_y)\n",
    "    \n",
    "    for i in range(len(_y)):\n",
    "        if _y[i] == 0: # making slightly bigger than zero\n",
    "            _y[i] = 1e-15\n",
    "        elif _y[i] == 1: # making slightly lesser than one\n",
    "            _y[i] = 1-1e-15\n",
    "    \n",
    "    loss_arr = []\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        loss_arr.append(y[i]*math.log(_y[i]) + (1 - y[i])*math.log(1 - _y[i]))\n",
    "    \n",
    "    loss = -np.mean(np.array(loss_arr))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f09902d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def prediction(x,weights,bias):\n",
    "    _y = x.iloc[:,0]*weights[0] + x.iloc[:,1]*weights[1] + bias\n",
    "    return sigmoid(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6912983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_of_weights(x,y,_y):\n",
    "    slopes = []\n",
    "    length = len(y)\n",
    "    for i in range(2):\n",
    "        slopes.append(sum((_y - y) * x.iloc[:,i])/length)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "954621d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_of_bias(y,_y):\n",
    "    return sum(_y - y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb21fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent function : updates the weights and biases\n",
    "def gradient_descent(x_train, y_train, epochs):\n",
    "    \n",
    "    weights = [1,1]\n",
    "    bias = 0\n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        _y = prediction(x_train,weights,bias)\n",
    "        loss = log_loss(y_train,_y)\n",
    "        \n",
    "        weight_slopes = slope_of_weights(x_train, y_train, _y)\n",
    "        bias_slopes = slope_of_bias(y_train, _y)\n",
    "        \n",
    "        for j in range(2):\n",
    "            weights[j] -= weight_slopes[j]*learning_rate\n",
    "        bias -= bias_slopes*learning_rate\n",
    "        \n",
    "        print(f'Epoch : {i}   loss = {loss}  weights = {weights} bias = {bias} ---->')\n",
    "        \n",
    "    return (weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca5756b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0   loss = 4.709905835436021  weights = [0.8136363636363636, 1.0] bias = -0.002272727272727273 ---->\n",
      "Epoch : 1   loss = 10.836965569240068  weights = [0.11136365919519231, 0.9886363644193947] bias = -0.027272726041946197 ---->\n",
      "Epoch : 2   loss = 1.8002279738044125  weights = [-0.5624879737132258, 0.9777508863432548] bias = -0.05105886404910974 ---->\n",
      "Epoch : 3   loss = 13.329804766850993  weights = [0.6556827763038551, 0.9982048910675946] bias = -0.026059458190583792 ---->\n",
      "Epoch : 4   loss = 9.424809878952711  weights = [-0.04658950167691467, 0.9868412691881141] bias = -0.05105943422463119 ---->\n",
      "Epoch : 5   loss = 1.075059227813082  weights = [0.7664467230924163, 0.9975215476106537] bias = -0.03890189788865259 ---->\n",
      "Epoch : 6   loss = 10.38813100979897  weights = [0.0641740529485838, 0.9861579131739192] bias = -0.06390189481673093 ---->\n",
      "Epoch : 7   loss = 1.1729001311017828  weights = [-0.5385891321547204, 0.9762493508160948] bias = -0.08521453312079051 ---->\n",
      "Epoch : 8   loss = 12.76524020769338  weights = [0.6795759608452042, 0.9967030831313115] bias = -0.060215428583495545 ---->\n",
      "Epoch : 9   loss = 9.618454993019883  weights = [-0.022696469577045186, 0.9853394564419274] bias = -0.08521541271649367 ---->\n",
      "Epoch : 10   loss = 0.7710240443083158  weights = [0.4324353833050689, 0.9898641179967369] bias = -0.08144545373325193 ---->\n",
      "Epoch : 11   loss = 6.258033310910964  weights = [-0.2698029571947731, 0.9785014604590047] bias = -0.10644367957734971 ---->\n",
      "Epoch : 12   loss = 6.229249464558572  weights = [0.945507589938225, 0.9988289235064518] bias = -0.08158985527724583 ---->\n",
      "Epoch : 13   loss = 12.015070511694647  weights = [0.24323486481141843, 0.9874652872199196] bias = -0.10658985516094335 ---->\n",
      "Epoch : 14   loss = 3.5890606434178096  weights = [-0.4573964057656107, 0.9761389122628894] bias = -0.1315107127932738 ---->\n",
      "Epoch : 15   loss = 10.810343995849665  weights = [0.7607113494923946, 0.9965899243673106] bias = -0.10651463637467196 ---->\n",
      "Epoch : 16   loss = 10.307598371704021  weights = [0.05843869028810855, 0.9852262902953551] bias = -0.1315146327157126 ---->\n",
      "Epoch : 17   loss = 1.0766492295319172  weights = [-0.5194315534560584, 0.975654097478667] bias = -0.1520320619438776 ---->\n",
      "Epoch : 18   loss = 12.332150249467798  weights = [0.6987278439477652, 0.9961075573333884] bias = -0.1270332596489016 ---->\n",
      "Epoch : 19   loss = 9.79834079692051  weights = [-0.0035446617248874324, 0.9847439282510687] bias = -0.15203324778630178 ---->\n",
      "Epoch : 20   loss = 0.6632621996639642  weights = [0.10094892755194991, 0.9839929569738243] bias = -0.15605982855518433 ---->\n",
      "Epoch : 21   loss = 1.5994843288762828  weights = [-0.5599644095008681, 0.9733084417873145] bias = -0.17933243289127604 ---->\n",
      "Epoch : 22   loss = 13.334274742587617  weights = [0.6582072424981046, 0.9937624910251555] bias = -0.1543329784588297 ---->\n",
      "Epoch : 23   loss = 9.39450394163679  weights = [-0.04406499642065975, 0.9823988704507305] bias = -0.17933295240210478 ---->\n",
      "Epoch : 24   loss = 1.0664337762585256  weights = [0.7776158600029608, 0.9933381284352271] bias = -0.16679165227517032 ---->\n",
      "Epoch : 25   loss = 10.437414665271532  weights = [0.07534318558266628, 0.9819744938646646] bias = -0.19179164943125504 ---->\n",
      "Epoch : 26   loss = 1.2535543930869462  weights = [-0.5447843235712293, 0.9718638174068618] bias = -0.21361225315330962 ---->\n",
      "Epoch : 27   loss = 12.982166606053175  weights = [0.6733844521505727, 0.9923177282374649] bias = -0.18861295191788446 ---->\n",
      "Epoch : 28   loss = 9.489652612113174  weights = [-0.028887894951525772, 0.9809541042528518] bias = -0.21361293160666886 ---->\n",
      "Epoch : 29   loss = 0.8531845794351912  weights = [0.59066173716574, 0.9883207663989362] bias = -0.20585906952336241 ---->\n",
      "Epoch : 30   loss = 8.417968336958607  weights = [-0.11160914053326154, 0.9769571881311755] bias = -0.2308589715087169 ---->\n",
      "Epoch : 31   loss = 2.4962029249601962  weights = [1.0423840376903157, 0.9951632878402654] bias = -0.20868191232978936 ---->\n",
      "Epoch : 32   loss = 12.851732589256864  weights = [0.3401113108263729, 0.9837996514918073] bias = -0.2336819123075702 ---->\n",
      "Epoch : 33   loss = 4.884021449456363  weights = [-0.361909201735486, 0.9724426052252715] bias = -0.2586692386754913 ---->\n",
      "Epoch : 34   loss = 8.549364788604448  weights = [0.8558667040918625, 0.9928783745774546] bias = -0.23369038571881412 ---->\n",
      "Epoch : 35   loss = 11.128427357390906  weights = [0.15359399000990015, 0.9815147386743438] bias = -0.2586903850062931 ---->\n",
      "Epoch : 36   loss = 2.263362695639978  weights = [-0.5352797995383801, 0.970404539636735] bias = -0.28308392000659177 ---->\n",
      "Epoch : 37   loss = 12.78593622304109  weights = [0.6828874920104998, 0.9908583797179863] bias = -0.258084697445613 ---->\n",
      "Epoch : 38   loss = 9.566586056334751  weights = [-0.01938489408860411, 0.9794947545146222] bias = -0.2830846792034393 ---->\n",
      "Epoch : 39   loss = 0.7572727523282208  weights = [0.4601666821268928, 0.9845839979403754] bias = -0.27844531679233303 ---->\n",
      "Epoch : 40   loss = 6.54782231087043  weights = [-0.24208161862206956, 0.9732210732974768] bias = -0.30344404868952407 ---->\n",
      "Epoch : 41   loss = 5.6557206122632655  weights = [0.972025049182458, 0.9934986667719389] bias = -0.27864957023197207 ---->\n",
      "Epoch : 42   loss = 12.176721260818589  weights = [0.2697523235164839, 0.9821350304666524] bias = -0.3036495701448116 ---->\n",
      "Epoch : 43   loss = 3.8613050034771588  weights = [-0.4313732037252703, 0.970798685856322] bias = -0.32859352802186964 ---->\n",
      "Epoch : 44   loss = 10.277076642125405  weights = [0.7867092142717876, 0.9912485260180387] bias = -0.30359877253389306 ---->\n",
      "Epoch : 45   loss = 10.464466744322657  weights = [0.08443653822039421, 0.9798848913994462] bias = -0.3285987697762982 ---->\n",
      "Epoch : 46   loss = 1.3066801551626281  weights = [-0.5446035246785461, 0.9696757782514226] bias = -0.3506790302523284 ---->\n",
      "Epoch : 47   loss = 13.04718840989682  weights = [0.6735669053633062, 0.9901297697145487] bias = -0.32567964036693564 ---->\n",
      "Epoch : 48   loss = 9.49004861938596  weights = [-0.028705386813645206, 0.9787661475319386] bias = -0.3506796171203404 ---->\n",
      "Epoch : 49   loss = 0.8743023089469826  weights = [0.6402058253807574, 0.9870943725920861] bias = -0.34156947224888706 ---->\n",
      "Epoch : 50   loss = 9.049117946833132  weights = [-0.0620660718063909, 0.9757307629267866] bias = -0.3665694280284173 ---->\n",
      "Epoch : 51   loss = 1.4607657557374467  weights = [0.9545746244183692, 0.9906568947642956] bias = -0.34872273918380003 ---->\n",
      "Epoch : 52   loss = 11.987185801724392  weights = [0.25230189952893245, 0.979293258486795] bias = -0.37372273905458286 ---->\n",
      "Epoch : 53   loss = 3.581125187505515  weights = [-0.4481960781561143, 0.967970738131723] bias = -0.3986367614749978 ---->\n",
      "Epoch : 54   loss = 10.72308759346197  weights = [0.769918671855975, 0.9884220945904011] bias = -0.37364030942754317 ---->\n",
      "Epoch : 55   loss = 10.281003331523321  weights = [0.06764601984033802, 0.977058460777312] bias = -0.3986403053796212 ---->\n",
      "Epoch : 56   loss = 1.0723207100505527  weights = [-0.5133528001263762, 0.9675209019225186] bias = -0.41910616002959217 ---->\n",
      "Epoch : 57   loss = 12.32091042507819  weights = [0.7048099084996936, 0.9879745240739214] bias = -0.3941071800547469 ---->\n",
      "Epoch : 58   loss = 9.743079321066652  weights = [0.0025374407449146874, 0.9766108962862282] bias = -0.41910716615481836 ---->\n",
      "Epoch : 59   loss = 0.6300788044328498  weights = [0.10792600249874662, 0.976106861003268] bias = -0.42268617602922764 ---->\n",
      "Epoch : 60   loss = 1.5661377126858118  weights = [-0.5495182494920482, 0.9655016700802654] bias = -0.4457881951440799 ---->\n",
      "Epoch : 61   loss = 13.21618903255477  weights = [0.6686541617338254, 0.9859557576541853] bias = -0.4207886993827012 ---->\n",
      "Epoch : 62   loss = 9.394941017828238  weights = [-0.033618039406459466, 0.9745921384316595] bias = -0.44578867128241867 ---->\n",
      "Epoch : 63   loss = 0.9659930200689213  weights = [0.7405278548365651, 0.984868397830409] bias = -0.43404840697407515 ---->\n",
      "Epoch : 64   loss = 9.985622191551442  weights = [0.03825526624630038, 0.9735047661206262] bias = -0.4590483995276707 ---->\n",
      "Epoch : 65   loss = 0.7515996567175409  weights = [-0.36562368306777454, 0.9662777287417518] bias = -0.47452479343398984 ---->\n",
      "Epoch : 66   loss = 8.750205511418006  weights = [0.8522552456154222, 0.9867182532649078] bias = -0.44954058471043573 ---->\n",
      "Epoch : 67   loss = 11.005565250063537  weights = [0.14998253591461597, 0.9753546175153485] bias = -0.47454058376134495 ---->\n",
      "Epoch : 68   loss = 2.10750632408925  weights = [-0.534360538003771, 0.9643290884348295] bias = -0.498732412417111 ---->\n",
      "Epoch : 69   loss = 12.873846458224596  weights = [0.6838094322357244, 0.9847830590348168] bias = -0.47373304641351127 ---->\n",
      "Epoch : 70   loss = 9.467020458568186  weights = [-0.018462877497580688, 0.9734194363678558] bias = -0.4987330240850004 ---->\n",
      "Epoch : 71   loss = 0.7729213461863207  weights = [0.5367587388714649, 0.9799447507422877] bias = -0.49202810713702216 ---->\n",
      "Epoch : 72   loss = 7.515728872015966  weights = [-0.16550707384901608, 0.9685813262696253] bias = -0.5170277432731213 ---->\n",
      "Epoch : 73   loss = 3.9099783231598106  weights = [1.0371773410920744, 0.988414995742133] bias = -0.4927753876552317 ---->\n",
      "Epoch : 74   loss = 12.686180730458318  weights = [0.33490461441984076, 0.9770513594008056] bias = -0.5177753876225945 ---->\n",
      "Epoch : 75   loss = 4.6674319486402736  weights = [-0.3669946774525047, 0.9656974552789008] bias = -0.5427566545482138 ---->\n",
      "Epoch : 76   loss = 8.817932599175371  weights = [0.8509117474731412, 0.9861392467159237] bias = -0.517771016275937 ---->\n",
      "Epoch : 77   loss = 10.96518545822071  weights = [0.14863903949519508, 0.9747756110263942] bias = -0.5427710152338463 ---->\n",
      "Epoch : 78   loss = 2.0560554500122907  weights = [-0.5339064923909446, 0.9637831839705694] bias = -0.5668832887886284 ---->\n",
      "Epoch : 79   loss = 12.897082278420354  weights = [0.6842641689441308, 0.9842371881818052] bias = -0.5418838857710826 ---->\n",
      "Epoch : 80   loss = 9.443191847004796  weights = [-0.018008114996580393, 0.972873566366835] bias = -0.5668838620622746 ---->\n",
      "Epoch : 81   loss = 0.7773754467083076  weights = [0.557148298255529, 0.9797892530085226] bias = -0.5596186953932085 ---->\n",
      "Epoch : 82   loss = 7.768241835419692  weights = [-0.145119418520549, 0.9684257719142492] bias = -0.5846184309636772 ---->\n",
      "Epoch : 83   loss = 3.453525265143922  weights = [1.050778160279711, 0.988018335344104] bias = -0.5606692695503814 ---->\n",
      "Epoch : 84   loss = 12.78322719115302  weights = [0.34850543350736085, 0.9766546989991395] bias = -0.5856692695231759 ---->\n",
      "Epoch : 85   loss = 4.824355888742173  weights = [-0.3534636153043954, 0.965299102494609] bias = -0.6106539642651104 ---->\n",
      "Epoch : 86   loss = 8.522438980472312  weights = [0.8643838262167721, 0.9857382438026996] bias = -0.5856713533547641 ---->\n",
      "Epoch : 87   loss = 11.061015292126712  weights = [0.16211111503155473, 0.9743746080038689] bias = -0.6106713524853876 ---->\n",
      "Epoch : 88   loss = 2.207581691110903  weights = [-0.5245434660623756, 0.963314586536791] bias = -0.634958951304279 ---->\n",
      "Epoch : 89   loss = 12.703195782687978  weights = [0.6936259269479337, 0.9837685304373627] bias = -0.6099596154209931 ---->\n",
      "Epoch : 90   loss = 9.5196243144808  weights = [-0.008646402124443564, 0.9724049071943955] bias = -0.634959594110072 ---->\n",
      "Epoch : 91   loss = 0.6909598327949701  weights = [0.41989562460023494, 0.9769831395099775] bias = -0.6309186088637743 ---->\n",
      "Epoch : 92   loss = 5.804286206801199  weights = [-0.2823003780900775, 0.9656216780862348] bias = -0.6559146614495454 ---->\n",
      "Epoch : 93   loss = 6.812113488329336  weights = [0.9345943817699895, 0.9860188943614694] bias = -0.6309804374594732 ---->\n",
      "Epoch : 94   loss = 11.687205638909525  weights = [0.23232165908354818, 0.9746552581627513] bias = -0.6559804372109673 ---->\n",
      "Epoch : 95   loss = 3.1600452919449937  weights = [-0.4663641958094913, 0.9633721412142384] bias = -0.680808496792151 ---->\n",
      "Epoch : 96   loss = 11.308662974253757  weights = [0.7517819653508064, 0.9838249838136] bias = -0.6558103881311366 ---->\n",
      "Epoch : 97   loss = 9.997997441337622  weights = [0.04950937845934267, 0.9724613521832246] bias = -0.6808103805880988 ---->\n",
      "Epoch : 98   loss = 0.776761147024055  weights = [-0.3983742869081808, 0.9647854277000713] bias = -0.6972068704899346 ---->\n",
      "Epoch : 99   loss = 9.659899891624782  weights = [0.8196787832468311, 0.9852339446658908] bias = -0.6722136250101851 ---->\n",
      "Epoch : 100   loss = 10.615023377056417  weights = [0.11740609621936637, 0.9738703096931692] bias = -0.6972136228396925 ---->\n",
      "Epoch : 101   loss = 1.5635934326173924  weights = [-0.5386473711078129, 0.9633143516700006] bias = -0.7202242594097845 ---->\n",
      "Epoch : 102   loss = 13.089447034274007  weights = [0.6795256959210062, 0.9837684721891384] bias = -0.6952247279217678 ---->\n",
      "Epoch : 103   loss = 9.392138004085028  weights = [-0.022746466285206046, 0.9724048543359176] bias = -0.7202246977141072 ---->\n",
      "Epoch : 104   loss = 0.8661906810548436  weights = [0.6893899297659976, 0.9817941901094637] bias = -0.7095721254643588 ---->\n",
      "Epoch : 105   loss = 9.439530957627282  weights = [-0.012882320633265776, 0.9704305694436647] bias = -0.7345720999508101 ---->\n",
      "Epoch : 106   loss = 0.7438302973614795  weights = [0.5396106771689071, 0.9771153803116593] bias = -0.7275683866410801 ---->\n",
      "Epoch : 107   loss = 7.437377282197985  weights = [-0.16265375080266675, 0.9657519989887047] bias = -0.7525679497090242 ---->\n",
      "Epoch : 108   loss = 3.956931339856172  weights = [1.042429536062882, 0.9856831282530584] bias = -0.7281986043493367 ---->\n",
      "Epoch : 109   loss = 12.637496589669974  weights = [0.34015680948123084, 0.9743194919151618] bias = -0.7531986043117699 ---->\n",
      "Epoch : 110   loss = 4.622921894534621  weights = [-0.3616905870385746, 0.962967024343059] bias = -0.7781772278965307 ---->\n",
      "Epoch : 111   loss = 8.807496402484492  weights = [0.8562505664513694, 0.9834104497662529] bias = -0.7531897649134816 ---->\n",
      "Epoch : 112   loss = 10.917277663734179  weights = [0.15397786133049884, 0.9720468141787684] bias = -0.7781897637167698 ---->\n",
      "Epoch : 113   loss = 2.014933190786454  weights = [-0.5263441764917267, 0.9611032941580574] bias = -0.8021969916193283 ---->\n",
      "Epoch : 114   loss = 12.831588837063435  weights = [0.6918275004671912, 0.9815573485515703] bias = -0.7771975337713126 ---->\n",
      "Epoch : 115   loss = 9.434193532747384  weights = [-0.010444739313350992, 0.970193728252937] bias = -0.8021975076846408 ---->\n",
      "Epoch : 116   loss = 0.7266170871768046  weights = [0.5255146669091939, 0.9766637734322521] bias = -0.7954663698962149 ---->\n",
      "Epoch : 117   loss = 7.205333907655688  weights = [-0.1767464202450556, 0.9653004920000676] bias = -0.8204657583773599 ---->\n",
      "Epoch : 118   loss = 4.330584741958759  weights = [1.032287859230947, 0.9853819598192991] bias = -0.7959116648401965 ---->\n",
      "Epoch : 119   loss = 12.516614012861663  weights = [0.3300151328498262, 0.9740183234887684] bias = -0.8209116647917418 ---->\n",
      "Epoch : 120   loss = 4.446684951023681  weights = [-0.371698730389463, 0.9626691918789182] bias = -0.8458836778438492 ---->\n",
      "Epoch : 121   loss = 9.08524883848661  weights = [0.8462978233468017, 0.9831151449800554] bias = -0.8208933483765078 ---->\n",
      "Epoch : 122   loss = 10.798129392696765  weights = [0.1440251245916424, 0.9717515096122159] bias = -0.845893346836568 ---->\n",
      "Epoch : 123   loss = 1.8478240556247423  weights = [-0.5290955081145223, 0.9609336310738565] bias = -0.8695897867883536 ---->\n",
      "Epoch : 124   loss = 12.932385868907039  weights = [0.6890773094831537, 0.9813877404519697] bias = -0.8445902681174215 ---->\n",
      "Epoch : 125   loss = 9.36290331011619  weights = [-0.013194868633834012, 0.9700241221661544] bias = -0.8695902387372325 ---->\n",
      "Epoch : 126   loss = 0.7685955224659005  weights = [0.5998544624766791, 0.977837926703212] bias = -0.8610055457039614 ---->\n",
      "Epoch : 127   loss = 8.216925562083738  weights = [-0.10241525526191575, 0.9664743857094287] bias = -0.8860053860313153 ---->\n",
      "Epoch : 128   loss = 2.582901608201694  weights = [1.071772356531411, 0.9854075549228876] bias = -0.8629080188066416 ---->\n",
      "Epoch : 129   loss = 12.851692606900524  weights = [0.3694996297194162, 0.9740439185765712] bias = -0.8879080187815775 ---->\n",
      "Epoch : 130   loss = 4.967483881650622  weights = [-0.3325032574225326, 0.96268759690123] bias = -0.9128943267563172 ---->\n",
      "Epoch : 131   loss = 8.16399331750227  weights = [0.8853075830405921, 0.9831252052302458] bias = -0.8879135306134278 ---->\n",
      "Epoch : 132   loss = 11.12889500546365  weights = [0.18303487055996714, 0.9717615693902153] bias = -0.912913529813351 ---->\n",
      "Epoch : 133   loss = 2.3477453215027784  weights = [-0.505979727827673, 0.9606689455853099] bias = -0.9372982660625505 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 134   loss = 12.403168163094232  weights = [0.7121890898179444, 0.9811228643660723] bias = -0.9122989593406138 ---->\n",
      "Epoch : 135   loss = 9.59728900753984  weights = [0.00991674358925887, 0.9697592406657749] bias = -0.9372989389192387 ---->\n",
      "Epoch : 136   loss = 0.5855569282785326  weights = [0.20260922090094705, 0.9709976723486099] bias = -0.9380734714552806 ---->\n",
      "Epoch : 137   loss = 2.6058984717088784  weights = [-0.49073941808701294, 0.9598240290795748] bias = -0.9626534489669429 ---->\n",
      "Epoch : 138   loss = 12.044886153828939  weights = [0.7274255070408536, 0.9802777631794888] bias = -0.9376543480353937 ---->\n",
      "Epoch : 139   loss = 9.65825504852958  weights = [0.025153073769952905, 0.9689141366489382] bias = -0.9626543322620883 ---->\n",
      "Epoch : 140   loss = 0.5676141504856365  weights = [-0.05459778439204756, 0.9663111836669763] bias = -0.9695976856048427 ---->\n",
      "Epoch : 141   loss = 1.5351081500858073  weights = [1.0124513911301949, 0.9826555402529251] bias = -0.9498476659552308 ---->\n",
      "Epoch : 142   loss = 12.270862553314338  weights = [0.31017866535928906, 0.9712919039447504] bias = -0.9748476658736558 ---->\n",
      "Epoch : 143   loss = 4.090898000815624  weights = [-0.39111701739333693, 0.9599530440134019] bias = -0.9997990998552048 ---->\n",
      "Epoch : 144   loss = 9.636338468091097  weights = [0.8269558547573903, 0.9804025033058859] bias = -0.9748048077740752 ---->\n",
      "Epoch : 145   loss = 10.55695479514616  weights = [0.12468317520606864, 0.9690388685988212] bias = -0.9998048051993486 ---->\n",
      "Epoch : 146   loss = 1.5191804731716994  weights = [-0.52594566619523, 0.9586031466484473] bias = -1.0225587213813891 ---->\n",
      "Epoch : 147   loss = 12.93308123041864  weights = [0.6922279734813583, 0.9790572962122407] bias = -0.9975591585805733 ---->\n",
      "Epoch : 148   loss = 9.328724364973501  weights = [-0.010044149755509602, 0.9676936797771689] bias = -1.0225591262555316 ---->\n",
      "Epoch : 149   loss = 0.7569642811914593  weights = [0.609465816660279, 0.9757527843039244] bias = -1.0136028644566089 ---->\n",
      "Epoch : 150   loss = 8.275612350686208  weights = [-0.09280398504229193, 0.9643892411538911] bias = -1.0386027090703074 ---->\n",
      "Epoch : 151   loss = 2.428691670830712  weights = [1.076892842812488, 0.983222797303538] bias = -1.0156379701635876 ---->\n",
      "Epoch : 152   loss = 12.835791196045035  weights = [0.37462011602897083, 0.9718591609583342] bias = -1.0406379701369703 ---->\n",
      "Epoch : 153   loss = 4.96255685308493  weights = [-0.3273685375831433, 0.9605032732126332] bias = -1.0656235330161874 ---->\n",
      "Epoch : 154   loss = 8.116130358926224  weights = [0.890461839405062, 0.9809418137187663] bias = -1.0406417038725997 ---->\n",
      "Epoch : 155   loss = 11.113244208581595  weights = [0.18818912781794317, 0.9695781779117812] bias = -1.0656417030240035 ---->\n",
      "Epoch : 156   loss = 2.3438168862989808  weights = [-0.500321496000267, 0.9584996071794984] bias = -1.0900007180279792 ---->\n",
      "Epoch : 157   loss = 12.3425510863068  weights = [0.7178479282158273, 0.9789535561038935] bias = -1.0650013784747885 ---->\n",
      "Epoch : 158   loss = 9.586285257898151  weights = [0.015575600747208207, 0.9675899330683331] bias = -1.09000135703893 ---->\n",
      "Epoch : 159   loss = 0.5627705635549256  weights = [0.16488449782307138, 0.9683406597714704] bias = -1.091506249290379 ---->\n",
      "Epoch : 160   loss = 2.0121627452589657  weights = [-0.5140785228606187, 0.9574370045627514] bias = -1.115441649484267 ---->\n",
      "Epoch : 161   loss = 12.690874183861746  weights = [0.704093984680593, 0.9778911005391305] bias = -1.0904421464872491 ---->\n",
      "Epoch : 162   loss = 9.41784344429108  weights = [0.0018217883748730124, 0.9665274817862002] bias = -1.115442118046711 ---->\n",
      "Epoch : 163   loss = 0.6443163028891941  weights = [0.43876351440656675, 0.9716846481814044] bias = -1.1104570033917693 ---->\n",
      "Epoch : 164   loss = 5.828330665297051  weights = [-0.2634233967798883, 0.960323487516996] bias = -1.135452568083622 ---->\n",
      "Epoch : 165   loss = 6.593996481401939  weights = [0.9536024139157884, 0.9807271324691005] bias = -1.1105113152004606 ---->\n",
      "Epoch : 166   loss = 11.664356780012163  weights = [0.25132969187485865, 0.9693634962951337] bias = -1.1355113149167817 ---->\n",
      "Epoch : 167   loss = 3.186367860173505  weights = [-0.4470722553655655, 0.9580900226725271] bias = -1.1603239209158194 ---->\n",
      "Epoch : 168   loss = 11.080555452577018  weights = [0.7710778462769317, 0.9785430620763755] bias = -1.1353255983718988 ---->\n",
      "Epoch : 169   loss = 9.977802987435853  weights = [0.06880527771907596, 0.9671794311143245] bias = -1.160325589833474 ---->\n",
      "Epoch : 170   loss = 0.7960674689854685  weights = [-0.41490227028576065, 0.9592592380738151] bias = -1.177282545642743 ---->\n",
      "Epoch : 171   loss = 10.304805838902888  weights = [0.8032218167570374, 0.9797110675739633] bias = -1.1522855831236267 ---->\n",
      "Epoch : 172   loss = 10.266270283303525  weights = [0.10094917812754967, 0.9683474342619087] bias = -1.1772855783465943 ---->\n",
      "Epoch : 173   loss = 1.1433781125785694  weights = [-0.4986131620034122, 0.9587390846635431] bias = -1.1980397934019278 ---->\n",
      "Epoch : 174   loss = 12.354850463892905  weights = [0.7195571639041567, 0.9791930771921579] bias = -1.1730404056651127 ---->\n",
      "Epoch : 175   loss = 9.557835835602246  weights = [0.01728486796026063, 0.9678294552159347] bias = -1.1980403825363362 ---->\n",
      "Epoch : 176   loss = 0.5547003515093705  weights = [0.18082399900710525, 0.9688896373079812] bias = -1.199051902126322 ---->\n",
      "Epoch : 177   loss = 2.177834346895663  weights = [-0.5031301168323905, 0.9579003267330503] bias = -1.2232038860610481 ---->\n",
      "Epoch : 178   loss = 12.477823800378491  weights = [0.7150414190487411, 0.9783543770025454] bias = -1.1982044341782718 ---->\n",
      "Epoch : 179   loss = 9.505888151612877  weights = [0.012769173364431508, 0.9669907566792232] bias = -1.2232044083623934 ---->\n",
      "Epoch : 180   loss = 0.5741478903444254  weights = [0.2779826596583381, 0.9695889615705475] bias = -1.2218917216429601 ---->\n",
      "Epoch : 181   loss = 3.5161950607970467  weights = [-0.42186744496180417, 0.9582841537001736] bias = -1.2467729303383308 ---->\n",
      "Epoch : 182   loss = 10.509635767576032  weights = [0.7962672850867657, 0.9787364793939799] bias = -1.2217754107488212 ---->\n",
      "Epoch : 183   loss = 10.173765919024534  weights = [0.093994666032713, 0.9673728467476955] bias = -1.246775404918903 ---->\n",
      "Epoch : 184   loss = 1.0332367238823297  weights = [-0.4807877478410626, 0.9581596688459151] bias = -1.2666133057254974 ---->\n",
      "Epoch : 185   loss = 11.955086074796647  weights = [0.737379042227477, 0.9786134943776058] bias = -1.2416141044568043 ---->\n",
      "Epoch : 186   loss = 9.624921219347378  weights = [0.03510664606317815, 0.9672498691383966] bias = -1.2666140866806996 ---->\n",
      "Epoch : 187   loss = 0.5439124388065782  weights = [-0.08942404875709715, 0.96430535439406] bias = -1.2741413076184318 ---->\n",
      "Epoch : 188   loss = 2.458268604679096  weights = [1.0862025214360764, 0.9833481172092863] bias = -1.2509113130059937 ---->\n",
      "Epoch : 189   loss = 12.82497236209993  weights = [0.38392979468482735, 0.971984480865354] bias = -1.2759113129776145 ---->\n",
      "Epoch : 190   loss = 4.975722824193378  weights = [-0.3180444540300701, 0.9606290600211677] bias = -1.3008961024200925 ---->\n",
      "Epoch : 191   loss = 8.00652728268763  weights = [0.8998038400719165, 0.9810684799161701] bias = -1.2759133091286003 ---->\n",
      "Epoch : 192   loss = 11.102802250258613  weights = [0.19753112949114215, 0.9697048441467686] bias = -1.3009133082252382 ---->\n",
      "Epoch : 193   loss = 2.3578823059633542  weights = [-0.49060104499777624, 0.9586402435815058] bias = -1.3252505865668902 ---->\n",
      "Epoch : 194   loss = 12.223292277239892  weights = [0.7275689991691869, 0.979094223628351] bias = -1.3002512131794202 ---->\n",
      "Epoch : 195   loss = 9.579335787660192  weights = [0.02529669356639408, 0.9677306013750081] bias = -1.3252511905561641 ---->\n",
      "Epoch : 196   loss = 0.531279320273605  weights = [0.09061268484130407, 0.9674924885977495] bias = -1.3282856931609277 ---->\n",
      "Epoch : 197   loss = 0.963261083221779  weights = [-0.4646314788609925, 0.958598038240896] bias = -1.3474058779027775 ---->\n",
      "Epoch : 198   loss = 11.601681574763917  weights = [0.7535314970052414, 0.9790516846965955] bias = -1.3224068770746664 ---->\n",
      "Epoch : 199   loss = 9.74027805438414  weights = [0.05125903513297403, 0.9676880573038782] bias = -1.3474068628117641 ---->\n",
      "Epoch : 200   loss = 0.5996436083726046  weights = [-0.25552262359823913, 0.9623230663945683] bias = -1.3592945390896958 ---->\n",
      "Epoch : 201   loss = 6.512532340747568  weights = [0.9615744202932028, 0.982730065297853] bias = -1.334349529381434 ---->\n",
      "Epoch : 202   loss = 11.646440147806286  weights = [0.259301698661185, 0.9713664291391089] bias = -1.359349529075511 ---->\n",
      "Epoch : 203   loss = 3.1871001562156382  weights = [-0.43888642390421506, 0.9600991304407201] bias = -1.384151037954706 ---->\n",
      "Epoch : 204   loss = 10.9922083033552  weights = [0.7792656998083302, 0.9805522687825954] bias = -1.3591526064856183 ---->\n",
      "Epoch : 205   loss = 9.961873419279497  weights = [0.07699314274984204, 0.9691886382252689] bias = -1.3841525973245146 ---->\n",
      "Epoch : 206   loss = 0.8002216347334489  weights = [-0.4141770671506717, 0.9612605204183402] bias = -1.4011500105151682 ---->\n",
      "Epoch : 207   loss = 10.398240856235414  weights = [0.8039578670377798, 0.9817128602036577] bias = -1.376152477014858 ---->\n",
      "Epoch : 208   loss = 10.181901636636788  weights = [0.10168524900358222, 0.9703492275988146] bias = -1.4011524711278394 ---->\n",
      "Epoch : 209   loss = 1.0611872231304393  weights = [-0.4793199963612852, 0.9610786966110219] bias = -1.4211484022670748 ---->\n",
      "Epoch : 210   loss = 11.995397845015441  weights = [0.7388485474455281, 0.9815326061924011] bias = -1.3961491076569972 ---->\n",
      "Epoch : 211   loss = 9.575858569544145  weights = [0.03657619547063928, 0.9701689824308637] bias = -1.4211490875072337 ---->\n",
      "Epoch : 212   loss = 0.5255451787344504  weights = [-0.05471599314124989, 0.9678132832753686] bias = -1.4276587758808439 ---->\n",
      "Epoch : 213   loss = 1.726399916281227  weights = [1.062981571588708, 0.9854722249631543] bias = -1.4061961110878527 ---->\n",
      "Epoch : 214   loss = 12.548800283867417  weights = [0.36070884524850144, 0.9741085886344774] bias = -1.4311961110371343 ---->\n",
      "Epoch : 215   loss = 4.572670692551931  weights = [-0.34101051342218924, 0.9627598206488012] bias = -1.4561681108449982 ---->\n",
      "Epoch : 216   loss = 8.642673506703135  weights = [0.8769886182900126, 0.9832059941062018] bias = -1.431177586120898 ---->\n",
      "Epoch : 217   loss = 10.830285809423048  weights = [0.17471592072680708, 0.9718423587911623] bias = -1.4561775845145022 ---->\n",
      "Epoch : 218   loss = 1.9721051656976243  weights = [-0.5009873871777901, 0.9610156332863977] bias = -1.4799552075723614 ---->\n",
      "Epoch : 219   loss = 12.552718221828144  weights = [0.7171861251427332, 0.9814697788092129] bias = -1.454955650217056 ---->\n",
      "Epoch : 220   loss = 9.42125403473881  weights = [0.014913994789128138, 0.9701061623200611] bias = -1.4799556182150586 ---->\n",
      "Epoch : 221   loss = 0.5729030796257489  weights = [0.3514944958767488, 0.9740274273497495] bias = -1.476652622460807 ---->\n",
      "Epoch : 222   loss = 4.420647541221625  weights = [-0.3500815968599669, 0.962682327232806] bias = -1.5016174788218253 ---->\n",
      "Epoch : 223   loss = 8.88639700738406  weights = [0.8679539083307235, 0.9831301425884788] bias = -1.4766250824949139 ---->\n",
      "Epoch : 224   loss = 10.728721261719185  weights = [0.16568121781974943, 0.971766507518313] bias = -1.501625080507939 ---->\n",
      "Epoch : 225   loss = 1.8291229408887277  weights = [-0.5030341534276123, 0.9610689570419907] bias = -1.5250942703625114 ---->\n",
      "Epoch : 226   loss = 12.6251318984619  weights = [0.7151400261776192, 0.9815231345197599] bias = -1.50009467755263 ---->\n",
      "Epoch : 227   loss = 9.384013343605575  weights = [0.012867947753449904, 0.9701595197415523] bias = -1.5250946427716183 ---->\n",
      "Epoch : 228   loss = 0.5915524751310497  weights = [0.4106156620659332, 0.9750711825244012] bias = -1.520363604004734 ---->\n",
      "Epoch : 229   loss = 5.2289392718919965  weights = [-0.29143279358887947, 0.9637138607515664] bias = -1.545352092307207 ---->\n",
      "Epoch : 230   loss = 7.479245754075593  weights = [0.9263068152459464, 0.9841486056052864] bias = -1.5203747525957727 ---->\n",
      "Epoch : 231   loss = 11.246840979164366  weights = [0.22403410099916254, 0.9727849697090524] bias = -1.5453747518901562 ---->\n",
      "Epoch : 232   loss = 2.6049724745814364  weights = [-0.46801122087556934, 0.9616486708019482] bias = -1.5698873803914875 ---->\n",
      "Epoch : 233   loss = 11.794012212967077  weights = [0.7501564124393039, 0.9821025386612424] bias = -1.544888132967699 ---->\n",
      "Epoch : 234   loss = 9.61896705284155  weights = [0.04788403759754345, 0.970738914181023] bias = -1.5698881140322445 ---->\n",
      "Epoch : 235   loss = 0.5361204342721358  weights = [-0.1544330202180176, 0.9669802748499785] bias = -1.5788451118092919 ---->\n",
      "Epoch : 236   loss = 4.163162245058999  weights = [1.056749328298106, 0.9871570973287369] bias = -1.55417995122859 ---->\n",
      "Epoch : 237   loss = 12.431412090648053  weights = [0.35447660223672484, 0.9757934610104] bias = -1.5791799511627183 ---->\n",
      "Epoch : 238   loss = 4.411700808265396  weights = [-0.34707002577368273, 0.9644491918224632] bias = -1.6041432869200054 ---->\n",
      "Epoch : 239   loss = 8.863557880535874  weights = [0.8709715439589449, 0.9848972925188386] bias = -1.5791505708599312 ---->\n",
      "Epoch : 240   loss = 10.714887935530147  weights = [0.16869885515702, 0.9735336575093696] bias = -1.6041505687803617 ---->\n",
      "Epoch : 241   loss = 1.8217560970506264  weights = [-0.49899545277930424, 0.9628611859822346] bias = -1.6275695990088346 ---->\n",
      "Epoch : 242   loss = 12.577238742585546  weights = [0.7191789121540922, 0.9833153726566222] bias = -1.602569996116719 ---->\n",
      "Epoch : 243   loss = 9.379583283659205  weights = [0.016906850663232054, 0.9719517584618778] bias = -1.627569960418612 ---->\n",
      "Epoch : 244   loss = 0.5697399195193726  weights = [0.3787726968114596, 0.9763987420767233] bias = -1.6234834774637936 ---->\n",
      "Epoch : 245   loss = 4.7306773364182435  weights = [-0.32303320237067207, 0.9650478663533502] bias = -1.648459726192278 ---->\n",
      "Epoch : 246   loss = 8.29992284670398  weights = [0.8949340248322297, 0.9854926513391403] bias = -1.6234708110035674 ---->\n",
      "Epoch : 247   loss = 10.91691148005935  weights = [0.19266132334480346, 0.9741290158905002] bias = -1.6484708096084022 ---->\n",
      "Epoch : 248   loss = 2.124152850941091  weights = [-0.48782697987405443, 0.9632222176752263] bias = -1.6724547593057826 ---->\n",
      "Epoch : 249   loss = 12.32743044211076  weights = [0.7303460332491574, 0.9836763403771172] bias = -1.6474552277479475 ---->\n",
      "Epoch : 250   loss = 9.463837549191318  weights = [0.028073870891861308, 0.9723127229042335] bias = -1.6724551974352198 ---->\n",
      "Epoch : 251   loss = 0.5132400436853074  weights = [0.1883768569430948, 0.9737734197008105] bias = -1.6727985435833184 ---->\n",
      "Epoch : 252   loss = 2.0542328391609925  weights = [-0.4895102042241779, 0.9629171923533981] bias = -1.6966650171799915 ---->\n",
      "Epoch : 253   loss = 12.380669308813788  weights = [0.7286632912733484, 0.9833713380664931] bias = -1.671665460058348 ---->\n",
      "Epoch : 254   loss = 9.438413447888179  weights = [0.026391161376750127, 0.9720077216682607] bias = -1.6966654280073146 ---->\n",
      "Epoch : 255   loss = 0.5194499154580972  weights = [0.22997562230456203, 0.9741304700791692] bias = -1.6959993433746314 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 256   loss = 2.6136690766475565  weights = [-0.4618504688918613, 0.9630015553513078] bias = -1.7204999382207506 ---->\n",
      "Epoch : 257   loss = 11.718666226208551  weights = [0.7563176157597723, 0.9834554457236742] bias = -1.695500666207201 ---->\n",
      "Epoch : 258   loss = 9.614231376227183  weights = [0.054045253379310765, 0.9720918216862912] bias = -1.7205006465951156 ---->\n",
      "Epoch : 259   loss = 0.5352450381257514  weights = [-0.1784425600331051, 0.9680387413353678] bias = -1.7299953171086326 ---->\n",
      "Epoch : 260   loss = 4.820059167213346  weights = [1.0361123043192078, 0.9883444180149256] bias = -1.7051725682185062 ---->\n",
      "Epoch : 261   loss = 12.18040619527361  weights = [0.33383957910516215, 0.9769807817277472] bias = -1.7301725681066185 ---->\n",
      "Epoch : 262   loss = 4.047168414733292  weights = [-0.3671553022282814, 0.9656504379868174] bias = -1.7551085032081766 ---->\n",
      "Epoch : 263   loss = 9.427839003929485  weights = [0.8509447617605832, 0.9861011964913364] bias = -1.7301127670155394 ---->\n",
      "Epoch : 264   loss = 10.469522089417953  weights = [0.1486720993061289, 0.9747375623923312] bias = -1.7551127635147665 ---->\n",
      "Epoch : 265   loss = 1.4900625291781844  weights = [-0.4934930323237444, 0.9645304472429849] bias = -1.7774254752968326 ---->\n",
      "Epoch : 266   loss = 12.517424480263964  weights = [0.7246816557554444, 0.9849846498555976] bias = -1.7524258549176581 ---->\n",
      "Epoch : 267   loss = 9.369183219466318  weights = [0.022409625500335095, 0.9736210367364677] bias = -1.7774258175312747 ---->\n",
      "Epoch : 268   loss = 0.5433185414137323  weights = [0.34011127223004356, 0.977530843183303] bias = -1.7740968707026348 ---->\n",
      "Epoch : 269   loss = 4.113319966409554  weights = [-0.3609855144164902, 0.966198059188741] bias = -1.7990377848881194 ---->\n",
      "Epoch : 270   loss = 9.299267786317623  weights = [0.8571080815006071, 0.9866485273327896] bias = -1.7740423803059961 ---->\n",
      "Epoch : 271   loss = 10.508265808796656  weights = [0.1548354146164218, 0.9752848930831891] bias = -1.7990423770436141 ---->\n",
      "Epoch : 272   loss = 1.5499548715579612  weights = [-0.4924591130608825, 0.9649931152318635] bias = -1.8215675500270838 ---->\n",
      "Epoch : 273   loss = 12.514116029111547  weights = [0.7257157452751278, 0.9854473260969006] bias = -1.7965679205333738 ---->\n",
      "Epoch : 274   loss = 9.360725095744668  weights = [0.023443732315361898, 0.9740837135599861] bias = -1.8215678822168102 ---->\n",
      "Epoch : 275   loss = 0.5396798288965857  weights = [0.3398930505644007, 0.9780160104052619] bias = -1.8182017510888022 ---->\n",
      "Epoch : 276   loss = 4.0883711087904535  weights = [-0.3611458761722019, 0.9666847304131214] bias = -1.8431397641920737 ---->\n",
      "Epoch : 277   loss = 9.32502248093931  weights = [0.8569517504371278, 0.9871353843623232] bias = -1.8181441498203421 ---->\n",
      "Epoch : 278   loss = 10.488899367943533  weights = [0.15467908643947437, 0.9757717502132589] bias = -1.8431441464020615 ---->\n",
      "Epoch : 279   loss = 1.528212290914046  weights = [-0.49027379013739547, 0.9655262014685753] bias = -1.8655653082192372 ---->\n",
      "Epoch : 280   loss = 12.48265439622381  weights = [0.7279010833008377, 0.9859804132145064] bias = -1.8405656778153106 ---->\n",
      "Epoch : 281   loss = 9.362912549440221  weights = [0.025629072334871772, 0.9746168007597391] bias = -1.8655656393863498 ---->\n",
      "Epoch : 282   loss = 0.5290929115973293  weights = [0.3178172736666654, 0.9782226690948581] bias = -1.8626728582820713 ---->\n",
      "Epoch : 283   loss = 3.7568918193354848  weights = [-0.3824406156002947, 0.9669105050459605] bias = -1.8875724536384393 ---->\n",
      "Epoch : 284   loss = 9.865931843271639  weights = [0.8356878515824908, 0.987362565121371] bias = -1.8625752444555475 ---->\n",
      "Epoch : 285   loss = 10.275533446475787  weights = [0.13341522246222137, 0.9759989321668802] bias = -1.8875752391581362 ---->\n",
      "Epoch : 286   loss = 1.241448696857052  weights = [-0.47692395270795107, 0.9663572679848367] bias = -1.9085558921735064 ---->\n",
      "Epoch : 287   loss = 12.178560838456667  weights = [0.7412492924667181, 0.9868114027902727] bias = -1.8835563475981618 ---->\n",
      "Epoch : 288   loss = 9.46807500549685  weights = [0.03897714751196446, 0.9754477859586671] bias = -1.908556316330446 ---->\n",
      "Epoch : 289   loss = 0.4833139496831143  weights = [0.09577187014276319, 0.9756340877123221] bias = -1.9108886178270363 ---->\n",
      "Epoch : 290   loss = 0.8089492812992752  weights = [-0.4039550494844453, 0.9677981907326022] bias = -1.927773904309367 ---->\n",
      "Epoch : 291   loss = 10.409819045412481  weights = [0.8141928767830424, 0.9882511456909437] bias = -1.9027756842327053 ---->\n",
      "Epoch : 292   loss = 10.061926870468822  weights = [0.11192030178092394, 0.9768875145735957] bias = -1.9277756760229794 ---->\n",
      "Epoch : 293   loss = 0.9740479241172618  weights = [-0.4435599714015399, 0.9681650636575483] bias = -1.9466218785206528 ---->\n",
      "Epoch : 294   loss = 11.383993745029938  weights = [0.7746062573251864, 0.9886188687596072] bias = -1.9216227026361357 ---->\n",
      "Epoch : 295   loss = 9.690823345129802  weights = [0.07233385425323269, 0.9772552434021061] bias = -1.946622685193415 ---->\n",
      "Epoch : 296   loss = 0.5947948725111042  weights = [-0.28226875731804346, 0.9716273465717145] bias = -1.9590490365482605 ---->\n",
      "Epoch : 297   loss = 7.459495320011038  weights = [0.9355599116369046, 0.9920661382623441] bias = -1.9340670895574084 ---->\n",
      "Epoch : 298   loss = 11.164363027930888  weights = [0.23328720088068378, 0.9807025024915694] bias = -1.9590670886624977 ---->\n",
      "Epoch : 299   loss = 2.532232772693882  weights = [-0.456450036082679, 0.9696216886468765] bias = -1.983467146387548 ---->\n",
      "Epoch : 300   loss = 11.715865321061306  weights = [0.7617200124897866, 0.9900756731035066] bias = -1.95846776979712 ---->\n",
      "Epoch : 301   loss = 9.557762411871037  weights = [0.059447712589543955, 0.9787120511699173] bias = -1.9834677468210822 ---->\n",
      "Epoch : 302   loss = 0.5120496108803564  weights = [-0.159764663133631, 0.9750523897491695] bias = -1.9922680341532106 ---->\n",
      "Epoch : 303   loss = 4.493750891191298  weights = [1.0542347978221964, 0.9953391224289468] bias = -1.9674693329467747 ---->\n",
      "Epoch : 304   loss = 12.241088997819555  weights = [0.35196207245698274, 0.9839754861363986] bias = -1.9924693328430618 ---->\n",
      "Epoch : 305   loss = 4.17202443657539  weights = [-0.34916285789486445, 0.9726422719993072] bias = -2.0174114378217634 ---->\n",
      "Epoch : 306   loss = 9.117776789595892  weights = [0.868929226082982, 0.9930926861493599] bias = -1.9924161007303476 ---->\n",
      "Epoch : 307   loss = 10.528935294128885  weights = [0.16665655889738928, 0.9817290518930339] bias = -2.0174160974828528 ---->\n",
      "Epoch : 308   loss = 1.6060546246577603  weights = [-0.4834521746150713, 0.9714079730435847] bias = -2.040042801567305 ---->\n",
      "Epoch : 309   loss = 12.401287307163221  weights = [0.734722971402759, 0.9918621982201018] bias = -2.015043156341348 ---->\n",
      "Epoch : 310   loss = 9.355509538070384  weights = [0.03245099213073965, 0.980498586833066] bias = -2.0400431161964376 ---->\n",
      "Epoch : 311   loss = 0.5011485110371758  weights = [0.26492079198658247, 0.9833631446384474] bias = -2.038225991589267 ---->\n",
      "Epoch : 312   loss = 2.932257388119463  weights = [-0.43030998293472555, 0.9721664677469856] bias = -2.0628832254700726 ---->\n",
      "Epoch : 313   loss = 11.117672023035727  weights = [0.7878538977731019, 0.9926201641817689] bias = -2.0378841717434195 ---->\n",
      "Epoch : 314   loss = 9.765808610552263  weights = [0.08558145429849573, 0.9812565374858744] bias = -2.062884156463904 ---->\n",
      "Epoch : 315   loss = 0.6676973164356657  weights = [-0.3380460651456062, 0.974664451734771] bias = -2.0772055752863734 ---->\n",
      "Epoch : 316   loss = 8.876016870960672  weights = [0.8800306056182977, 0.9951141771028507] bias = -2.0522110260171007 ---->\n",
      "Epoch : 317   loss = 10.606863937266342  weights = [0.17775793020237407, 0.9837505425636165] bias = -2.0772110232132177 ---->\n",
      "Epoch : 318   loss = 1.724488131894212  weights = [-0.4806658639576179, 0.9732821210878458] bias = -2.100195945625936 ---->\n",
      "Epoch : 319   loss = 12.362712479812783  weights = [0.73750931983938, 0.9937363482329054] bias = -2.075196298260188 ---->\n",
      "Epoch : 320   loss = 9.356911128740732  weights = [0.035237345756321536, 0.9823727370282663] bias = -2.100196257830267 ---->\n",
      "Epoch : 321   loss = 0.4907439171207752  weights = [0.23925160716529428, 0.984869527388357] bias = -2.0989270995543765 ---->\n",
      "Epoch : 322   loss = 2.5471850542741037  weights = [-0.45036521671204277, 0.9737939727457788] bias = -2.123319585103248 ---->\n",
      "Epoch : 323   loss = 11.635836109266869  weights = [0.7678050681175327, 0.9942479691182688] bias = -2.09832019545534 ---->\n",
      "Epoch : 324   loss = 9.557370192971057  weights = [0.0655327784889761, 0.9828843475421053] bias = -2.1233201719197408 ---->\n",
      "Epoch : 325   loss = 0.5154360000915471  weights = [-0.18241549593034134, 0.978922727664216] bias = -2.1326675879919255 ---->\n",
      "Epoch : 326   loss = 5.112395034240407  weights = [1.033506585982535, 0.9992838412417505] bias = -2.1077783806747474 ---->\n",
      "Epoch : 327   loss = 11.994267036293534  weights = [0.33123386191684656, 0.9879202049966951] bias = -2.13277838050048 ---->\n",
      "Epoch : 328   loss = 3.812478154102477  weights = [-0.3690406840413213, 0.9766082212176044] bias = -2.157678334895093 ---->\n",
      "Epoch : 329   loss = 9.67054619866922  weights = [0.8490879142140185, 0.9970602964703292] bias = -2.132681111829646 ---->\n",
      "Epoch : 330   loss = 10.290276565578402  weights = [0.14681528659150878, 0.9856966635720914] bias = -2.157681106448712 ---->\n",
      "Epoch : 331   loss = 1.2938004418671445  weights = [-0.46803322481788734, 0.9760194456994578] bias = -2.1787980910888267 ---->\n",
      "Epoch : 332   loss = 12.09311794976495  weights = [0.7501407806049036, 0.9964736173831641] bias = -2.1537985056276736 ---->\n",
      "Epoch : 333   loss = 9.372990289213318  weights = [0.047868695735624245, 0.9851100025607258] bias = -2.178798471117968 ---->\n",
      "Epoch : 334   loss = 0.46299818931182296  weights = [0.05659656088435201, 0.9848461121734127] bias = -2.18184305949459 ---->\n",
      "Epoch : 335   loss = 0.47293622790543766  weights = [-0.06533403742432331, 0.9827279491920416] bias = -2.187967808207724 ---->\n",
      "Epoch : 336   loss = 2.3116127892817904  weights = [1.116952358574598, 1.0020961490404825] bias = -2.1643239760048427 ---->\n",
      "Epoch : 337   loss = 12.737918290174514  weights = [0.41467963203084657, 0.9907325127044874] bias = -2.1893239759651513 ---->\n",
      "Epoch : 338   loss = 4.955280179527266  weights = [-0.28719271130655943, 0.9793801084724504] bias = -2.2143034094061216 ---->\n",
      "Epoch : 339   loss = 7.703811040481133  weights = [0.93073918436752, 0.9998234626724274] bias = -2.189316204398509 ---->\n",
      "Epoch : 340   loss = 11.017442560625557  weights = [0.2284664802846147, 0.9884598271375876] bias = -2.214316203142334 ---->\n",
      "Epoch : 341   loss = 2.343690966454796  weights = [-0.4561992725500005, 0.9774895759667326] bias = -2.2384768380774696 ---->\n",
      "Epoch : 342   loss = 11.834039282557848  weights = [0.761973316755043, 0.9979436811909956] bias = -2.213477326913682 ---->\n",
      "Epoch : 343   loss = 9.457554423858834  weights = [0.05970113573894953, 0.9865800632176579] bias = -2.2384772975483656 ---->\n",
      "Epoch : 344   loss = 0.4741025256968717  weights = [-0.08567523946808384, 0.9841761488279052] bias = -2.2450933648306286 ---->\n",
      "Epoch : 345   loss = 2.8232707277787186  weights = [1.1135551174377558, 1.003998638606023] bias = -2.2208773919523206 ---->\n",
      "Epoch : 346   loss = 12.68406671632942  weights = [0.41128239098507724, 0.9926350022734302] bias = -2.245877391907675 ---->\n",
      "Epoch : 347   loss = 4.879773280032764  weights = [-0.29053785507298535, 0.9812840120558896] bias = -2.2708541703823304 ---->\n",
      "Epoch : 348   loss = 7.812778434681723  weights = [0.927422523712043, 1.0017286214699594] bias = -2.2458655177910556 ---->\n",
      "Epoch : 349   loss = 10.964288907670294  weights = [0.22514982249861992, 0.9903649860360038] bias = -2.2708655163796347 ---->\n",
      "Epoch : 350   loss = 2.2714984402531537  weights = [-0.4572609347074692, 0.9794425023343747] bias = -2.294920875283716 ---->\n",
      "Epoch : 351   loss = 11.887327623528797  weights = [0.7609123205110822, 0.9998966391250368] bias = -2.2699213289241893 ---->\n",
      "Epoch : 352   loss = 9.425165722336493  weights = [0.05864018206517074, 0.9885330225619257] bias = -2.2949212972730813 ---->\n",
      "Epoch : 353   loss = 0.46445509451593003  weights = [-0.054573474484430826, 0.9866344051658397] bias = -2.300677820014851 ---->\n",
      "Epoch : 354   loss = 2.1096440097344935  weights = [1.118253902135386, 1.0057924424311833] bias = -2.2772957083912297 ---->\n",
      "Epoch : 355   loss = 12.704535257828718  weights = [0.41598117565750226, 0.9944288060976627] bias = -2.3022957083479523 ---->\n",
      "Epoch : 356   loss = 4.9179519216371474  weights = [-0.2858555743924247, 0.9830773932253534] bias = -2.327273307648304 ---->\n",
      "Epoch : 357   loss = 7.726185418908921  weights = [0.9320962728965638, 1.0035216428031926] bias = -2.302285077430833 ---->\n",
      "Epoch : 358   loss = 10.984529263277313  weights = [0.22982357088287397, 0.9921580073415482] bias = -2.3272850760625605 ---->\n",
      "Epoch : 359   loss = 2.3085530395447957  weights = [-0.4534233908251326, 0.9812201354487898] bias = -2.351377786530438 ---->\n",
      "Epoch : 360   loss = 11.821332503044044  weights = [0.7647497074373071, 1.0016742650953063] bias = -2.3263782482263995 ---->\n",
      "Epoch : 361   loss = 9.437707895748273  weights = [0.062477559503130164, 0.9903106482284163] bias = -2.351378217078846 ---->\n",
      "Epoch : 362   loss = 0.467587357017058  weights = [-0.08371708837545219, 0.9879885679657274] bias = -2.3578595917516387 ---->\n",
      "Epoch : 363   loss = 2.82943976201108  weights = [1.116489650032231, 1.0078473230686558] bias = -2.333598169597219 ---->\n",
      "Epoch : 364   loss = 12.665779371455322  weights = [0.4142169236268898, 0.9964836867378447] bias = -2.358598169549995 ---->\n",
      "Epoch : 365   loss = 4.865529939682601  weights = [-0.2875788630379299, 0.9851333900230629] bias = -2.383573676111884 ---->\n",
      "Epoch : 366   loss = 7.795460225637054  weights = [0.9303924780928476, 1.0055785009559455] bias = -2.3585844536089353 ---->\n",
      "Epoch : 367   loss = 10.94632123062513  weights = [0.22811977836079067, 0.9942148655744973] bias = -2.383584452117189 ---->\n",
      "Epoch : 368   loss = 2.2586658926712606  weights = [-0.4534013159388752, 0.9833141333824948] bias = -2.4075961992347095 ---->\n",
      "Epoch : 369   loss = 11.848046764707863  weights = [0.7647722400586423, 1.003768284771688] bias = -2.3825966366985654 ---->\n",
      "Epoch : 370   loss = 9.415392302775956  weights = [0.06250012458094878, 0.9924046689806487] bias = -2.407596603806728 ---->\n",
      "Epoch : 371   loss = 0.4607311616580734  weights = [-0.06656953950314512, 0.9903738719380648] bias = -2.4135829527751302 ---->\n",
      "Epoch : 372   loss = 2.445315690294195  weights = [1.1236173294664402, 1.0099713980860472] bias = -2.3896493763240807 ---->\n",
      "Epoch : 373   loss = 12.708726096524158  weights = [0.4213446029972425, 0.9986077617528656] bias = -2.414649376280327 ---->\n",
      "Epoch : 374   loss = 4.938059208458633  weights = [-0.28049019772069705, 0.9872564349303273] bias = -2.4396268469045954 ---->\n",
      "Epoch : 375   loss = 7.64993160411965  weights = [0.9374621848940796, 1.0077007322986615] bias = -2.4146385722831125 ---->\n",
      "Epoch : 376   loss = 10.988785217537485  weights = [0.23518948314468902, 0.9963370968467743] bias = -2.439638570900332 ---->\n",
      "Epoch : 377   loss = 2.3286568721039953  weights = [-0.44815379700328006, 0.9854004223806406] bias = -2.4637333902242653 ---->\n",
      "Epoch : 378   loss = 11.747413636866025  weights = [0.7700193729337115, 1.0058545558490484] bias = -2.438733847771341 ---->\n",
      "Epoch : 379   loss = 9.441079422766508  weights = [0.06774723168611352, 0.9944909392151257] bias = -2.4637338162560614 ---->\n",
      "Epoch : 380   loss = 0.4696044893984483  weights = [-0.10974471166424926, 0.991809434741594] bias = -2.470840267725876 ---->\n",
      "Epoch : 381   loss = 3.5108769400483073  weights = [1.1002003853473101, 1.0119643508992016] bias = -2.4462072845143146 ---->\n",
      "Epoch : 382   loss = 12.471100376357594  weights = [0.3979276593808233, 1.0006007145846862] bias = -2.471207284443227 ---->\n",
      "Epoch : 383   loss = 4.581632658462279  weights = [-0.3036108813161179, 0.9892572856042662] bias = -2.496169745997405 ---->\n",
      "Epoch : 384   loss = 8.240595342731835  weights = [0.9144333804532127, 1.009705611125895] bias = -2.4711768198030595 ---->\n",
      "Epoch : 385   loss = 10.75466498736026  weights = [0.21216069448141484, 0.9983419762250245] bias = -2.4961768175673518 ---->\n",
      "Epoch : 386   loss = 1.9901276595758035  weights = [-0.4583527188935749, 0.9876678455685942] bias = -2.5196814765774334 ---->\n",
      "Epoch : 387   loss = 12.022940922654993  weights = [0.7598223509441223, 1.0081220685920027] bias = -2.494681834158766 ---->\n",
      "Epoch : 388   loss = 9.325079928664856  weights = [0.057550372259040916, 0.9967584573107986] bias = -2.5196817939262854 ---->\n",
      "Epoch : 389   loss = 0.44281928958479005  weights = [0.03574662691911881, 0.9963565294562987] bias = -2.522959161131277 ---->\n",
      "Epoch : 390   loss = 0.5155455813503447  weights = [0.4068613754294724, 1.0017240633751245] bias = -2.5174405983528367 ---->\n",
      "Epoch : 391   loss = 4.684158602266621  weights = [-0.2947672095561935, 0.9903782876392224] bias = -2.542407585039861 ---->\n",
      "Epoch : 392   loss = 8.047810811411976  weights = [0.9232580947724196, 1.0108257860450944] bias = -2.517415615399419 ---->\n",
      "Epoch : 393   loss = 10.817030588894504  weights = [0.22098540421116597, 0.9994621509851015] bias = -2.5424156134115448 ---->\n",
      "Epoch : 394   loss = 2.0872503424308175  weights = [-0.4535541870565293, 0.9887096334821251] bias = -2.566102208855379 ---->\n",
      "Epoch : 395   loss = 11.928815748063021  weights = [0.7646205664161162, 1.0091638417808357] bias = -2.5411025829355696 ---->\n",
      "Epoch : 396   loss = 9.350382697294414  weights = [0.062348555673501505, 0.9978002294601473] bias = -2.5661025444154864 ---->\n",
      "Epoch : 397   loss = 0.44396361131983486  weights = [-0.013904524205266791, 0.9966598892333339] bias = -2.570601114433263 ---->\n",
      "Epoch : 398   loss = 1.306338038358205  weights = [1.0504261707135507, 1.0136606002755255] bias = -2.5498705234025323 ---->\n",
      "Epoch : 399   loss = 11.972029714559689  weights = [0.34815344705926154, 1.0022969640457697] bias = -2.5748705232058535 ---->\n",
      "Epoch : 400   loss = 3.8325479324537826  weights = [-0.3519306775593336, 0.9909906350806792] bias = -2.599760337111762 ---->\n",
      "Epoch : 401   loss = 9.468836181676117  weights = [0.8662028611951806, 1.011442950318425] bias = -2.5747628477684334 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 402   loss = 10.269840101382746  weights = [0.16393024575960424, 1.0000793178471399] bias = -2.5997628417259273 ---->\n",
      "Epoch : 403   loss = 1.3206465134673282  weights = [-0.4488742726127929, 0.9905067993080351] bias = -2.6207286057483925 ---->\n",
      "Epoch : 404   loss = 11.84137427823058  weights = [0.7693002211566081, 1.0109609955857455] bias = -2.5957289933101517 ---->\n",
      "Epoch : 405   loss = 9.371411685337158  weights = [0.067028186609566, 0.9995973824918535] bias = -2.620728956060346 ---->\n",
      "Epoch : 406   loss = 0.4478353020313191  weights = [-0.05475080383973137, 0.9978488024040207] bias = -2.6262514572895626 ---->\n",
      "Epoch : 407   loss = 2.2631967590423345  weights = [1.1301628864545503, 1.0173443183931006] bias = -2.6024430056687042 ---->\n",
      "Epoch : 408   loss = 12.683450457494871  weights = [0.4278901600587358, 1.0059806820626898] bias = -2.6274430056209517 ---->\n",
      "Epoch : 409   loss = 4.925311699142971  weights = [-0.2739081927031174, 0.9946304062634583] bias = -2.652418565404735 ---->\n",
      "Epoch : 410   loss = 7.592931786062281  weights = [0.9440608862530787, 1.0150754742885888] bias = -2.6274294179456796 ---->\n",
      "Epoch : 411   loss = 10.963998522969998  weights = [0.24178818679577418, 1.0037118389182256] bias = -2.652429416438506 ---->\n",
      "Epoch : 412   loss = 2.317957842929638  weights = [-0.44031600884539246, 0.9928073329066659] bias = -2.6764621648449407 ---->\n",
      "Epoch : 413   loss = 11.659790389658086  weights = [0.7778576374691651, 1.0132614896032661] bias = -2.651462596684321 ---->\n",
      "Epoch : 414   loss = 9.427706979455392  weights = [0.07558553370615606, 1.0018978742341078] bias = -2.676462563140956 ---->\n",
      "Epoch : 415   loss = 0.46892455196702515  weights = [-0.13050704210341788, 0.9989670805833973] bias = -2.6840190810361078 ---->\n",
      "Epoch : 416   loss = 4.1168090879172885  weights = [1.0835638799494414, 1.01926389725132] bias = -2.6592100336379083 ---->\n",
      "Epoch : 417   loss = 12.232847190692253  weights = [0.38129115486117404, 1.0079002609692118] bias = -2.6842100335190824 ---->\n",
      "Epoch : 418   loss = 4.243653799249433  weights = [-0.31972466772925234, 0.996570578814779] bias = -2.709146085984421 ---->\n",
      "Epoch : 419   loss = 8.736624834303026  weights = [0.8983756159156174, 1.0170214059541836] bias = -2.684150295833468 ---->\n",
      "Epoch : 420   loss = 10.521762865923906  weights = [0.1961029571203876, 1.0056577719960538] bias = -2.7091502921291393 ---->\n",
      "Epoch : 421   loss = 1.68117104347929  weights = [-0.45351255853685724, 0.995407445230398] bias = -2.731705554989167 ---->\n",
      "Epoch : 422   loss = 12.007862086704245  weights = [0.7646632322865422, 1.015861702838197] bias = -2.7067058741510097 ---->\n",
      "Epoch : 423   loss = 9.284550019244309  weights = [0.062391346461848074, 1.004498094636365] bias = -2.731705828918633 ---->\n",
      "Epoch : 424   loss = 0.43168680214110755  weights = [0.04062360310804948, 1.004278129472761] bias = -2.7346981457270823 ---->\n",
      "Epoch : 425   loss = 0.5024372343749619  weights = [0.4039571656846724, 1.0096984884344278] bias = -2.7290890470217777 ---->\n",
      "Epoch : 426   loss = 4.539555216116583  weights = [-0.29747683252620666, 0.9983579658631507] bias = -2.7540461014419244 ---->\n",
      "Epoch : 427   loss = 8.216345470584768  weights = [0.9205840706709849, 1.0188070537724323] bias = -2.729052310303331 ---->\n",
      "Epoch : 428   loss = 10.707713515869816  weights = [0.21831139081952666, 1.0074434190864265] bias = -2.7540523077360035 ---->\n",
      "Epoch : 429   loss = 1.9535431436216428  weights = [-0.4485927387113098, 0.9968553931998144] bias = -2.777382871178575 ---->\n",
      "Epoch : 430   loss = 11.910244018949088  weights = [0.7695827474842563, 1.0173096366120702] bias = -2.7523832062251077 ---->\n",
      "Epoch : 431   loss = 9.311362967089073  weights = [0.06731082302697566, 1.005946027153015] bias = -2.7773831630577535 ---->\n",
      "Epoch : 432   loss = 0.4332875864017726  weights = [-0.00943798929241818, 1.0049745387839712] bias = -2.7816140225067425 ---->\n",
      "Epoch : 433   loss = 1.296163033201575  weights = [1.056570003492338, 1.0220835192757476] bias = -2.7607308068596055 ---->\n",
      "Epoch : 434   loss = 11.944093606770059  weights = [0.354297280186879, 1.0107198830587782] bias = -2.785730806643952 ---->\n",
      "Epoch : 435   loss = 3.81551936525013  weights = [-0.3456003995159086, 0.9994186184108845] bias = -2.810611015676347 ---->\n",
      "Epoch : 436   loss = 9.416581184504956  weights = [0.8725368629144804, 1.019871108726188] bias = -2.7856133297467776 ---->\n",
      "Epoch : 437   loss = 10.243656195791921  weights = [0.17026425777041498, 1.008507476609494] bias = -2.8106133231471007 ---->\n",
      "Epoch : 438   loss = 1.311639992760369  weights = [-0.43825070254942244, 0.9990454712658198] bias = -2.8313682960521898 ---->\n",
      "Epoch : 439   loss = 11.684372216778325  weights = [0.779923794324715, 1.0194996683972222] bias = -2.8063686828329617 ---->\n",
      "Epoch : 440   loss = 9.384725233110279  weights = [0.07765176484061476, 1.0081360554911263] bias = -2.8313686452917874 ---->\n",
      "Epoch : 441   loss = 0.4550383088405368  weights = [-0.1091430517188463, 1.0056071577999133] bias = -2.8382380776927807 ---->\n",
      "Epoch : 442   loss = 3.6721370262827095  weights = [1.103153356191164, 1.0258470425037147] bias = -2.813500187285877 ---->\n",
      "Epoch : 443   loss = 12.351077193384446  weights = [0.40088063068792223, 1.0144834062063848] bias = -2.8385001871895867 ---->\n",
      "Epoch : 444   loss = 4.442881796886659  weights = [-0.30040081880239977, 1.00314695470807] bias = -2.8634494783179623 ---->\n",
      "Epoch : 445   loss = 8.34030838122388  weights = [0.9176782542758984, 1.0235968530317465] bias = -2.838454758453965 ---->\n",
      "Epoch : 446   loss = 10.63736608250325  weights = [0.21540558265869902, 1.012233218631698] bias = -2.8634547554413166 ---->\n",
      "Epoch : 447   loss = 1.865201265427791  weights = [-0.44563759572903905, 1.001769251505189] bias = -2.8865144870411545 ---->\n",
      "Epoch : 448   loss = 11.890801263680062  weights = [0.772538189729794, 1.022223509275711] bias = -2.861514806117517 ---->\n",
      "Epoch : 449   loss = 9.294971388770243  weights = [0.070266307271875, 1.010859901202313] bias = -2.8865147606865853 ---->\n",
      "Epoch : 450   loss = 0.4288575778521487  weights = [-0.012048433155049276, 1.0098959242306138] bias = -2.890738774353709 ---->\n",
      "Epoch : 451   loss = 1.3972014597118676  weights = [1.081509738097951, 1.027562151268919] bias = -2.8691643512684615 ---->\n",
      "Epoch : 452   loss = 12.129971620763781  weights = [0.37923701360826256, 1.0161985150088033] bias = -2.8941643511170962 ---->\n",
      "Epoch : 453   loss = 4.112067565727437  weights = [-0.32142979959077544, 1.0048780171403275] bias = -2.919082715311154 ---->\n",
      "Epoch : 454   loss = 8.879720189413398  weights = [0.8966876248927412, 1.0253296206258806] bias = -2.894086041749533 ---->\n",
      "Epoch : 455   loss = 10.422269494746939  weights = [0.1944149843167554, 1.0139659872968092] bias = -2.919086037060351 ---->\n",
      "Epoch : 456   loss = 1.567556787721869  weights = [-0.44296094651607365, 1.0039719934838518] bias = -2.941083869605082 ---->\n",
      "Epoch : 457   loss = 11.851971912609478  weights = [0.7752148483855009, 1.0244262518487348] bias = -2.916084188054674 ---->\n",
      "Epoch : 458   loss = 9.29772477147942  weights = [0.0729429687189509, 1.0130626438736685] bias = -2.941084142467792 ---->\n",
      "Epoch : 459   loss = 0.42898834849543643  weights = [-0.027475596993618706, 1.0118806209071531] bias = -2.945674958656277 ---->\n",
      "Epoch : 460   loss = 1.768724650994406  weights = [1.1257543083669477, 1.0307376553404755] bias = -2.922643520525765 ---->\n",
      "Epoch : 461   loss = 12.515085552219404  weights = [0.42348158239214706, 1.0193740190257419] bias = -2.9476435204551032 ---->\n",
      "Epoch : 462   loss = 4.706574095196516  weights = [-0.2780844448868852, 1.0080300957763937] bias = -2.9726071591003898 ---->\n",
      "Epoch : 463   loss = 7.8492229343209425  weights = [0.9399535310132353, 1.0284782060925337] bias = -2.9476145071255475 ---->\n",
      "Epoch : 464   loss = 10.798346692605516  weights = [0.237680844719792, 1.0171145711832836] bias = -2.9726145049057244 ---->\n",
      "Epoch : 465   loss = 2.1125777034676956  weights = [-0.43531021838621287, 1.0064120298946413] bias = -2.9962165398836573 ---->\n",
      "Epoch : 466   loss = 11.69214110573434  weights = [0.7828649892036775, 1.0268662608552346] bias = -2.9712168889707047 ---->\n",
      "Epoch : 467   loss = 9.345967157070092  weights = [0.0805930373596927, 1.0155026505141542] bias = -2.99621684724904 ---->\n",
      "Epoch : 468   loss = 0.44421657816648  weights = [-0.0939466495955587, 1.0132785358925882] bias = -3.0025726898090874 ---->\n",
      "Epoch : 469   loss = 3.3820225635134715  weights = [1.1168292723961646, 1.033475221969962] bias = -2.9778889573228753 ---->\n",
      "Epoch : 470   loss = 12.411146417601536  weights = [0.41455654673677556, 1.022111585666891] bias = -3.002888957235062 ---->\n",
      "Epoch : 471   loss = 4.554402990299639  weights = [-0.2868277986388147, 1.0107725171191915] bias = -3.0278433535739415 ---->\n",
      "Epoch : 472   loss = 8.088709555154141  weights = [0.9312392880204999, 1.0312219037023485] bias = -3.002849229045006 ---->\n",
      "Epoch : 473   loss = 10.696361748363573  weights = [0.22896661153939768, 1.0198582691341944] bias = -3.0278492262945567 ---->\n",
      "Epoch : 474   loss = 1.9705808365738642  weights = [-0.4368107802212532, 1.0093075293304674] bias = -3.0511176445911143 ---->\n",
      "Epoch : 475   loss = 11.754965737162443  weights = [0.781364941441418, 1.0297617845374778] bias = -3.0261179666132607 ---->\n",
      "Epoch : 476   loss = 9.310392602066761  weights = [0.0790930550981781, 1.0183981763467378] bias = -3.051117921372535 ---->\n",
      "Epoch : 477   loss = 0.43305148021425893  weights = [-0.06397475186857038, 1.0166783470447855] bias = -3.0566178587621926 ---->\n",
      "Epoch : 478   loss = 2.6837045148817484  weights = [1.1376569915343069, 1.036627028631505] bias = -3.0322425396019463 ---->\n",
      "Epoch : 479   loss = 12.58082706612978  weights = [0.4353842654204938, 1.0252633923116126] bias = -3.0572425395388407 ---->\n",
      "Epoch : 480   loss = 4.820206453579779  weights = [-0.26626602207276406, 1.0139172376942762] bias = -3.08221042480538 ---->\n",
      "Epoch : 481   loss = 7.613696383718027  weights = [0.9517518823354284, 1.03436449303355] bias = -3.05721876962286 ---->\n",
      "Epoch : 482   loss = 10.863176835175066  weights = [0.24947919168710297, 1.0230008579722722] bias = -3.082218767638288 ---->\n",
      "Epoch : 483   loss = 2.221166079550836  weights = [-0.42721216169287224, 1.0122241922531436] bias = -3.105989397936891 ---->\n",
      "Epoch : 484   loss = 11.547352073416  weights = [0.7909627057537681, 1.0326784075927802] bias = -3.0809897645216195 ---->\n",
      "Epoch : 485   loss = 9.37673274027284  weights = [0.08869072000926204, 1.0213147961346984] bias = -3.105989724608944 ---->\n",
      "Epoch : 486   loss = 0.46186125955731844  weights = [-0.13894362209978514, 1.0183731883921732] bias = -3.1135926091632466 ---->\n",
      "Epoch : 487   loss = 4.527488077682938  weights = [1.0769862810461672, 1.0387394918969093] bias = -3.0886986016672475 ---->\n",
      "Epoch : 488   loss = 12.001165938590702  weights = [0.37471355751260516, 1.027375855671649] bias = -3.1136986014639274 ---->\n",
      "Epoch : 489   loss = 3.9418831397896583  weights = [-0.32538793621683926, 1.0160700024096043] bias = -3.1385884143146163 ---->\n",
      "Epoch : 490   loss = 9.081312543099209  weights = [0.8927455600160714, 1.0365223332306095] bias = -3.113590913096141 ---->\n",
      "Epoch : 491   loss = 10.298820512767263  weights = [0.1904729480810068, 1.025158700881967] bias = -3.1385909068595623 ---->\n",
      "Epoch : 492   loss = 1.4253965390899792  weights = [-0.4284208558802476, 1.015544801910807] bias = -3.1597575124506614 ---->\n",
      "Epoch : 493   loss = 11.602325364241553  weights = [0.7897545067408083, 1.0359990405539097] bias = -3.1347578529932636 ---->\n",
      "Epoch : 494   loss = 9.344397987999345  weights = [0.0874825781475771, 1.0246354309685635] bias = -3.1597578100087786 ---->\n",
      "Epoch : 495   loss = 0.44903195747049857  weights = [-0.11592168701300298, 1.022096144511068] bias = -3.1666621086965363 ---->\n",
      "Epoch : 496   loss = 3.9927983973121726  weights = [1.0986055329027566, 1.042414361409412] bias = -3.1418274929180723 ---->\n",
      "Epoch : 497   loss = 12.178783133133056  weights = [0.3963328082719756, 1.0310507251441032] bias = -3.1668274927743463 ---->\n",
      "Epoch : 498   loss = 4.219118208273152  weights = [-0.3044499473500565, 1.0197274816612425] bias = -3.1917513980619123 ---->\n",
      "Epoch : 499   loss = 8.596293613742331  weights = [0.9136625481549597, 1.0401788787219066] bias = -3.166754964906406 ---->\n",
      "Epoch : 500   loss = 10.46995861068275  weights = [0.21138990325349705, 1.028815245243015] bias = -3.191754960449085 ---->\n",
      "Epoch : 501   loss = 1.6673178290834143  weights = [-0.4320079999626032, 1.0187272999753414] bias = -3.214001818135443 ---->\n",
      "Epoch : 502   loss = 11.715540693785522  weights = [0.7861680923519752, 1.0391815729289458] bias = -3.1890021203655357 ---->\n",
      "Epoch : 503   loss = 9.290000760391202  weights = [0.08389626481177237, 1.0278179666532279] bias = -3.214002071953522 ---->\n",
      "Epoch : 504   loss = 0.4295961129555009  weights = [-0.06896810456051, 1.0260712218396522] bias = -3.219552789776895 ---->\n",
      "Epoch : 505   loss = 2.8798697851457704  weights = [1.137019517046476, 1.046142388306139] bias = -3.195024839256581 ---->\n",
      "Epoch : 506   loss = 12.510563163114119  weights = [0.4347467911447003, 1.0347787519940832] bias = -3.220024839181938 ---->\n",
      "Epoch : 507   loss = 4.7321432320280925  weights = [-0.266788412470611, 1.0234357297054546] bias = -3.244986798954997 ---->\n",
      "Epoch : 508   loss = 7.703892624883861  weights = [0.9512544082522962, 1.0438840830921858] bias = -3.219993877279163 ---->\n",
      "Epoch : 509   loss = 10.79418267040636  weights = [0.24898172421047093, 1.0325204482603738] bias = -3.2449938749368874 ---->\n",
      "Epoch : 510   loss = 2.1394351319114318  weights = [-0.42343252573444035, 1.021840092784108] bias = -3.268561110369688 ---->\n",
      "Epoch : 511   loss = 11.532617897330494  weights = [0.7947428867654639, 1.042294334035918] bias = -3.243561448018948 ---->\n",
      "Epoch : 512   loss = 9.347120585064744  weights = [0.0924709678206147, 1.030930724759278] bias = -3.268561404506623 ---->\n",
      "Epoch : 513   loss = 0.4552187138091924  weights = [-0.13156145222509935, 1.028151624400817] bias = -3.27588607806653 ---->\n",
      "Epoch : 514   loss = 4.4247854593552525  weights = [1.0843364448926913, 1.0485177588480106] bias = -3.2509924481908747 ---->\n",
      "Epoch : 515   loss = 12.004486820734291  weights = [0.3820637214362045, 1.0371541226254786] bias = -3.275992447983349 ---->\n",
      "Epoch : 516   loss = 3.9662226047893285  weights = [-0.31801540134720074, 1.0258490207719018] bias = -3.3008809022036463 ---->\n",
      "Epoch : 517   loss = 8.97883597714788  weights = [0.9001185423615501, 1.0463013765677267] bias = -3.275883373808334 ---->\n",
      "Epoch : 518   loss = 10.302348014308807  weights = [0.1978459326957971, 1.0349377442940557] bias = -3.3008833674479403 ---->\n",
      "Epoch : 519   loss = 1.4498613397921827  weights = [-0.4217293214316199, 1.0253293546042466] bias = -3.322064648971915 ---->\n",
      "Epoch : 520   loss = 11.5164458703009  weights = [0.7964462039737715, 1.0457836012570976] bias = -3.297064980583736 ---->\n",
      "Epoch : 521   loss = 9.341665359647388  weights = [0.09417430106055047, 1.0344199924981192] bias = -3.3220649362061434 ---->\n",
      "Epoch : 522   loss = 0.4552465855697102  weights = [-0.13275433530709468, 1.0316307186814684] bias = -3.3294083738241724 ---->\n",
      "Epoch : 523   loss = 4.479030155149041  weights = [1.0833142670539408, 1.0520032057735318] bias = -3.304506984555174 ---->\n",
      "Epoch : 524   loss = 11.97400556134054  weights = [0.3810415438741903, 1.0406395695610076] bias = -3.3295069843326135 ---->\n",
      "Epoch : 525   loss = 3.9260665213218755  weights = [-0.31887528034707047, 1.0293386406360736] bias = -3.354387233764227 ---->\n",
      "Epoch : 526   loss = 9.025108143848819  weights = [0.8992617788220074, 1.0497911372554871] bias = -3.3293895450766295 ---->\n",
      "Epoch : 527   loss = 10.273385656734892  weights = [0.19698917732816967, 1.0384275052590588] bias = -3.3543895382747664 ---->\n",
      "Epoch : 528   loss = 1.4174024054814192  weights = [-0.4177353795279948, 1.028919501666351] bias = -3.375352908347966 ---->\n",
      "Epoch : 529   loss = 11.444314528339332  weights = [0.8004399775202857, 1.0493737405705377] bias = -3.350353248613146 ---->\n",
      "Epoch : 530   loss = 9.357351634006902  weights = [0.09816805562478925, 1.0380101311792171] bias = -3.3753532052500943 ---->\n",
      "Epoch : 531   loss = 0.4663559884717912  weights = [-0.1506492347615784, 1.0349150212452736] bias = -3.3832332039374022 ---->\n",
      "Epoch : 532   loss = 4.939894011848003  weights = [1.0661867951660322, 1.055315598242058] bias = -3.358297492785061 ---->\n",
      "Epoch : 533   loss = 11.795486753080741  weights = [0.36391407380142604, 1.0439519620951043] bias = -3.383297492463946 ---->\n",
      "Epoch : 534   loss = 3.660500115653384  weights = [-0.3348783737325396, 1.0326793062411614] bias = -3.408121572263335 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 535   loss = 9.440488246363948  weights = [0.8832723331658994, 1.0531324172052365] bias = -3.383123184769574 ---->\n",
      "Epoch : 536   loss = 10.105350947794728  weights = [0.18099978402924255, 1.0417687869838652] bias = -3.408123175142669 ---->\n",
      "Epoch : 537   loss = 1.204741943276936  weights = [-0.40039222393589147, 1.0329076460126874] bias = -3.427637751082634 ---->\n",
      "Epoch : 538   loss = 11.046285308840236  weights = [0.8177810105770793, 1.0533617861989413] bias = -3.4026382017917443 ---->\n",
      "Epoch : 539   loss = 9.496090715429442  weights = [0.11550889629147765, 1.0419981704674603] bias = -3.4276381687599677 ---->\n",
      "Epoch : 540   loss = 0.5626206417970232  weights = [-0.23915289109958976, 1.0372157932113428] bias = -3.438591777579221 ---->\n",
      "Epoch : 541   loss = 7.121818062411615  weights = [0.9788272558517537, 1.057661491541255] bias = -3.4136019557870267 ---->\n",
      "Epoch : 542   loss = 10.971279267430509  weights = [0.2765545598189231, 1.0462978562895937] bias = -3.4386019540932122 ---->\n",
      "Epoch : 543   loss = 2.423775295102754  weights = [-0.40505300880931905, 1.0354231366427271] bias = -3.4625957049095777 ---->\n",
      "Epoch : 544   loss = 11.17628785854967  weights = [0.813121213458783, 1.0558773228441352] bias = -3.437596104087055 ---->\n",
      "Epoch : 545   loss = 9.439576142002727  weights = [0.11084917741735711, 1.044513709682817] bias = -3.4625960668485494 ---->\n",
      "Epoch : 546   loss = 0.524031074422693  weights = [-0.21050596167105695, 1.0403036391456495] bias = -3.472482766726937 ---->\n",
      "Epoch : 547   loss = 6.4397025497975475  weights = [1.0073260173322023, 1.0607431576769666] bias = -3.447500215960058 ---->\n",
      "Epoch : 548   loss = 11.219782809881703  weights = [0.30505330911495887, 1.0493795219974449] bias = -3.472500214926045 ---->\n",
      "Epoch : 549   loss = 2.799172131036005  weights = [-0.38506696661590867, 1.03831328016855] bias = -3.4969001003988445 ---->\n",
      "Epoch : 550   loss = 10.705328397967703  weights = [0.8331040417738457, 1.0587673174907588] bias = -3.4719006664409355 ---->\n",
      "Epoch : 551   loss = 9.609677757060767  weights = [0.1308318069024782, 1.047403697761164] bias = -3.496900639889308 ---->\n",
      "Epoch : 552   loss = 0.6653855576710026  weights = [-0.2872413863949558, 1.0415530519600102] bias = -3.5099436289644173 ---->\n",
      "Epoch : 553   loss = 8.327200596239395  weights = [0.9308682466082819, 1.0620043376818913] bias = -3.484947327326574 ---->\n",
      "Epoch : 554   loss = 10.502728899860125  weights = [0.2285956005463915, 1.0506407041568975] bias = -3.5099473229304223 ---->\n",
      "Epoch : 555   loss = 1.7517229328435255  weights = [-0.4183485247624781, 1.0405034725304054] bias = -3.53233570625653 ---->\n",
      "Epoch : 556   loss = 11.533004481996437  weights = [0.7998277785101886, 1.060957755963451] bias = -3.5073359967406876 ---->\n",
      "Epoch : 557   loss = 9.29014320364409  weights = [0.09755599760793421, 1.0495941511436566] bias = -3.5323359457944052 ---->\n",
      "Epoch : 558   loss = 0.4413624868627851  weights = [-0.11198229143675129, 1.047202390306652] bias = -3.5389913355933027 ---->\n",
      "Epoch : 559   loss = 4.07194539052014  weights = [1.10336468698048, 1.067551696246821] bias = -3.5141186100775292 ---->\n",
      "Epoch : 560   loss = 12.075892196514895  weights = [0.4010919631610954, 1.0561880600108455] bias = -3.539118609889693 ---->\n",
      "Epoch : 561   loss = 4.105993088196549  weights = [-0.2992432420542992, 1.0448765759702598] bias = -3.5640195822793808 ---->\n",
      "Epoch : 562   loss = 8.645269451818349  weights = [0.9188844616118479, 1.0653286620078537] bias = -3.5390223636790648 ---->\n",
      "Epoch : 563   loss = 10.371329907487931  weights = [0.21661184112973353, 1.0539650293566967] bias = -3.5640223579008654 ---->\n",
      "Epoch : 564   loss = 1.5754482699963708  weights = [-0.4135113909410689, 1.0441733096975025] bias = -3.5856503059593856 ---->\n",
      "Epoch : 565   loss = 11.440310563746362  weights = [0.8046646720079177, 1.0646275820004034] bias = -3.560650608862574 ---->\n",
      "Epoch : 566   loss = 9.313578168675617  weights = [0.10239285490192052, 1.0532639759863605] bias = -3.5856505598550306 ---->\n",
      "Epoch : 567   loss = 0.45575778082177687  weights = [-0.1359671499381938, 1.050456946465727] bias = -3.593027080218233 ---->\n",
      "Epoch : 568   loss = 4.680878083038819  weights = [1.0806803811380241, 1.0708513165156306] bias = -3.568099050313964 ---->\n",
      "Epoch : 569   loss = 11.846268915503044  weights = [0.3784076593877763, 1.05948768035443] bias = -3.5930990500137536 ---->\n",
      "Epoch : 570   loss = 3.762414373600133  weights = [-0.3206762867119821, 1.0482080073113744] bias = -3.6179371786790924 ---->\n",
      "Epoch : 571   loss = 9.193031546334995  weights = [0.8974717782297985, 1.0686610029224697] bias = -3.5929389227152138 ---->\n",
      "Epoch : 572   loss = 10.153423164536795  weights = [0.19519921818953045, 1.0572973723211316] bias = -3.6179389136741262 ---->\n",
      "Epoch : 573   loss = 1.291373667650873  weights = [-0.39705866973785076, 1.0482579892727888] bias = -3.6378949440511694 ---->\n",
      "Epoch : 574   loss = 11.063915595019456  weights = [0.8211156295834009, 1.0687121795248862] bias = -3.6128953386556626 ---->\n",
      "Epoch : 575   loss = 9.444183121471745  weights = [0.1188436065790085, 1.0573485667547018] bias = -3.637895300705324 ---->\n",
      "Epoch : 576   loss = 0.5425544064154342  weights = [-0.21873620949025996, 1.0529518670939515] bias = -3.6481360121631656 ---->\n",
      "Epoch : 577   loss = 6.722775699527762  weights = [0.9991948453529073, 1.0733955483601105] bias = -3.623148568918165 ---->\n",
      "Epoch : 578   loss = 11.076143399514045  weights = [0.2969221442579134, 1.0620319129295401] bias = -3.6481485674982066 ---->\n",
      "Epoch : 579   loss = 2.604739729289265  weights = [-0.388607810337923, 1.051072469597301] bias = -3.6723257007097567 ---->\n",
      "Epoch : 580   loss = 10.874087018529863  weights = [0.8295654387124446, 1.0715266112143274] bias = -3.647326149755598 ---->\n",
      "Epoch : 581   loss = 9.508321957271512  weights = [0.1272933332834193, 1.0601629957264913] bias = -3.6723261162343515 ---->\n",
      "Epoch : 582   loss = 0.5956819700955034  weights = [-0.2482169449743516, 1.0551277384440678] bias = -3.683781754272834 ---->\n",
      "Epoch : 583   loss = 7.45785042454936  weights = [0.9698313035895905, 1.0755763741691318] bias = -3.6587885186288522 ---->\n",
      "Epoch : 584   loss = 10.792448177161178  weights = [0.2675586229171585, 1.0642127394485386] bias = -3.683788516103406 ---->\n",
      "Epoch : 585   loss = 2.189266929525973  weights = [-0.40414488670161164, 1.0535610104909168] bias = -3.707310303706266 ---->\n",
      "Epoch : 586   loss = 11.26909844253435  weights = [0.8140307807869428, 1.0740152645684296] bias = -3.682310626921548 ---->\n",
      "Epoch : 587   loss = 9.351939578480078  weights = [0.11175891202015176, 1.0626516568287132] bias = -3.707310580678673 ---->\n",
      "Epoch : 588   loss = 0.48591383606253336  weights = [-0.17065589364197126, 1.0592066780505631] bias = -3.7158147178550216 ---->\n",
      "Epoch : 589   loss = 5.583017447500698  weights = [1.0468861983276134, 1.0796347379779527] bias = -3.690845871743984 ---->\n",
      "Epoch : 590   loss = 11.487758309794797  weights = [0.3446134826267866, 1.0682711020325495] bias = -3.7158458711155116 ---->\n",
      "Epoch : 591   loss = 3.232228769029307  weights = [-0.3506873318050313, 1.0570843954967366] bias = -3.740496167760094 ---->\n",
      "Epoch : 592   loss = 9.981840533720996  weights = [0.8674777267259893, 1.0775381611162138] bias = -3.7154970395578477 ---->\n",
      "Epoch : 593   loss = 9.829903537782297  weights = [0.16520532737177485, 1.0661745358916035] bias = -3.7404970218524953 ---->\n",
      "Epoch : 594   loss = 0.9162575431726693  weights = [-0.34263532674761266, 1.0587581061785045] bias = -3.7568799383327187 ---->\n",
      "Epoch : 595   loss = 9.793174216847154  weights = [0.8755271801749792, 1.0792117556974166] bias = -3.7318809411624234 ---->\n",
      "Epoch : 596   loss = 9.8974899914268  weights = [0.1732547396845101, 1.067848129098058] bias = -3.756880925673305 ---->\n",
      "Epoch : 597   loss = 0.9944721771393066  weights = [-0.35556415806538544, 1.0600414393250535] bias = -3.774122453630154 ---->\n",
      "Epoch : 598   loss = 10.11625915459114  weights = [0.8626028802177463, 1.0804952955680873] bias = -3.7491232232397516 ---->\n",
      "Epoch : 599   loss = 9.772059549172258  weights = [0.16033052352436228, 1.0691316717557877] bias = -3.774123203235756 ---->\n",
      "Epoch : 600   loss = 0.8573245917907737  weights = [-0.3286062690683651, 1.0620744642570763] bias = -3.7897343273635578 ---->\n",
      "Epoch : 601   loss = 9.466451316949405  weights = [0.889550908553888, 1.0825278725766576] bias = -3.7647356030307324 ---->\n",
      "Epoch : 602   loss = 10.01356634841892  weights = [0.18727840928919226, 1.0711642440062172] bias = -3.789735590709591 ---->\n",
      "Epoch : 603   loss = 1.136136810278358  weights = [-0.37336749145017156, 1.0627585226758498] bias = -3.8083102465583263 ---->\n",
      "Epoch : 604   loss = 10.565990665005678  weights = [0.8448041846396207, 1.0832125920101587] bias = -3.783310776553926 ---->\n",
      "Epoch : 605   loss = 9.595267088856872  weights = [0.14253199020420904, 1.0718489735555232] bias = -3.8083107478143163 ---->\n",
      "Epoch : 606   loss = 0.6853813690001636  weights = [-0.2790699650308278, 1.066038548161568] bias = -3.8213161692689255 ---->\n",
      "Epoch : 607   loss = 8.273775507995987  weights = [0.9390483478390294, 1.086490228958371] bias = -3.7963194164918552 ---->\n",
      "Epoch : 608   loss = 10.456022620666644  weights = [0.23677571440133616, 1.07512659585467] bias = -3.8213194114122824 ---->\n",
      "Epoch : 609   loss = 1.7234687382189202  weights = [-0.4043019249441412, 1.0651300011007465] bias = -3.8434247418856335 ---->\n",
      "Epoch : 610   loss = 11.336248134914332  weights = [0.813874485660156, 1.0855842900600494] bias = -3.8184250260792543 ---->\n",
      "Epoch : 611   loss = 9.297450797755225  weights = [0.11160273804158749, 1.0742206862093213] bias = -3.8434249733179726 ---->\n",
      "Epoch : 612   loss = 0.4638695774872792  weights = [-0.14433807201876053, 1.0712752667929482] bias = -3.851041855412413 ---->\n",
      "Epoch : 613   loss = 5.004822912398082  weights = [1.0728436945973994, 1.091689845597212] bias = -3.8260893133672247 ---->\n",
      "Epoch : 614   loss = 11.673508652478905  weights = [0.3705709754699731, 1.0803262095292856] bias = -3.851089312924621 ---->\n",
      "Epoch : 615   loss = 3.5296805654980257  weights = [-0.3269576239648907, 1.0690854595350108] bias = -3.8758492456723164 ---->\n",
      "Epoch : 616   loss = 9.466472455819902  weights = [0.8912007013454674, 1.0895389206749955] bias = -3.850850461544204 ---->\n",
      "Epoch : 617   loss = 9.995079087943834  weights = [0.18892821405118965, 1.0781752924968382] bias = -3.875850448576382 ---->\n",
      "Epoch : 618   loss = 1.1239159136150327  weights = [-0.3673297615194656, 1.069867818325278] bias = -3.894225476737165 ---->\n",
      "Epoch : 619   loss = 10.458939264748446  weights = [0.8508415302245455, 1.09032187027643] bias = -3.869226026200125 ---->\n",
      "Epoch : 620   loss = 9.617169475426804  weights = [0.14856931971851584, 1.078958251273006] bias = -3.894225998322059 ---->\n",
      "Epoch : 621   loss = 0.7151424866896873  weights = [-0.28440430020906926, 1.0729661656537437] bias = -3.9076164347520423 ---->\n",
      "Epoch : 622   loss = 8.444044479946637  weights = [0.9337247874683354, 1.0934183237458963] bias = -3.882619135221356 ---->\n",
      "Epoch : 623   loss = 10.373412822522043  weights = [0.23145217259006579, 1.0820546912695832] bias = -3.90761912913868 ---->\n",
      "Epoch : 624   loss = 1.6194204754386554  weights = [-0.39866615905325953, 1.07229025373573] bias = -3.929223822751359 ---->\n",
      "Epoch : 625   loss = 11.238910891395092  weights = [0.8195100930366929, 1.0927445354402756] bias = -3.9042241149999364 ---->\n",
      "Epoch : 626   loss = 9.315723596777792  weights = [0.11723832272401469, 1.0813809308151494] bias = -3.9292240634507367 ---->\n",
      "Epoch : 627   loss = 0.48086476713570325  weights = [-0.1605147828340246, 1.0781230113219675] bias = -3.93739364009408 ---->\n",
      "Epoch : 628   loss = 5.438996308083346  weights = [1.0570196135534757, 1.0985510123939994] bias = -3.9124249063669656 ---->\n",
      "Epoch : 629   loss = 11.494454642664524  weights = [0.35474689811457494, 1.0871873764567097] bias = -3.937424905724236 ---->\n",
      "Epoch : 630   loss = 3.268139164090855  weights = [-0.34050847142529683, 1.0760022753106868] bias = -3.9620718520994034 ---->\n",
      "Epoch : 631   loss = 9.836895038011921  weights = [0.8776567001787081, 1.09645604757951] bias = -3.93707271628144 ---->\n",
      "Epoch : 632   loss = 9.837019957734212  weights = [0.1753843077785242, 1.0850924225514353] bias = -3.9620726981968706 ---->\n",
      "Epoch : 633   loss = 0.9500181553854244  weights = [-0.33665803472287437, 1.0776429617521013] bias = -3.9785771562623164 ---->\n",
      "Epoch : 634   loss = 9.750666913928633  weights = [0.8815061078619287, 1.0980966873270968] bias = -3.9535780731099117 ---->\n",
      "Epoch : 635   loss = 9.86598518716139  weights = [0.17923369724514104, 1.086733061690867] bias = -3.9785780560067883 ---->\n",
      "Epoch : 636   loss = 0.9845231180110567  weights = [-0.3417374571210091, 1.079117383935253] bias = -3.995449500062083 ---->\n",
      "Epoch : 637   loss = 9.882251147135666  weights = [0.8764285981626075, 1.0995711966362312] bias = -3.970450318606736 ---->\n",
      "Epoch : 638   loss = 9.812797279598904  weights = [0.17415622443196832, 1.0882075722203597] bias = -3.9954502995155416 ---->\n",
      "Epoch : 639   loss = 0.9270761015678063  weights = [-0.3305593121971402, 1.0809030221209088] bias = -4.011645679179769 ---->\n",
      "Epoch : 640   loss = 9.617282133157982  weights = [0.8876031887846909, 1.1013566734282199] bias = -3.9866466798561833 ---->\n",
      "Epoch : 641   loss = 9.909180290241324  weights = [0.18533075322235348, 1.0899930469567616] bias = -4.011646664097186 ---->\n",
      "Epoch : 642   loss = 1.0380055014215177  weights = [-0.3483787423419107, 1.0821403254066873] bias = -4.029045493405295 ---->\n",
      "Epoch : 643   loss = 10.059615941794657  weights = [0.8697896450498499, 1.1025942447046682] bias = -4.004046191846687 ---->\n",
      "Epoch : 644   loss = 9.738782983378917  weights = [0.16751733058301288, 1.0912306222409756] bias = -4.0290461695620685 ---->\n",
      "Epoch : 645   loss = 0.8515164512335255  weights = [-0.3130953551143603, 1.0843871021790081] bias = -4.044252189971933 ---->\n",
      "Epoch : 646   loss = 9.206681810119427  weights = [0.9050600656306733, 1.1048404343328475] bias = -4.019253551951942 ---->\n",
      "Epoch : 647   loss = 10.056918654936625  weights = [0.20278755592617326, 1.0934768053846722] bias = -4.044253540190928 ---->\n",
      "Epoch : 648   loss = 1.2198884416707314  weights = [-0.3689646260408659, 1.0848935964992423] bias = -4.063271685891415 ---->\n",
      "Epoch : 649   loss = 10.577144831826844  weights = [0.849208463427346, 1.1053477318294578] bias = -4.038272141711937 ---->\n",
      "Epoch : 650   loss = 9.536434812053898  weights = [0.14693636119941922, 1.093984116327898] bias = -4.063272108000641 ---->\n",
      "Epoch : 651   loss = 0.6598987470016288  weights = [-0.25659308127575853, 1.0885812117685378] bias = -4.075489619775569 ---->\n",
      "Epoch : 652   loss = 7.844036519681876  weights = [0.9615101536310752, 1.109032246380442] bias = -4.050493612159089 ---->\n",
      "Epoch : 653   loss = 10.563405574544923  weights = [0.25923750508101917, 1.0976686127507247] bias = -4.075493607895523 ---->\n",
      "Epoch : 654   loss = 1.9049754054427603  weights = [-0.3933139180059475, 1.0874435719392093] bias = -4.098111701861914 ---->\n",
      "Epoch : 655   loss = 11.186755388652408  weights = [0.8248626180679686, 1.107897867128293] bias = -4.073111978962451 ---->\n",
      "Epoch : 656   loss = 9.299223021267299  weights = [0.12259090705977482, 1.0965342643370333] bias = -4.098111924213772 ---->\n",
      "Epoch : 657   loss = 0.484245332461856  weights = [-0.15881927613265845, 1.0932947519050884] bias = -4.1062472040788265 ---->\n",
      "Epoch : 658   loss = 5.475836578877991  weights = [1.0587879063242966, 1.1137257304594652] bias = -4.081274918677277 ---->\n",
      "Epoch : 659   loss = 11.445064804989745  weights = [0.3565151924794705, 1.1023620945773351] bias = -4.10627491794806 ---->\n",
      "Epoch : 660   loss = 3.2129458265345803  weights = [-0.33783461869190756, 1.0911991672371042] bias = -4.130876280055671 ---->\n",
      "Epoch : 661   loss = 9.849933863721706  weights = [0.8803321854870613, 1.1116530148707726] bias = -4.1058770591325455 ---->\n",
      "Epoch : 662   loss = 9.795983351665896  weights = [0.1780598319578578, 1.1002893910970102] bias = -4.130877038950028 ---->\n",
      "Epoch : 663   loss = 0.9244769273272635  weights = [-0.3224484953056985, 1.0930920671066437] bias = -4.146869739205313 ---->\n",
      "Epoch : 664   loss = 9.482299400830852  weights = [0.8957133355321709, 1.1135456892168225] bias = -4.121870772804482 ---->\n",
      "Epoch : 665   loss = 9.931097468218622  weights = [0.19344089342008153, 1.1021820625069163] bias = -4.146870757396583 ---->\n",
      "Epoch : 666   loss = 1.0796387058276422  weights = [-0.34694406698013325, 1.094224250243335] bias = -4.164530279398442 ---->\n",
      "Epoch : 667   loss = 10.087459710145579  weights = [0.8712255600989273, 1.1146782268835134] bias = -4.139530913242609 ---->\n",
      "Epoch : 668   loss = 9.699288134542671  weights = [0.16895328970373158, 1.1033146058399252] bias = -4.164530888580726 ---->\n",
      "Epoch : 669   loss = 0.8262708850371786  weights = [-0.299609249638348, 1.0967285768180224] bias = -4.179215555631364 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 670   loss = 8.940548163238704  weights = [0.9185421738625641, 1.1171817317653088] bias = -4.154217118842632 ---->\n",
      "Epoch : 671   loss = 10.128301382896016  weights = [0.21626963906730245, 1.1058181019634272] bias = -4.1792171084342575 ---->\n",
      "Epoch : 672   loss = 1.326125331364286  weights = [-0.37128938269014367, 1.0969399932752157] bias = -4.198909383121682 ---->\n",
      "Epoch : 673   loss = 10.696673714863287  weights = [0.8468850701012983, 1.1173941919380033] bias = -4.173909767955023 ---->\n",
      "Epoch : 674   loss = 9.462351672246982  weights = [0.1446130848261027, 1.1060305802009782] bias = -4.19890972794547 ---->\n",
      "Epoch : 675   loss = 0.6113874001484136  weights = [-0.23040193125430686, 1.1011912679612814] bias = -4.210027952968892 ---->\n",
      "Epoch : 676   loss = 7.268073962512685  weights = [0.987662285577142, 1.1216406381318709] bias = -4.185033874121636 ---->\n",
      "Epoch : 677   loss = 10.75135597066709  weights = [0.2853896133958683, 1.110277003690307] bias = -4.210033871135937 ---->\n",
      "Epoch : 678   loss = 2.1913356364378114  weights = [-0.3827033658672562, 1.0997177084954137] bias = -4.233371566807527 ---->\n",
      "Epoch : 679   loss = 10.99085290071846  weights = [0.8354727295623755, 1.1201719833878057] bias = -4.208371866467397 ---->\n",
      "Epoch : 680   loss = 9.344099044559742  weights = [0.13320095028878576, 1.108808378316165] bias = -4.233371815377921 ---->\n",
      "Epoch : 681   loss = 0.5253918220249456  weights = [-0.18447079848328796, 1.105006106073145] bias = -4.24252778804372 ---->\n",
      "Epoch : 682   loss = 6.163884488827109  weights = [1.033417515688396, 1.1254482180596734] bias = -4.217542234857355 ---->\n",
      "Epoch : 683   loss = 11.159039185148663  weights = [0.331144812802849, 1.114084582559377] bias = -4.242542233534031 ---->\n",
      "Epoch : 684   loss = 2.798134736017425  weights = [-0.3564376196457931, 1.1030826770051576] bias = -4.266811049885982 ---->\n",
      "Epoch : 685   loss = 10.36627059393055  weights = [0.8617349731081977, 1.1235367900787834] bias = -4.241811530511504 ---->\n",
      "Epoch : 686   loss = 9.572318682566186  weights = [0.15946284621871687, 1.11217317370584] bias = -4.266811498119354 ---->\n",
      "Epoch : 687   loss = 0.7144624321819196  weights = [-0.2637108982130724, 1.1064648553158603] bias = -4.279679867545974 ---->\n",
      "Epoch : 688   loss = 8.112209160864367  weights = [0.9544144639389787, 1.1269168621429557] bias = -4.254682742747446 ---->\n",
      "Epoch : 689   loss = 10.418787134428026  weights = [0.2521418455384459, 1.1155532295256438] bias = -4.279682736853534 ---->\n",
      "Epoch : 690   loss = 1.7262718358515714  weights = [-0.3835907287053498, 1.1056968812367625] bias = -4.301519719565581 ---->\n",
      "Epoch : 691   loss = 11.044099878317912  weights = [0.8345858061520904, 1.1261511766774681] bias = -4.276519996272318 ---->\n",
      "Epoch : 692   loss = 9.309435685612806  weights = [0.13231410691986534, 1.1147875741553441] bias = -4.301519940875233 ---->\n",
      "Epoch : 693   loss = 0.5082103863057074  weights = [-0.17024082474314872, 1.111276394128456] bias = -4.310145666820618 ---->\n",
      "Epoch : 694   loss = 5.848508487066936  weights = [1.0475685872877825, 1.1317153946513203] bias = -4.285163813653513 ---->\n",
      "Epoch : 695   loss = 11.26273261431138  weights = [0.34529588003115297, 1.1203517589981504] bias = -4.310163812567049 ---->\n",
      "Epoch : 696   loss = 2.961613200639633  weights = [-0.34509960805144624, 1.109283920684097] bias = -4.334569296109986 ---->\n",
      "Epoch : 697   loss = 10.121379272462521  weights = [0.8730714058011585, 1.1297379615462417] bias = -4.309569857701605 ---->\n",
      "Epoch : 698   loss = 9.650097694282856  weights = [0.17079919706909008, 1.1183743424801142] bias = -4.334569829713799 ---->\n",
      "Epoch : 699   loss = 0.7963981819275839  weights = [-0.2825686831509675, 1.112115173443608] bias = -4.348598706956455 ---->\n",
      "Epoch : 700   loss = 8.603781085392445  weights = [0.9355767232998051, 1.132568063816306] bias = -4.323600571554151 ---->\n",
      "Epoch : 701   loss = 10.218913121014356  weights = [0.2333041607550459, 1.121204433070419] bias = -4.348600562642588 ---->\n",
      "Epoch : 702   loss = 1.4641159907587402  weights = [-0.3717267078922516, 1.111991975410728] bias = -4.369050160708714 ---->\n",
      "Epoch : 703   loss = 10.786240136504178  weights = [0.8464488659667767, 1.1324462263477686] bias = -4.344050487029601 ---->\n",
      "Epoch : 704   loss = 9.392164568249969  weights = [0.14417701746704925, 1.1210826189714453] bias = -4.369050439653823 ---->\n",
      "Epoch : 705   loss = 0.5734966057381657  weights = [-0.20469876652022617, 1.1167755402641295] bias = -4.379158026343325 ---->\n",
      "Epoch : 706   loss = 6.720091968147881  weights = [1.0133130567432713, 1.1372227342575636] bias = -4.354166491726147 ---->\n",
      "Epoch : 707   loss = 10.921227779148523  weights = [0.3110403696899622, 1.125859099301795] bias = -4.3791664895452085 ---->\n",
      "Epoch : 708   loss = 2.4602965807439507  weights = [-0.3668720677075241, 1.1150819076429448] bias = -4.402966598594838 ---->\n",
      "Epoch : 709   loss = 10.683658020252778  weights = [0.8513031019170778, 1.135536139934743] bias = -4.377966945721432 ---->\n",
      "Epoch : 710   loss = 9.42356256340431  weights = [0.1490312037435333, 1.1241725309371338] bias = -4.402966901015607 ---->\n",
      "Epoch : 711   loss = 0.6013770365851482  weights = [-0.21560282624549165, 1.119589607531784] bias = -4.413607303494007 ---->\n",
      "Epoch : 712   loss = 7.00179043837716  weights = [1.0024473140676027, 1.14003840581943] bias = -4.388613894698105 ---->\n",
      "Epoch : 713   loss = 10.808007883853902  weights = [0.30017463758678653, 1.1286747712251182] bias = -4.4136138919448005 ---->\n",
      "Epoch : 714   loss = 2.2979576312589116  weights = [-0.37130427870998295, 1.1180442502880723] bias = -4.437106363207016 ---->\n",
      "Epoch : 715   loss = 10.807500049909974  weights = [0.8468716261675291, 1.1384985167018897] bias = -4.412106672217224 ---->\n",
      "Epoch : 716   loss = 9.369580683232979  weights = [0.14459982880731026, 1.1271349109432667] bias = -4.437106622086913 ---->\n",
      "Epoch : 717   loss = 0.5633788415903861  weights = [-0.19638587895431214, 1.122994357401084] bias = -4.446903359634572 ---->\n",
      "Epoch : 718   loss = 6.548907134123048  weights = [1.021606345122363, 1.1434407557931816] bias = -4.421912760952195 ---->\n",
      "Epoch : 719   loss = 10.971074170639378  weights = [0.3193336546311113, 1.1320771207178926] bias = -4.446912758957364 ---->\n",
      "Epoch : 720   loss = 2.541952772169216  weights = [-0.36085750657559046, 1.1212484808357004] bias = -4.470821096206513 ---->\n",
      "Epoch : 721   loss = 10.568526377387126  weights = [0.8573172933780003, 1.1417026961962242] bias = -4.445821462215803 ---->\n",
      "Epoch : 722   loss = 9.452426562887815  weights = [0.15504535663436947, 1.1303390859215174] bias = -4.470821419581548 ---->\n",
      "Epoch : 723   loss = 0.6319328601642232  weights = [-0.22428248948552149, 1.1255060304421114] bias = -4.481958600918262 ---->\n",
      "Epoch : 724   loss = 7.244986151360715  weights = [0.9937957380053501, 1.1459560214457052] bias = -4.456963805772021 ---->\n",
      "Epoch : 725   loss = 10.70195455981055  weights = [0.29152307430878033, 1.1345923872850998] bias = -4.481963802326812 ---->\n",
      "Epoch : 726   loss = 2.1517698393423315  weights = [-0.37243965934662593, 1.124132165436416] bias = -4.50509895104041 ---->\n",
      "Epoch : 727   loss = 10.86666733488385  weights = [0.8457367245376861, 1.1445864541934867] bias = -4.480099235093125 ---->\n",
      "Epoch : 728   loss = 9.332728795078275  weights = [0.14346501013508195, 1.133222851069172] bias = -4.505099180497172 ---->\n",
      "Epoch : 729   loss = 0.5433405656126831  weights = [-0.1827050074869565, 1.129373522006707] bias = -4.514353679156966 ---->\n",
      "Epoch : 730   loss = 6.246751967638178  weights = [1.0352398467109036, 1.1498180092602037] bias = -4.489365334275781 ---->\n",
      "Epoch : 731   loss = 11.070109892018513  weights = [0.3329671499064104, 1.1384543739664024] bias = -4.514365332622855 ---->\n",
      "Epoch : 732   loss = 2.6969838546384604  weights = [-0.3512272269512713, 1.1275334993285155] bias = -4.53846618181407 ---->\n",
      "Epoch : 733   loss = 10.365150102319872  weights = [0.8669466404947159, 1.1479876718766215] bias = -4.513466595666743 ---->\n",
      "Epoch : 734   loss = 9.514596780161044  weights = [0.16467461783291393, 1.1366240587939354] bias = -4.5384665576533685 ---->\n",
      "Epoch : 735   loss = 0.6925155189279079  weights = [-0.24148443333391612, 1.1313077980868218] bias = -4.550581459543207 ---->\n",
      "Epoch : 736   loss = 7.695991383421307  weights = [0.9766287179855917, 1.1517592867455668] bias = -4.525584932424543 ---->\n",
      "Epoch : 737   loss = 10.517576799883198  weights = [0.27435608390161204, 1.140395653584295] bias = -4.550584927377553 ---->\n",
      "Epoch : 738   loss = 1.8965289425586631  weights = [-0.37255971846449953, 1.1303139461067475] bias = -4.572921971233724 ---->\n",
      "Epoch : 739   loss = 10.900974656366559  weights = [0.845617005352318, 1.1507682507581598] bias = -4.547922237535481 ---->\n",
      "Epoch : 740   loss = 9.305288810348076  weights = [0.14334536044353763, 1.1394046498243628] bias = -4.5729221791980255 ---->\n",
      "Epoch : 741   loss = 0.5307435514150733  weights = [-0.17250842052960585, 1.1357648090129027] bias = -4.581791548798277 ---->\n",
      "Epoch : 742   loss = 6.02946701637643  weights = [1.04539722584208, 1.156207750412869] bias = -4.556805035759826 ---->\n",
      "Epoch : 743   loss = 11.137235484109574  weights = [0.3431245254815486, 1.144844114995366] bias = -4.581805034299533 ---->\n",
      "Epoch : 744   loss = 2.805028224397279  weights = [-0.3433370214478608, 1.133870490604053] bias = -4.606015408413647 ---->\n",
      "Epoch : 745   loss = 10.204098990614439  weights = [0.874836084581124, 1.1543246283629978] bias = -4.581015861176475 ---->\n",
      "Epoch : 746   loss = 9.56084258724128  weights = [0.17256400592481735, 1.142961013440705] bias = -4.606015826175105 ---->\n",
      "Epoch : 747   loss = 0.7419462637576332  weights = [-0.2523276066807129, 1.1373072860224136] bias = -4.618835591581565 ---->\n",
      "Epoch : 748   loss = 7.9918264428665085  weights = [0.9658023464008496, 1.1577595053560155] bias = -4.593838224524025 ---->\n",
      "Epoch : 749   loss = 10.391612819817464  weights = [0.26352974056921874, 1.1463958731398267] bias = -4.618838217949583 ---->\n",
      "Epoch : 750   loss = 1.7292202271262107  weights = [-0.3680590948369762, 1.1366492736874918] bias = -4.640467296712067 ---->\n",
      "Epoch : 751   loss = 10.822504167809479  weights = [0.850117499296611, 1.1571035724244472] bias = -4.6154675695683425 ---->\n",
      "Epoch : 752   loss = 9.320419172476086  weights = [0.147845833037626, 1.1457399707635718] bias = -4.640467512374315 ---->\n",
      "Epoch : 753   loss = 0.5479321476168876  weights = [-0.17854958359444162, 1.1419339989242945] bias = -4.649648176036906 ---->\n",
      "Epoch : 754   loss = 6.208010493727712  weights = [1.0394039255858858, 1.1623788772656058] bias = -4.624659376146484 ---->\n",
      "Epoch : 755   loss = 11.055850483328289  weights = [0.3371312303580042, 1.151015242023654] bias = -4.649659374408082 ---->\n",
      "Epoch : 756   loss = 2.691512072666969  weights = [-0.3463220588835346, 1.1401126588302886] bias = -4.6737223827306495 ---->\n",
      "Epoch : 757   loss = 10.308124210144529  weights = [0.8718520336444312, 1.1605668421071027] bias = -4.648722784497268 ---->\n",
      "Epoch : 758   loss = 9.507164054662471  weights = [0.16958003723483694, 1.1492032298158943] bias = -4.673722745065198 ---->\n",
      "Epoch : 759   loss = 0.7009896737548368  weights = [-0.23636320569988156, 1.1439260886103977] bias = -4.6857813428730095 ---->\n",
      "Epoch : 760   loss = 7.633656006966561  weights = [0.9817513773562446, 1.164377645886508] bias = -4.660784737663205 ---->\n",
      "Epoch : 761   loss = 10.512170797706283  weights = [0.27947874636096925, 1.153014012821753] bias = -4.6857847324488695 ---->\n",
      "Epoch : 762   loss = 1.9049672490474021  weights = [-0.3665794682492419, 1.1429572135623252] bias = -4.708076085826932 ---->\n",
      "Epoch : 763   loss = 10.817678777206147  weights = [0.8515972971197624, 1.1634115203524023] bias = -4.6830763496752095 ---->\n",
      "Epoch : 764   loss = 9.307781933047389  weights = [0.14932567012625486, 1.152047919904617] bias = -4.7080762903649465 ---->\n",
      "Epoch : 765   loss = 0.5457048120755419  weights = [-0.1740576424708306, 1.1483196474724429] bias = -4.717115662741959 ---->\n",
      "Epoch : 766   loss = 6.129698670393421  weights = [1.043888237247721, 1.168764242312636] bias = -4.692127200825672 ---->\n",
      "Epoch : 767   loss = 11.07087539706167  weights = [0.3416155414055617, 1.1574006070483462] bias = -4.717127199120517 ---->\n",
      "Epoch : 768   loss = 2.7217382450899223  weights = [-0.34231378799064516, 1.1464873130810826] bias = -4.74121244912161 ---->\n",
      "Epoch : 769   loss = 10.241605500153982  weights = [0.8758601787114982, 1.1669414907626054] bias = -4.71621285710791 ---->\n",
      "Epoch : 770   loss = 9.517805316571922  weights = [0.17358817446752406, 1.1555778781891526] bias = -4.74121281809496 ---->\n",
      "Epoch : 771   loss = 0.7180205535844366  weights = [-0.23756044719525193, 1.1502186484780024] bias = -4.753451528163685 ---->\n",
      "Epoch : 772   loss = 7.694080442281614  weights = [0.9805596966024233, 1.170670448465227] bias = -4.728454643793595 ---->\n",
      "Epoch : 773   loss = 10.47497609297786  weights = [0.27828707423314913, 1.1593068156859068] bias = -4.753454638112692 ---->\n",
      "Epoch : 774   loss = 1.860846871819144  weights = [-0.3634528472166221, 1.149347864031705] bias = -4.775543099947147 ---->\n",
      "Epoch : 775   loss = 10.772622059918449  weights = [0.8547239243435878, 1.1698021712143403] bias = -4.750543363322856 ---->\n",
      "Epoch : 776   loss = 9.310342340690148  weights = [0.1524523034570524, 1.1584385709162108] bias = -4.775543303679592 ---->\n",
      "Epoch : 777   loss = 0.5542689939800725  weights = [-0.17493857736928287, 1.1546595347170576] bias = -4.784681265644467 ---->\n",
      "Epoch : 778   loss = 6.182332895083577  weights = [1.043025615453206, 1.175104883822807] bias = -4.7596919162380615 ---->\n",
      "Epoch : 779   loss = 11.0367555912149  weights = [0.3407529222110438, 1.163741248646325] bias = -4.784691914392028 ---->\n",
      "Epoch : 780   loss = 2.6788340957047585  weights = [-0.3417358218166048, 1.1528622038406418] bias = -4.808706135803916 ---->\n",
      "Epoch : 781   loss = 10.25866267315858  weights = [0.8764385318956381, 1.1733163994898426] bias = -4.783706523651773 ---->\n",
      "Epoch : 782   loss = 9.496953493705051  weights = [0.17416656696032062, 1.1619527881511222] bias = -4.808706482519826 ---->\n",
      "Epoch : 783   loss = 0.7070806657389359  weights = [-0.23036598605453718, 1.1567361838858388] bias = -4.82066566213891 ---->\n",
      "Epoch : 784   loss = 7.549743275392376  weights = [0.9877487737415535, 1.1771877558466861] bias = -4.795669040986041 ---->\n",
      "Epoch : 785   loss = 10.514969314386873  weights = [0.2854761443013546, 1.1658241228262343] bias = -4.820669035687303 ---->\n",
      "Epoch : 786   loss = 1.9249093320580768  weights = [-0.36060394946002383, 1.1557728123837578] bias = -4.842955502353675 ---->\n",
      "Epoch : 787   loss = 10.73429032745435  weights = [0.857572854694543, 1.176227121183547] bias = -4.8179557638931385 ---->\n",
      "Epoch : 788   loss = 9.310383132055296  weights = [0.1553012456357269, 1.1648635212162197] bias = -4.842955703609245 ---->\n",
      "Epoch : 789   loss = 0.5611291915813285  weights = [-0.17473512529915364, 1.1610574388537003] bias = -4.8521486763007715 ---->\n",
      "Epoch : 790   loss = 6.2084804837461265  weights = [1.0432412678909528, 1.1815032969666328] bias = -4.8271587293506935 ---->\n",
      "Epoch : 791   loss = 11.01259027055592  weights = [0.340968576733206, 1.1701396618599897] bias = -4.852158727391721 ---->\n",
      "Epoch : 792   loss = 2.650799486614167  weights = [-0.34040558576911417, 1.15928722774362] bias = -4.876117781685952 ---->\n",
      "Epoch : 793   loss = 10.257330415524217  weights = [0.8777690302806798, 1.1797414356269937] bias = -4.8511181558160095 ---->\n",
      "Epoch : 794   loss = 9.483052665394963  weights = [0.17549709555762072, 1.168377825226007] bias = -4.876118113054778 ---->\n",
      "Epoch : 795   loss = 0.7024525149003936  weights = [-0.2250279067988048, 1.1632541812070187] bias = -4.887899785721689 ---->\n",
      "Epoch : 796   loss = 7.450641940291689  weights = [0.9930836581309157, 1.1837056202657978] bias = -4.8629033184504795 ---->\n",
      "Epoch : 797   loss = 10.537929638626245  weights = [0.29081102528273894, 1.172341987127156] bias = -4.887903313335896 ---->\n",
      "Epoch : 798   loss = 1.9652424950051535  weights = [-0.35755708097202576, 1.1622427378437523] bias = -4.910293381710304 ---->\n",
      "Epoch : 799   loss = 10.69107966760153  weights = [0.8606197356712363, 1.182697047328485] bias = -4.885293642452128 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 800   loss = 9.312282168462458  weights = [0.15834813431245565, 1.1713334475587422] bias = -4.910293581749675 ---->\n",
      "Epoch : 801   loss = 0.5694020010340686  weights = [-0.17496913312764079, 1.1674874928309094] bias = -4.919566471628381 ---->\n",
      "Epoch : 802   loss = 6.245247224165203  weights = [1.0430205474985184, 1.1879339027745102] bias = -4.894575877026847 ---->\n",
      "Epoch : 803   loss = 10.984445388918745  weights = [0.3407478588605488, 1.176570267752263] bias = -4.919575874931362 ---->\n",
      "Epoch : 804   loss = 2.61692779984253  weights = [-0.3392756692265082, 1.165749993916193] bias = -4.9434682933116205 ---->\n",
      "Epoch : 805   loss = 10.260832644978121  weights = [0.8788992262657085, 1.1862042148151832] bias = -4.918468652856999 ---->\n",
      "Epoch : 806   loss = 9.467346295715698  weights = [0.17662732596097108, 1.1748406054827285] bias = -4.943468608240009 ---->\n",
      "Epoch : 807   loss = 0.6963755395561806  weights = [-0.21923580810920035, 1.1698224265688115] bias = -4.955047601322578 ---->\n",
      "Epoch : 808   loss = 7.340416168130508  weights = [0.9988716936139299, 1.1902736967034244] bias = -4.930051329786525 ---->\n",
      "Epoch : 809   loss = 10.565097403094498  weights = [0.29659905670666864, 1.1789100634249423] bias = -4.955051324891346 ---->\n",
      "Epoch : 810   loss = 2.011630958438194  weights = [-0.35437484068076164, 1.1687551848725979] bias = -4.977560366400616 ---->\n",
      "Epoch : 811   loss = 10.644518030160189  weights = [0.8638019745627361, 1.1892094943995515] bias = -4.952560627060809 ---->\n",
      "Epoch : 812   loss = 9.315462706198156  weights = [0.16153037801132797, 1.1778458947340238] bias = -4.9775605660954785 ---->\n",
      "Epoch : 813   loss = 0.5786967493026361  weights = [-0.17541203557187957, 1.1739524941414778] bias = -4.986928702406348 ---->\n",
      "Epoch : 814   loss = 6.287061420278008  weights = [1.0425908487553441, 1.1943994520188252] bias = -4.961937465226431 ---->\n",
      "Epoch : 815   loss = 10.954411718120003  weights = [0.34031816296996387, 1.1830358170919366] bias = -4.986937462976419 ---->\n",
      "Epoch : 816   loss = 2.5803483569364327  weights = [-0.33818548447717245, 1.1722516872126756] bias = -5.010755048730362 ---->\n",
      "Epoch : 817   loss = 10.265255089374849  weights = [0.8799896840560616, 1.1927059208287547] bias = -4.985755394031801 ---->\n",
      "Epoch : 818   loss = 9.451309988226038  weights = [0.17771782023351546, 1.1813423126262865] bias = -5.010755347447914 ---->\n",
      "Epoch : 819   loss = 0.690159507990453  weights = [-0.21338299592197507, 1.1764315396885818] bias = -5.022128091343947 ---->\n",
      "Epoch : 820   loss = 7.22866115467742  weights = [1.0047200702487928, 1.1968826264106502] bias = -4.997132032621112 ---->\n",
      "Epoch : 821   loss = 10.59285590346611  weights = [0.30244742935376434, 1.185518992994889] bias = -5.02213202794152 ---->\n",
      "Epoch : 822   loss = 2.0589919480748673  weights = [-0.3510561689327497, 1.1753095430054086] bias = -5.044757092833161 ---->\n",
      "Epoch : 823   loss = 10.594580166170887  weights = [0.8671206308840508, 1.195763851926708] bias = -5.019757354133369 ---->\n",
      "Epoch : 824   loss = 9.319934062060526  weights = [0.16484903618951396, 1.1844002522705916] bias = -5.044757293063993 ---->\n",
      "Epoch : 825   loss = 0.5890422047609746  weights = [-0.17604182125521062, 1.1804521566277688] bias = -5.054235671913158 ---->\n",
      "Epoch : 826   loss = 6.333387233928615  weights = [1.0419740002612456, 1.200899651346071] bias = -5.029243805739959 ---->\n",
      "Epoch : 827   loss = 10.922691349379425  weights = [0.3397013176903644, 1.1895360165264053] bias = -5.054243803315833 ---->\n",
      "Epoch : 828   loss = 2.5413816148654282  weights = [-0.3371030155439392, 1.1787922545769465] bias = -5.077977893983343 ---->\n",
      "Epoch : 829   loss = 10.269817671999176  weights = [0.8810724155451082, 1.199246500424023] bias = -5.052978225590825 ---->\n",
      "Epoch : 830   loss = 9.435237720611502  weights = [0.17880058987264924, 1.1878828933999073] bias = -5.077978176950228 ---->\n",
      "Epoch : 831   loss = 0.6840609320532461  weights = [-0.2075496580026353, 1.1830793117416196] bias = -5.089145482088595 ---->\n",
      "Epoch : 832   loss = 7.117333483379668  weights = [1.0105486957562577, 1.2035302048763565] bias = -5.064149648314355 ---->\n",
      "Epoch : 833   loss = 10.620467772399737  weights = [0.3082760510735879, 1.1921665713301863] bias = -5.089149643839563 ---->\n",
      "Epoch : 834   loss = 2.1062738123701568  weights = [-0.34761380482385973, 1.1819051820884385] bias = -5.111884576853707 ---->\n",
      "Epoch : 835   loss = 10.541577210886244  weights = [0.8705629666344281, 1.202359489808249] bias = -5.086884839457587 ---->\n",
      "Epoch : 836   loss = 9.325578724236731  weights = [0.16829137110190762, 1.1909958900752458] bias = -5.111884778429284 ---->\n",
      "Epoch : 837   loss = 0.6003738992443656  weights = [-0.17680337688146508, 1.1869870867438657] bias = -5.12148630829419 ---->\n",
      "Epoch : 838   loss = 6.382881361715669  weights = [1.0412248583876682, 1.2074350969710357] bias = -5.096493838754857 ---->\n",
      "Epoch : 839   loss = 10.889786451306824  weights = [0.33895217939496414, 1.196071462270422] bias = -5.121493836136939 ---->\n",
      "Epoch : 840   loss = 2.500795261170057  weights = [-0.3359798559376239, 1.1853721446180066] bias = -5.14513611407755 ---->\n",
      "Epoch : 841   loss = 10.27334049926836  weights = [0.8821958218193968, 1.2058264019615266] bias = -5.120136432817835 ---->\n",
      "Epoch : 842   loss = 9.41957429011801  weights = [0.17992403519678568, 1.1944627961393157] bias = -5.145136382072071 ---->\n",
      "Epoch : 843   loss = 0.678449416907427  weights = [-0.20185404589186395, 1.1897629789987543] bias = -5.156105515858405 ---->\n",
      "Epoch : 844   loss = 7.009317999165714  weights = [1.0162395132496518, 1.2102136767723213] bias = -5.131109909452204 ---->\n",
      "Epoch : 845   loss = 10.64684608004088  weights = [0.3139668651416311, 1.1988500431080282] bias = -5.156109905162647 ---->\n",
      "Epoch : 846   loss = 2.1519094523733946  weights = [-0.3440815347238496, 1.1885413463075145] bias = -5.178944498411516 ---->\n",
      "Epoch : 847   loss = 10.486333469080495  weights = [0.874095198546997, 1.2089956523747694] bias = -5.153944762821535 ---->\n",
      "Epoch : 848   loss = 9.33208565128579  weights = [0.17182360019923737, 1.1976320525016564] bias = -5.1789447019408446 ---->\n",
      "Epoch : 849   loss = 0.6124772504529965  weights = [-0.17759624711521227, 1.1935590742489581] bias = -5.188677604752807 ---->\n",
      "Epoch : 850   loss = 6.433094419193233  weights = [1.0404435514801347, 1.2140075654793485] bias = -5.163684572889803 ---->\n",
      "Epoch : 851   loss = 10.856619596661618  weights = [0.3381708763793648, 1.202643930907838] bias = -5.188684570061124 ---->\n",
      "Epoch : 852   loss = 2.4599621646323144  weights = [-0.33475160569010776, 1.1919923047189684] bias = -5.2122284757982005 ---->\n",
      "Epoch : 853   loss = 10.274253556143762  weights = [0.8834242964617357, 1.2124465725304423] bias = -5.187228782825029 ---->\n",
      "Epoch : 854   loss = 9.404911679275203  weights = [0.18115254858718932, 1.2010829678953463] bias = -5.212228729990323 ---->\n",
      "Epoch : 855   loss = 0.6737980552628832  weights = [-0.1964497934933339, 1.196479273474402] bias = -5.22301536060196 ---->\n",
      "Epoch : 856   loss = 6.9083623973001265  weights = [1.0216392019066851, 1.216929787275817] bias = -5.198019968679757 ---->\n",
      "Epoch : 857   loss = 10.670579184870379  weights = [0.3193665509203848, 1.2055661535118465] bias = -5.2230199645458635 ---->\n",
      "Epoch : 858   loss = 2.193847401078902  weights = [-0.3405177030299209, 1.1952170678308838] bias = -5.245939395909906 ---->\n",
      "Epoch : 859   loss = 10.430272081786207  weights = [0.8776589878200074, 1.215671372053962] bias = -5.220939662339658 ---->\n",
      "Epoch : 860   loss = 9.338917913776216  weights = [0.17538738591778724, 1.2043077720169133] bias = -5.245939601646523 ---->\n",
      "Epoch : 861   loss = 0.6249528671692771  weights = [-0.17827356140472833, 1.2001711205886236] bias = -5.255804481435603 ---->\n",
      "Epoch : 862   loss = 6.480444675297301  weights = [1.0397765940710042, 1.2206200438272345] bias = -5.230810945160647 ---->\n",
      "Epoch : 863   loss = 10.824537346861238  weights = [0.3375039230526403, 1.2092564093906542] bias = -5.255810942110912 ---->\n",
      "Epoch : 864   loss = 2.4208641356204916  weights = [-0.33334661372290697, 1.198653982788449] bias = -5.279253548202659 ---->\n",
      "Epoch : 865   loss = 10.270809942208757  weights = [0.884829484309925, 1.2191082597519332] bias = -5.254253844988964 ---->\n",
      "Epoch : 866   loss = 9.391908571892378  weights = [0.18255777335291656, 1.2077446562408065] bias = -5.279253790163836 ---->\n",
      "Epoch : 867   loss = 0.6706146770106721  weights = [-0.1915025750652518, 1.203224835480534] bias = -5.28988270247987 ---->\n",
      "Epoch : 868   loss = 6.81850793726008  weights = [1.02658248816046, 1.2236751932030527] bias = -5.264887492894854 ---->\n",
      "Epoch : 869   loss = 10.690145762752794  weights = [0.32430983501956157, 1.212311559363716] bias = -5.289887488877486 ---->\n",
      "Epoch : 870   loss = 2.2298610005061796  weights = [-0.33699892540193044, 1.2019311811698121] bias = -5.312872574000751 ---->\n",
      "Epoch : 871   loss = 10.375261806354583  weights = [0.8811777264165949, 1.2223854837092134] bias = -5.2878728422717405 ---->\n",
      "Epoch : 872   loss = 9.345370506215648  weights = [0.17890612182923793, 1.2110218835352777] bias = -5.312872781719537 ---->\n",
      "Epoch : 873   loss = 0.6372512041362182  weights = [-0.17866330502744004, 1.2068269397172038] bias = -5.322860599816867 ---->\n",
      "Epoch : 874   loss = 6.520736827706241  weights = [1.039395695686852, 1.2272762334132126] bias = -5.297866631563394 ---->\n",
      "Epoch : 875   loss = 10.79512092760383  weights = [0.33712302874549416, 1.21591259911078] bias = -5.322866628292918 ---->\n",
      "Epoch : 876   loss = 2.3857961100365173  weights = [-0.33170364266875774, 1.2053583138368702] bias = -5.3462103259211124 ---->\n",
      "Epoch : 877   loss = 10.261516729934574  weights = [0.8864726183890465, 1.2258125984364057] bias = -5.32121061416115 ---->\n",
      "Epoch : 878   loss = 9.381127879985959  weights = [0.18420094100063, 1.214448995938499] bias = -5.346210557525858 ---->\n",
      "Epoch : 879   loss = 0.66931495525518  weights = [-0.187145922889228, 1.2099969871904872] bias = -5.356714032051831 ---->\n",
      "Epoch : 880   loss = 6.743011927725039  weights = [1.0309362251660907, 1.230447232257265] bias = -5.331718954463364 ---->\n",
      "Epoch : 881   loss = 10.704319929906273  weights = [0.3286635707174629, 1.2190835983709265] bias = -5.35671895051671 ---->\n",
      "Epoch : 882   loss = 2.258141628491799  weights = [-0.33360048670006814, 1.208682508771811] bias = -5.379747584948833 ---->\n",
      "Epoch : 883   loss = 10.323139105664815  weights = [0.8845761372163281, 1.229136810144364] bias = -5.354747854485742 ---->\n",
      "Epoch : 884   loss = 9.350750532780145  weights = [0.1823045323801611, 1.217773209909865] bias = -5.379747793943489 ---->\n",
      "Epoch : 885   loss = 0.6488098665090412  weights = [-0.17861532293666071, 1.213529852257696] bias = -5.389840366938638 ---->\n",
      "Epoch : 886   loss = 6.550308548495372  weights = [1.0394508541421867, 1.2339794482674362] bias = -5.36484604664096 ---->\n",
      "Epoch : 887   loss = 10.769750326344381  weights = [0.33717819104812596, 1.2226158140908803] bias = -5.389846043162192 ---->\n",
      "Epoch : 888   loss = 2.3567343962535774  weights = [-0.32979217734945887, 1.21210583485265] bias = -5.4130989414858695 ---->\n",
      "Epoch : 889   loss = 10.245630305978148  weights = [0.8883842130871039, 1.2325601255360887] bias = -5.388099222912555 ---->\n",
      "Epoch : 890   loss = 9.372849828776324  weights = [0.18611256488906225, 1.2211965239088634] bias = -5.413099164702763 ---->\n",
      "Epoch : 891   loss = 0.6700843446393449  weights = [-0.18343341787576012, 1.2167945650397864] bias = -5.423512790827896 ---->\n",
      "Epoch : 892   loss = 6.683181784956002  weights = [1.0346470586317948, 1.237244749614857] bias = -5.3985177845841585 ---->\n",
      "Epoch : 893   loss = 10.712610269886683  weights = [0.3323744037505837, 1.2258811157107377] bias = -5.423517780660867 ---->\n",
      "Epoch : 894   loss = 2.2779454436785724  weights = [-0.33037031890490864, 1.2154701590459167] bias = -5.4465674521649206 ---->\n",
      "Epoch : 895   loss = 10.275073648307716  weights = [0.887806293335598, 1.2359244600019843] bias = -5.421567722132379 ---->\n",
      "Epoch : 896   loss = 9.354616492532381  weights = [0.18553469169047532, 1.224560859814483] bias = -5.446567661415044 ---->\n",
      "Epoch : 897   loss = 0.659249635742724  weights = [-0.1780550202138511, 1.2202815101342206] bias = -5.456741369761157 ---->\n",
      "Epoch : 898   loss = 6.5673404987528725  weights = [1.040016719448811, 1.2407313424168256] bias = -5.4317467747038375 ---->\n",
      "Epoch : 899   loss = 10.749112187412965  weights = [0.33774405979956823, 1.2293677083521788] bias = -5.456746771038578 ---->\n",
      "Epoch : 900   loss = 2.334629964341875  weights = [-0.32762305792576085, 1.218896208419282] bias = -5.479921042387829 ---->\n",
      "Epoch : 901   loss = 10.223415734469627  weights = [0.8905534315015982, 1.239350503785063] bias = -5.454921318564888 ---->\n",
      "Epoch : 902   loss = 9.366974183534609  weights = [0.18828180791903626, 1.2279869028806247] bias = -5.479921259026863 ---->\n",
      "Epoch : 903   loss = 0.6728125586948152  weights = [-0.18031788684476213, 1.2236182670762858] bias = -5.490278549070104 ---->\n",
      "Epoch : 904   loss = 6.637867732449616  weights = [1.0377621386271576, 1.2440684417717092] bias = -5.465283555225871 ---->\n",
      "Epoch : 905   loss = 10.71544984875709  weights = [0.3354894841094729, 1.2327048078762888] bias = -5.4902835512828645 ---->\n",
      "Epoch : 906   loss = 2.289878964413538  weights = [-0.3273133553556956, 1.2222937280069037] bias = -5.513334126130946 ---->\n",
      "Epoch : 907   loss = 10.23118676823675  weights = [0.8908632620935751, 1.242748029325551] bias = -5.488334395661704 ---->\n",
      "Epoch : 908   loss = 9.356922198954642  weights = [0.1885916672142216, 1.2313844292963327] bias = -5.513334334576954 ---->\n",
      "Epoch : 909   loss = 0.6685029209703847  weights = [-0.17700782419690242, 1.2270812780386757] bias = -5.5235656257554355 ---->\n",
      "Epoch : 910   loss = 6.572453207713988  weights = [1.0410681160976192, 1.2475312907812623] bias = -5.49857082114146 ---->\n",
      "Epoch : 911   loss = 10.732974021442267  weights = [0.33879545943488243, 1.2361676568127995] bias = -5.523570817314526 ---->\n",
      "Epoch : 912   loss = 2.3191009308157464  weights = [-0.3252414294357602, 1.2257283356055737] bias = -5.546679553472816 ---->\n",
      "Epoch : 913   loss = 10.19597481830908  weights = [0.8929351347750543, 1.2461826345374813] bias = -5.521679825645114 ---->\n",
      "Epoch : 914   loss = 9.363085029444415  weights = [0.190663531833696, 1.234819034227631] bias = -5.546679764992806 ---->\n",
      "Epoch : 915   loss = 0.6771507726475267  weights = [-0.17767452047410603, 1.230470207216906] bias = -5.557007870596218 ---->\n",
      "Epoch : 916   loss = 6.604026616086845  weights = [1.0404060356644096, 1.250920412404399] bias = -5.532012842086538 ---->\n",
      "Epoch : 917   loss = 10.713984478075652  weights = [0.33813338214804545, 1.2395567785387795] bias = -5.557012838089304 ---->\n",
      "Epoch : 918   loss = 2.2955926013212835  weights = [-0.3243976742865944, 1.2291532374477643] bias = -5.580048548021842 ---->\n",
      "Epoch : 919   loss = 10.190701200184412  weights = [0.8937789620162002, 1.2496075397575481] bias = -5.555048816416408 ---->\n",
      "Epoch : 920   loss = 9.357960354705842  weights = [0.19150737686475572, 1.238243939978122] bias = -5.580048754804854 ---->\n",
      "Epoch : 921   loss = 0.676780037782732  weights = [-0.175575369986589, 1.2339267191662369] bias = -5.590318685120027 ---->\n",
      "Epoch : 922   loss = 6.568126306635074  weights = [1.0425037647547155, 1.254376871105709] bias = -5.565323719093805 ---->\n",
      "Epoch : 923   loss = 10.720403676311825  weights = [0.3402311106821154, 1.243013237219864] bias = -5.590323715126657 ---->\n",
      "Epoch : 924   loss = 2.3087638724774964  weights = [-0.3227071005523078, 1.2326007473386669] bias = -5.613377996406068 ---->\n",
      "Epoch : 925   loss = 10.16476706882307  weights = [0.8954695212735643, 1.2530550490452765] bias = -5.588378265456124 ---->\n",
      "Epoch : 926   loss = 9.360631507755338  weights = [0.1931979360307572, 1.241691449234847] bias = -5.613378203847965 ---->\n",
      "Epoch : 927   loss = 0.6826529242915675  weights = [-0.17535153100365708, 1.2373529645362875] bias = -5.6236962608406005 ---->\n",
      "Epoch : 928   loss = 6.577957350739077  weights = [1.0427302090868582, 1.2578032268923973] bias = -5.598701166545473 ---->\n",
      "Epoch : 929   loss = 10.709607412506186  weights = [0.34045755702468683, 1.2464395930714405] bias = -5.623701162469507 ---->\n",
      "Epoch : 930   loss = 2.297101891161518  weights = [-0.3215756763535824, 1.2360488754233265] bias = -5.646711178023715 ---->\n",
      "Epoch : 931   loss = 10.152457409259265  weights = [0.896600987535584, 1.2565031791259271] bias = -5.621711444835386 ---->\n",
      "Epoch : 932   loss = 9.358167804941777  weights = [0.19432941412919325, 1.245139579657728] bias = -5.646711382588492 ---->\n",
      "Epoch : 933   loss = 0.684416636604822  weights = [-0.17388378231036833, 1.2408147392326911] bias = -5.6570073945797 ---->\n",
      "Epoch : 934   loss = 6.55743700915615  weights = [1.0441978877573757, 1.2612650033232056] bias = -5.632012298665112 ---->\n",
      "Epoch : 935   loss = 10.710242721747143  weights = [0.34192523600212654, 1.2499013695105894] bias = -5.657012294572521 ---->\n",
      "Epoch : 936   loss = 2.301924855782097  weights = [-0.3200752549241186, 1.2395119980508114] bias = -5.680019809182383 ---->\n",
      "Epoch : 937   loss = 10.131139264457214  weights = [0.8981014134469827, 1.259966302021956] bias = -5.655020075679182 ---->\n",
      "Epoch : 938   loss = 9.359105267526278  weights = [0.19582984400148473, 1.2486027026488598] bias = -5.680020013217557 ---->\n",
      "Epoch : 939   loss = 0.6889116857554816  weights = [-0.17321559447950918, 1.2442687260552665] bias = -5.690339945528559 ---->\n",
      "Epoch : 940   loss = 6.556409183359341  weights = [1.0448676862866972, 1.2647190600296743] bias = -5.665344768578159 ---->\n",
      "Epoch : 941   loss = 10.703541959629904  weights = [0.3425950359679981, 1.2533554262627455] bias = -5.6903447644078105 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 942   loss = 2.29617814615259  weights = [-0.3188039250819532, 1.2429807478891783] bias = -5.713322532914397 ---->\n",
      "Epoch : 943   loss = 10.115397344620392  weights = [0.8993727706558217, 1.26343505318025] bias = -5.688322797925978 ---->\n",
      "Epoch : 944   loss = 9.357943154433316  weights = [0.19710121013071702, 1.2520714540568378] bias = -5.713322734982622 ---->\n",
      "Epoch : 945   loss = 0.6917251860291163  weights = [-0.17204059435238223, 1.2477425671467457] bias = -5.723637948102281 ---->\n",
      "Epoch : 946   loss = 6.543009191135822  weights = [1.0460432176270047, 1.268192927223445] bias = -5.698642741121041 ---->\n",
      "Epoch : 947   loss = 10.70150287962716  weights = [0.3437705680392884, 1.2568292934787877] bias = -5.723642736911121 ---->\n",
      "Epoch : 948   loss = 2.2971477133551077  weights = [-0.31738626333417996, 1.2464608819579066] bias = -5.746607966259734 ---->\n",
      "Epoch : 949   loss = 10.096076960348874  weights = [0.900790444837243, 1.2669151878827962] bias = -5.721608230550098 ---->\n",
      "Epoch : 950   loss = 9.358134161966984  weights = [0.19851889008512769, 1.2555515889101565] bias = -5.746608167294475 ---->\n",
      "Epoch : 951   loss = 0.6956295692744768  weights = [-0.17117299725289448, 1.2512188867767633] bias = -5.7569367159221825 ---->\n",
      "Epoch : 952   loss = 6.537097431624929  weights = [1.0469119736127825, 1.2716692983305953] bias = -5.731941449342544 ---->\n",
      "Epoch : 953   loss = 10.696647547575994  weights = [0.3446393252089126, 1.260305664623109] bias = -5.756941445068546 ---->\n",
      "Epoch : 954   loss = 2.2940653362462555  weights = [-0.31605228479277747, 1.2499487704365198] bias = -5.7798834445111655 ---->\n",
      "Epoch : 955   loss = 10.078787245129517  weights = [0.9021244439869102, 1.2704030773705202] bias = -5.754883707662721 ---->\n",
      "Epoch : 956   loss = 9.357562715360537  weights = [0.19985289685488417, 1.2590394786057726] bias = -5.779883643995396 ---->\n",
      "Epoch : 957   loss = 0.6989242204264001  weights = [-0.17011791874261434, 1.2547081650901395] bias = -5.790215061530883 ---->\n",
      "Epoch : 958   loss = 6.526602809259077  weights = [1.0479678101315604, 1.275158611877414] bias = -5.765219754268692 ---->\n",
      "Epoch : 959   loss = 10.693521483271287  weights = [0.3456951626511402, 1.2637949781984288] bias = -5.79021974994471 ---->\n",
      "Epoch : 960   loss = 2.293472154331491  weights = [-0.3146647939389662, 1.2534464700727492] bias = -5.813144911199453 ---->\n",
      "Epoch : 961   loss = 10.060182761637982  weights = [0.9035119498926563, 1.2739007777606557] bias = -5.788145173496456 ---->\n",
      "Epoch : 962   loss = 9.357490516792689  weights = [0.2012404092299075, 1.2625371791673525] bias = -5.8131451094794 ---->\n",
      "Epoch : 963   loss = 0.7026242747206267  weights = [-0.1691687384838248, 1.258204075381042] bias = -5.8234858972428825 ---->\n",
      "Epoch : 964   loss = 6.518681593476214  weights = [1.0489179529454515, 1.2786545656310835] bias = -5.798490539707167 ---->\n",
      "Epoch : 965   loss = 10.689428884926862  weights = [0.34664530655633974, 1.267290931986065] bias = -5.823490535324118 ---->\n",
      "Epoch : 966   loss = 2.291492290970083  weights = [-0.31330372294677633, 1.256952685385564] bias = -5.846395055536943 ---->\n",
      "Epoch : 967   loss = 10.04221281471119  weights = [0.9048730383647625, 1.2774069939387283] bias = -5.821395316855631 ---->\n",
      "Epoch : 968   loss = 9.357182324289347  weights = [0.20260150477582006, 1.2660433955351595] bias = -5.846395252456308 ---->\n",
      "Epoch : 969   loss = 0.7061374789890663  weights = [-0.16815603145665448, 1.2617101838790157] bias = -5.856742057606742 ---->\n",
      "Epoch : 970   loss = 6.50920125891866  weights = [1.0499314806610793, 1.2821607118368414] bias = -5.831746656493971 ---->\n",
      "Epoch : 971   loss = 10.685927038954548  weights = [0.3476588352806711, 1.2707970782229945] bias = -5.856746652056327 ---->\n",
      "Epoch : 972   loss = 2.290362594702847  weights = [-0.3119238259581951, 1.2604680531125507] bias = -5.879632659950337 ---->\n",
      "Epoch : 973   loss = 10.023774186042825  weights = [0.9062529507627326, 1.2809223624358912] bias = -5.854632920396717 ---->\n",
      "Epoch : 974   loss = 9.35705418726515  weights = [0.20398142385156315, 1.2695587642091775] bias = -5.879632855636461 ---->\n",
      "Epoch : 975   loss = 0.709799210192526  weights = [-0.16717534685584517, 1.2652243837922283] bias = -5.88998789258369 ---->\n",
      "Epoch : 976   loss = 6.500492585691254  weights = [1.050913038358288, 1.2856749515392625] bias = -5.864992445464258 ---->\n",
      "Epoch : 977   loss = 10.682137620938665  weights = [0.3486403940470596, 1.2743113179585046] bias = -5.889992440968749 ---->\n",
      "Epoch : 978   loss = 2.288822052195663  weights = [-0.3105502001687488, 1.2639921301448471] bias = -5.912858699891689 ---->\n",
      "Epoch : 979   loss = 10.005479001027005  weights = [0.9076265923865652, 1.2844464402578006] bias = -5.887858959444306 ---->\n",
      "Epoch : 980   loss = 9.356875176795587  weights = [0.20535507231404204, 1.2730828422123972] bias = -5.9128588943144695 ---->\n",
      "Epoch : 981   loss = 0.7134230522857171  weights = [-0.16617433606737386, 1.2687477451875973] bias = -5.9232213017879625 ---->\n",
      "Epoch : 982   loss = 6.491278781950546  weights = [1.051914869421032, 1.2891983505684643] bias = -5.898225811165713 ---->\n",
      "Epoch : 983   loss = 10.678541757952525  weights = [0.34964222616011453, 1.2778347170201003] bias = -5.923225806613361 ---->\n",
      "Epoch : 984   loss = 2.287560957211209  weights = [-0.30916941002045717, 1.2675250669783122] bias = -5.9460729389892775 ---->\n",
      "Epoch : 985   loss = 9.986999742215074  weights = [0.9090073974688693, 1.2879793778395445] bias = -5.921073197694308 ---->\n",
      "Epoch : 986   loss = 9.356768778198399  weights = [0.20673588409489685, 1.2766157799705498] bias = -5.9460731322024465 ---->\n",
      "Epoch : 987   loss = 0.7171087120397386  weights = [-0.16518113182284228, 1.2722796089920823] bias = -5.9564436955164926 ---->\n",
      "Epoch : 988   loss = 6.482246185119812  weights = [1.052908897615972, 1.2927302521261888] bias = -5.931448161246683 ---->\n",
      "Epoch : 989   loss = 10.674880495481615  weights = [0.3506362554297229, 1.2813666186109436] bias = -5.956448156636172 ---->\n",
      "Epoch : 990   loss = 2.2862083527608514  weights = [-0.307788587989417, 1.2710667014245296] bias = -5.9792757816481 ---->\n",
      "Epoch : 991   loss = 9.968510450489955  weights = [0.9103882342418016, 1.2915210130252046] bias = -5.954276039515554 ---->\n",
      "Epoch : 992   loss = 9.356669314395397  weights = [0.2081167275858059, 1.280157415332674] bias = -5.979275973660634 ---->\n",
      "Epoch : 993   loss = 0.720803021029663  weights = [-0.16418118229031903, 1.2758202385127848] bias = -5.989654610436821 ---->\n",
      "Epoch : 994   loss = 6.473039947051737  weights = [1.0539096461165025, 1.296270918369799] bias = -5.964659033713152 ---->\n",
      "Epoch : 995   loss = 10.671287373325537  weights = [0.3516370050066908, 1.2849072848876542] bias = -5.989659029044389 ---->\n",
      "Epoch : 996   loss = 2.284955831392627  weights = [-0.30640416571084206, 1.2746170368430854] bias = -6.012467290744833 ---->\n",
      "Epoch : 997   loss = 9.949924217927393  weights = [0.9117726707228353, 1.2950713491584662] bias = -5.987467547802411 ---->\n",
      "Epoch : 998   loss = 9.356609519659024  weights = [0.20950117072291552, 1.2837077516399327] bias = -6.01246748158778 ---->\n",
      "Epoch : 999   loss = 0.7245324316140644  weights = [-0.16318200167567687, 1.2793694223979268] bias = -6.022854546661757 ---->\n",
      "Epoch : 1000   loss = 6.463843463562068  weights = [1.0549096157396014, 1.2998201385521664] bias = -5.997858927974048 ---->\n",
      "Epoch : 1001   loss = 10.667693963522634  weights = [0.35263697571986485, 1.288456505103492] bias = -6.022858923246295 ---->\n",
      "Epoch : 1002   loss = 2.283704339640941  weights = [-0.3050179964338424, 1.2781759961545256] bias = -6.045647695268465 ---->\n",
      "Epoch : 1003   loss = 9.931286342251784  weights = [0.9131588538486657, 1.298630309168412] bias = -6.020647951534368 ---->\n",
      "Epoch : 1004   loss = 9.356572264471597  weights = [0.21088736048431778, 1.2872667118226933] bias = -6.045647884961144 ---->\n",
      "Epoch : 1005   loss = 0.7282830202677942  weights = [-0.16217999070220745, 1.2829271919986773] bias = -6.056043510837281 ---->\n",
      "Epoch : 1006   loss = 6.454569040016642  weights = [1.0559123989261037, 1.303377943752248] bias = -6.031047850992122 ---->\n",
      "Epoch : 1007   loss = 10.66413274187576  weights = [0.35363976000438757, 1.2920143103372257] bias = -6.056047846204952 ---->\n",
      "Epoch : 1008   loss = 2.2825011330895806  weights = [-0.3036292550064369, 1.2817435450203483] bias = -6.078817134826654 ---->\n",
      "Epoch : 1009   loss = 9.912576803689928  weights = [0.9145476086940608, 1.302197858713023] bias = -6.053817390322994 ---->\n",
      "Epoch : 1010   loss = 9.35656505338351  weights = [0.2122761219252599, 1.290834261538334] bias = -6.078817323393347 ---->\n",
      "Epoch : 1011   loss = 0.7320608349455315  weights = [-0.16117700508912797, 1.2864934623094748] bias = -6.089221745320734 ---->\n",
      "Epoch : 1012   loss = 6.445262040853951  weights = [1.0569161437571595, 1.3069442491183385] bias = -6.06422604494561 ---->\n",
      "Epoch : 1013   loss = 10.660586653319681  weights = [0.35464350594445193, 1.295580615737249] bias = -6.0892260400984295 ---->\n",
      "Epoch : 1014   loss = 2.281321699028872  weights = [-0.3022384023983089, 1.2853196316678925] bias = -6.111975785022461 ---->\n",
      "Epoch : 1015   loss = 9.893806942070896  weights = [0.9159384743378287, 1.3057739460218805] bias = -6.086976039768855 ---->\n",
      "Epoch : 1016   loss = 9.356583583097619  weights = [0.21366699413446932, 1.2944103490167438] bias = -6.11197597248442 ---->\n",
      "Epoch : 1017   loss = 0.7358623286454193  weights = [-0.16017229367343594, 1.2900682069958191] bias = -6.122389372708965 ---->\n",
      "Epoch : 1018   loss = 6.4359042382172085  weights = [1.0579216001326488, 1.3105190282671746] bias = -6.097393632488043 ---->\n",
      "Epoch : 1019   loss = 10.657062486309206  weights = [0.35564896343876384, 1.299155394920258] bias = -6.122393627580324 ---->\n",
      "Epoch : 1020   loss = 2.280175809846794  weights = [-0.30084529555978057, 1.2889042154305255] bias = -6.145123797651581 ---->\n",
      "Epoch : 1021   loss = 9.874973364728927  weights = [0.9173315938189649, 1.309358530427883] bias = -6.120124051668161 ---->\n",
      "Epoch : 1022   loss = 9.35662908769745  weights = [0.21506012014699383, 1.297994933590701] bias = -6.1451239840307865 ---->\n",
      "Epoch : 1023   loss = 0.739688469724004  weights = [-0.15916631960701466, 1.2936513751918777] bias = -6.155546564767571 ---->\n",
      "Epoch : 1024   loss = 6.426507021832461  weights = [1.0589283059644963, 1.3141022303770975] bias = -6.13055078533356 ---->\n",
      "Epoch : 1025   loss = 10.653555981310822  weights = [0.35665567040007184, 1.3027385970646201] bias = -6.155550780364729 ---->\n",
      "Epoch : 1026   loss = 2.279057283280997  weights = [-0.29945006494200177, 1.2924972534787762] bias = -6.178261328605657 ---->\n",
      "Epoch : 1027   loss = 9.856079345378793  weights = [0.9187268367021093, 1.3129515691023033] bias = -6.153261581911729 ---->\n",
      "Epoch : 1028   loss = 9.356700295946327  weights = [0.21645536952986788, 1.3015879724315536] bias = -6.178261513923136 ---->\n",
      "Epoch : 1029   loss = 0.7435381844085562  weights = [-0.158158996003251, 1.2972429299393338] bias = -6.188693464365912 ---->\n",
      "Epoch : 1030   loss = 6.4170683613370985  weights = [1.0599363481414135, 1.317693818491567] bias = -6.163697646349395 ---->\n",
      "Epoch : 1031   loss = 10.650067784328867  weights = [0.35766371371700423, 1.3063301852137905] bias = -6.188697641318883 ---->\n",
      "Epoch : 1032   loss = 2.2779671666063046  weights = [-0.298052717776049, 1.296098706738274] bias = -6.211388525329449 ---->\n",
      "Epoch : 1033   loss = 9.837125149898952  weights = [0.9201241957598225, 1.3165530229709583] bias = -6.186388777944108 ---->\n",
      "Epoch : 1034   loss = 9.35679707593836  weights = [0.21785273505520397, 1.3051894264651056] bias = -6.21138870960604 ---->\n",
      "Epoch : 1035   loss = 0.7474113243386037  weights = [-0.15715047897616752, 1.3008428308112598] bias = -6.221830220733769 ---->\n",
      "Epoch : 1036   loss = 6.407592150928815  weights = [1.0609455710031572, 1.3212937522033932] bias = -6.196834364742304 ---->\n",
      "Epoch : 1037   loss = 10.646596533485651  weights = [0.35867293772965025, 1.3099301189605892] bias = -6.221834359649524 ---->\n",
      "Epoch : 1038   loss = 2.276903321639538  weights = [-0.2966533126122015, 1.2997085372348791] bias = -6.244505532445106 ---->\n",
      "Epoch : 1039   loss = 9.818112292623958  weights = [0.9215236124502766, 1.3201628540601158] bias = -6.219505784386992 ---->\n",
      "Epoch : 1040   loss = 9.356918825129485  weights = [0.21925215818194332, 1.30879925771765] bias = -6.244505715701152 ---->\n",
      "Epoch : 1041   loss = 0.7513073596349986  weights = [-0.15614082037585608, 1.3044510414772272] bias = -6.254956974092993 ---->\n",
      "Epoch : 1042   loss = 6.398079738568719  weights = [1.0619559229472342, 1.3249019951936474] bias = -6.2299610807206935 ---->\n",
      "Epoch : 1043   loss = 10.643141319223936  weights = [0.35968329083567774, 1.313538361986091] bias = -6.254961075565049 ---->\n",
      "Epoch : 1044   loss = 2.2758649827596327  weights = [-0.2952518845522335, 1.3033267091681406] bias = -6.27761248943946 ---->\n",
      "Epoch : 1045   loss = 9.799041713143104  weights = [0.9229250516777184, 1.323781026569621] bias = -6.252612740726881 ---->\n",
      "Epoch : 1046   loss = 9.35706515291517  weights = [0.22065360381456922, 1.3124174303890406] bias = -6.2776126716949605 ---->\n",
      "Epoch : 1047   loss = 0.7552259392814058  weights = [-0.15513011557192913, 1.3080675264172508] bias = -6.2880738623136745 ---->\n",
      "Epoch : 1048   loss = 6.388533530938136  weights = [1.0629673089240548, 1.3285185119566871] bias = -6.263077932137908 ---->\n",
      "Epoch : 1049   loss = 10.639701829917513  weights = [0.3606946779857405, 1.3171548787846599] bias = -6.288077926918791 ---->\n",
      "Epoch : 1050   loss = 2.2748508182187734  weights = [-0.29384847638114175, 1.3069531884070686] bias = -6.310709531731242 ---->\n",
      "Epoch : 1051   loss = 9.779914535519303  weights = [0.92432847066376, 1.3274075063688078] bias = -6.2857097823821455 ---->\n",
      "Epoch : 1052   loss = 9.357235595593032  weights = [0.2220570291751296, 1.3160439103486254] bias = -6.310709713005813 ---->\n",
      "Epoch : 1053   loss = 0.7591666575225408  weights = [-0.15411844205161496, 1.311692252231381] bias = -6.321181018248902 ---->\n",
      "Epoch : 1054   loss = 6.3789554957024075  weights = [1.0639796517242703, 1.3321432691051989] bias = -6.296185051832272 ---->\n",
      "Epoch : 1055   loss = 10.636276816822418  weights = [0.36170702197071014, 1.320779635968988] bias = -6.321185046549062 ---->\n",
      "Epoch : 1056   loss = 2.273859735176586  weights = [-0.2924431259387277, 1.3105879426357392] bias = -6.343796790342745 ---->\n",
      "Epoch : 1057   loss = 9.760731760392424  weights = [0.925733831574584, 1.3310422611420465] bias = -6.318797040374747 ---->\n",
      "Epoch : 1058   loss = 9.357429750343922  weights = [0.22346239643014176, 1.3196786652807866] bias = -6.343796970655652 ---->\n",
      "Epoch : 1059   loss = 0.7631291486830505  weights = [-0.15310588404504583, 1.3153251870557197] bias = -6.354278570912786 ---->\n",
      "Epoch : 1060   loss = 6.369347762257829  weights = [1.0649928673995823, 1.3357762347880433] bias = -6.329282568802992 ---->\n",
      "Epoch : 1061   loss = 10.632866070283137  weights = [0.3627202388425259, 1.3244126016879423] bias = -6.3542825634550555 ---->\n",
      "Epoch : 1062   loss = 2.272890556927072  weights = [-0.29103587108745155, 1.3142309412390893] bias = -6.376874392136045 ---->\n",
      "Epoch : 1063   loss = 9.741494386178614  weights = [0.9271410965535717, 1.3346852602745627] bias = -6.351874641566441 ---->\n",
      "Epoch : 1064   loss = 9.35764721608317  weights = [0.22486966772333805, 1.3233216645707615] bias = -6.376874571506216 ---->\n",
      "Epoch : 1065   loss = 0.7671130497927193  weights = [-0.15209252274505086, 1.3189663007380261] bias = -6.387366645120825 ---->\n",
      "Epoch : 1066   loss = 6.359712383214932  weights = [1.0660068750251848, 1.339417378865158] bias = -6.362370607851336 ---->\n",
      "Epoch : 1067   loss = 10.629467971511641  weights = [0.36373424767662244, 1.3280537458014663] bias = -6.387370602438026 ---->\n",
      "Epoch : 1068   loss = 2.2719421509697177  weights = [-0.2896267478068034, 1.317882155290346] bias = -6.409942459830726 ---->\n",
      "Epoch : 1069   loss = 9.722203362656437  weights = [0.9285502296267544, 1.3383364748398567] bias = -6.384942708676505 ---->\n",
      "Epoch : 1070   loss = 9.357887606848985  weights = [0.2262788070810705, 1.3269728792920612] bias = -6.409942638276762 ---->\n",
      "Epoch : 1071   loss = 0.7711180149005795  weights = [-0.15107843991990938, 1.3226155647176754] bias = -6.420445361731822 ---->\n",
      "Epoch : 1072   loss = 6.350051422581959  weights = [1.0670215930939475, 1.3430666727877907] bias = -6.395449289822231 ---->\n",
      "Epoch : 1073   loss = 10.626082206574656  weights = [0.3647489669661189, 1.3317030397608143] bias = -6.420449284342889 ---->\n",
      "Epoch : 1074   loss = 2.2710133817052074  weights = [-0.28821579090370164, 1.3215415575005771] bias = -6.443001112106781 ---->\n",
      "Epoch : 1075   loss = 9.702859608346762  weights = [0.9299611959924886, 1.3419958775492598] bias = -6.418001360384636 ---->\n",
      "Epoch : 1076   loss = 9.358150542103093  weights = [0.22768977970200244, 1.3306322821560275] bias = -6.4430012896469755 ---->\n",
      "Epoch : 1077   loss = 0.7751437096959087  weights = [-0.1500637164686331, 1.3262729520182719] bias = -6.4535148376638 ---->\n",
      "Epoch : 1078   loss = 6.340366920579402  weights = [1.0680369409587929, 1.3467240895910222] bias = -6.428518731620289 ---->\n",
      "Epoch : 1079   loss = 10.622707663969054  weights = [0.365764316064193, 1.3353604566010737] bias = -6.453518726074241 ---->\n",
      "Epoch : 1080   loss = 2.2701031292217553  weights = [-0.2868030337610066, 1.3252091221828297] bias = -6.476050463677767 ---->\n",
      "Epoch : 1081   loss = 9.683464004436935  weights = [0.9313739622729222, 1.3456634427160687] bias = -6.451050711404114 ---->\n",
      "Epoch : 1082   loss = 9.35843565452895  weights = [0.22910255220856857, 1.3342998474759669] bias = -6.476050640330118 ---->\n",
      "Epoch : 1083   loss = 0.7791898133769436  weights = [-0.14904843284276909, 1.329938437199419] bias = -6.486575185994727 ---->\n",
      "Epoch : 1084   loss = 6.330660903985758  weights = [1.0690528384119498, 1.3503896038455772] bias = -6.46157904631048 ---->\n",
      "Epoch : 1085   loss = 10.61934368585639  weights = [0.36678021476333544, 1.3390259708929761] bias = -6.486579040697038 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1086   loss = 2.269210283764981  weights = [-0.2853885084345985, 1.328884825211784] bias = -6.509090625376033 ---->\n",
      "Epoch : 1087   loss = 9.664017397205038  weights = [0.9327884964169287, 1.3493391462152033] bias = -6.484090872567019 ---->\n",
      "Epoch : 1088   loss = 9.358742615545724  weights = [0.23051709254990793, 1.3379755511268085] bias = -6.509090801158257 ---->\n",
      "Epoch : 1089   loss = 0.7832560178899733  weights = [-0.14803266880921445, 1.333611996323819] bias = -6.51962651603421 ---->\n",
      "Epoch : 1090   loss = 6.320935380408257  weights = [1.0700692059219912, 1.3540631916249197] bias = -6.494630343189828 ---->\n",
      "Epoch : 1091   loss = 10.615990031652375  weights = [0.3677965835323884, 1.3426995587099926] bias = -6.519630337508289 ---->\n",
      "Epoch : 1092   loss = 2.2683337487934376  weights = [-0.28397224563238366, 1.3325686439857516] bias = -6.542121704234832 ---->\n",
      "Epoch : 1093   loss = 9.644520597565002  weights = [0.934204767721105, 1.3530229654452028] bias = -6.517121950906348 ---->\n",
      "Epoch : 1094   loss = 9.359071084862647  weights = [0.23193337002286363, 1.3416593705070998] bias = -6.542121879164376 ---->\n",
      "Epoch : 1095   loss = 0.7873420280597897  weights = [-0.14701650344869144, 1.337293606919806] bias = -6.552668933406271 ---->\n",
      "Epoch : 1096   loss = 6.311192338302162  weights = [1.0710859646356372, 1.3577448304677981] bias = -6.52767272787018 ---->\n",
      "Epoch : 1097   loss = 10.612645055182067  weights = [0.3688133435183474, 1.3463811975908782] bias = -6.552672722119828 ---->\n",
      "Epoch : 1098   loss = 2.267472440911596  weights = [-0.28255427473614814, 1.336260557388724] bias = -6.575143803572299 ---->\n",
      "Epoch : 1099   loss = 9.624974381656555  weights = [0.9356227468079222, 1.3567148792902757] bias = -6.550144049739995 ---->\n",
      "Epoch : 1100   loss = 9.359420752976428  weights = [0.23335135525013095, 1.3453512845010571] bias = -6.575143977666357 ---->\n",
      "Epoch : 1101   loss = 0.7914475613959163  weights = [-0.14600001508185212, 1.3409832479462271] bias = -6.585702540129153 ---->\n",
      "Epoch : 1102   loss = 6.301433745224523  weights = [1.0721030364517912, 1.3614344993431318] bias = -6.560706302358003 ---->\n",
      "Epoch : 1103   loss = 10.609308184855903  weights = [0.3698304166203976, 1.3500708665045598] bias = -6.585706296538106 ---->\n",
      "Epoch : 1104   loss = 2.2666252908135154  weights = [-0.28113462381201715, 1.33996054575329] bias = -6.6081570230753615 ---->\n",
      "Epoch : 1105   loss = 9.605379491157178  weights = [0.93704240561527, 1.3604148680832164] bias = -6.583157268754655 ---->\n",
      "Epoch : 1106   loss = 9.359791301247723  weights = [0.23477102016980234, 1.3490512734414823] bias = -6.608157196350886 ---->\n",
      "Epoch : 1107   loss = 0.7955723479849387  weights = [-0.144983281225658, 1.3446808997573956] bias = -6.618727434696591 ---->\n",
      "Epoch : 1108   loss = 6.291661546826228  weights = [1.0731203440653438, 1.3651321786149722] bias = -6.593731165135641 ---->\n",
      "Epoch : 1109   loss = 10.605979157913493  weights = [0.37084772553371903, 1.3537685458150963] bias = -6.618731159245452 ---->\n",
      "Epoch : 1110   loss = 2.2657912437433243  weights = [-0.2797133196268887, 1.3436685908241959] bias = -6.641161458883965 ---->\n",
      "Epoch : 1111   loss = 9.585736633739485  weights = [0.9384637173800295, 1.3641229135689672] bias = -6.6161617040900556 ---->\n",
      "Epoch : 1112   loss = 9.360182459974466  weights = [0.23619233801893935, 1.3527593190733236] bias = -6.641161631357679 ---->\n",
      "Epoch : 1113   loss = 0.7997161303374792  weights = [-0.1439663785465468, 1.3483865440688905] bias = -6.651743712158895 ---->\n",
      "Epoch : 1114   loss = 6.281877665765318  weights = [1.0741378110141848, 1.3688378500083112] bias = -6.626747411242397 ---->\n",
      "Epoch : 1115   loss = 10.60265691026671  weights = [0.3718651937964973, 1.3574742172474872] bias = -6.651747405281151 ---->\n",
      "Epoch : 1116   loss = 2.2649692600884657  weights = [-0.2782903876651065, 1.3473846757226582] bias = -6.674157203675279 ---->\n",
      "Epoch : 1117   loss = 9.566046483534144  weights = [0.9398866566214034, 1.36783899886893] bias = -6.649157448423159 ---->\n",
      "Epoch : 1118   loss = 9.360593937621356  weights = [0.23761528331690318, 1.3564754045179885] bias = -6.6741573753636905 ---->\n",
      "Epoch : 1119   loss = 0.8038786632332694  weights = [-0.142949382820645, 1.3521001639239894] bias = -6.684751464204157 ---->\n",
      "Epoch : 1120   loss = 6.272084000791782  weights = [1.0751553617191718, 1.3725514965755206] bias = -6.659755132355725 ---->\n",
      "Epoch : 1121   loss = 10.599340750743472  weights = [0.37288274582989234, 1.361187863854112] bias = -6.684755126322642 ---->\n",
      "Epoch : 1122   loss = 2.264158315809111  weights = [-0.2768658521468701, 1.351108784911425] bias = -6.707144346747775 ---->\n",
      "Epoch : 1123   loss = 9.546309681634751  weights = [0.9413111991225105, 1.3715631084460274] bias = -6.6821445910522375 ---->\n",
      "Epoch : 1124   loss = 9.361025484264792  weights = [0.23903983184694755, 1.3601995142384051] bias = -6.707144517667187 ---->\n",
      "Epoch : 1125   loss = 0.8080597135529973  weights = [-0.14193236889766747, 1.3558217436608229] bias = -6.717750779239301 ---->\n",
      "Epoch : 1126   loss = 6.262282425921794  weights = [1.076172921520412, 1.376273102663515] bias = -6.692754416872273 ---->\n",
      "Epoch : 1127   loss = 10.596030152193025  weights = [0.37390030697432064, 1.3649094699818936] bias = -6.717754410766556 ---->\n",
      "Epoch : 1128   loss = 2.263357402858519  weights = [-0.2754397360477179, 1.3548409041606069] bias = -6.740122974105018 ---->\n",
      "Epoch : 1129   loss = 9.526526836628351  weights = [0.9427373219109065, 1.3752952280705362] bias = -6.715123217980674 ---->\n",
      "Epoch : 1130   loss = 9.361476845344818  weights = [0.24046596063674053, 1.3639316340048542] bias = -6.740123144271545 ---->\n",
      "Epoch : 1131   loss = 0.8122590601020817  weights = [-0.14091541066922258, 1.3595512688802422] bias = -6.750741742470875 ---->\n",
      "Epoch : 1132   loss = 6.2524747897188755  weights = [1.0771904167091433, 1.3800026538816272] bias = -6.725745349988664 ---->\n",
      "Epoch : 1133   loss = 10.592723974882652  weights = [0.37491780352133564, 1.3686390212401722] bias = -6.750745343809501 ---->\n",
      "Epoch : 1134   loss = 2.2625655295230946  weights = [-0.2740120611190501, 1.3585810205142932] bias = -6.77309316853905 ---->\n",
      "Epoch : 1135   loss = 9.506698525150817  weights = [0.9441650032380663, 1.379035344786701] bias = -6.748093412000332 ---->\n",
      "Epoch : 1136   loss = 9.361947782287288  weights = [0.24189364793784596, 1.3676717508615839] bias = -6.773093337968622 ---->\n",
      "Epoch : 1137   loss = 0.8164764934266647  weights = [-0.1398985810410701, 1.3632887264144156] bias = -6.783724435985441 ---->\n",
      "Epoch : 1138   loss = 6.242662914670863  weights = [1.0782077745556586, 1.3837401370702116] bias = -6.758728013781882 ---->\n",
      "Epoch : 1139   loss = 10.589421622542922  weights = [0.3759351627415538, 1.3723765044693108] bias = -6.783728007528441 ---->\n",
      "Epoch : 1140   loss = 2.2617817207415296  weights = [-0.2725828479094964, 1.362329122257959] bias = -6.806055009713217 ---->\n",
      "Epoch : 1141   loss = 9.48682529246218  weights = [0.9455942225580197, 1.3827834468801437] bias = -6.781055252774396 ---->\n",
      "Epoch : 1142   loss = 9.36243807037232  weights = [0.2433228732043594, 1.371419853094219] bias = -6.806055178421602 ---->\n",
      "Epoch : 1143   loss = 0.8207118156232073  weights = [-0.13888195190919228, 1.36703410429616] bias = -6.816698938829483 ---->\n",
      "Epoch : 1144   loss = 6.232848596659211  weights = [1.0792249233334208, 1.3874855402699855] bias = -6.791702487289165 ---->\n",
      "Epoch : 1145   loss = 10.586122487663932  weights = [0.37695231290876763, 1.3761219077100353] bias = -6.816702480960598 ---->\n",
      "Epoch : 1146   loss = 2.261005018288473  weights = [-0.27115211578699816, 1.366085198886671] bias = -6.839008574244378 ---->\n",
      "Epoch : 1147   loss = 9.46690765303874  weights = [0.947024960505272, 1.3865395238460678] bias = -6.81400881691957 ---->\n",
      "Epoch : 1148   loss = 9.36294750358754  weights = [0.244753617070828, 1.3751759301979651] bias = -6.8390087422471835 ---->\n",
      "Epoch : 1149   loss = 0.824964840142928  weights = [-0.13786559413945026, 1.3707873917290108] bias = -6.849665327088693 ---->\n",
      "Epoch : 1150   loss = 6.223033604515073  weights = [1.0802417923395917, 1.3912388526921047] bias = -6.8246688465872865 ---->\n",
      "Epoch : 1151   loss = 10.582826030389244  weights = [0.3779691833204758, 1.3798752201735098] bias = -6.8496688401827255 ---->\n",
      "Epoch : 1152   loss = 2.2602344810524615  weights = [-0.2697198829614498, 1.369849241074091] bias = -6.871953935784337 ---->\n",
      "Epoch : 1153   loss = 9.446946091178066  weights = [0.9484571988721677, 1.3903035663582641] bias = -6.846954178087512 ---->\n",
      "Epoch : 1154   loss = 9.363475878267804  weights = [0.24618586132961529, 1.3789399728466145] bias = -6.8719541030970275 ---->\n",
      "Epoch : 1155   loss = 0.8292353915922056  weights = [-0.13684957755066507, 1.374548579058028] bias = -6.88262367396656 ---->\n",
      "Epoch : 1156   loss = 6.213219679658139  weights = [1.0812583119121342, 1.3950000646889793] bias = -6.857627164871131 ---->\n",
      "Epoch : 1157   loss = 10.579531227881818  weights = [0.3789857043149847, 1.3836364322121533] bias = -6.882627158389691 ---->\n",
      "Epoch : 1158   loss = 2.2594691851684288  weights = [-0.26828616650779336, 1.3736212406422803] bias = -6.904891165100443 ---->\n",
      "Epoch : 1159   loss = 9.426941061614345  weights = [0.9498909205857986, 1.394075566238913] bias = -6.879891407045438 ---->\n",
      "Epoch : 1160   loss = 9.364023006142908  weights = [0.2476195889078081, 1.382711972862348] bias = -6.904891331738347 ---->\n",
      "Epoch : 1161   loss = 0.8335233055297205  weights = [-0.1358339709008674, 1.3783176577413396] bias = -6.915574049862165 ---->\n",
      "Epoch : 1162   loss = 6.203408535811999  weights = [1.0822744134437483, 1.3987691677258232] bias = -6.890577512531485 ---->\n",
      "Epoch : 1163   loss = 10.576237905619958  weights = [0.38000180728534505, 1.3874055352911885] bias = -6.915577505972262 ---->\n",
      "Epoch : 1164   loss = 2.2587082240687293  weights = [-0.26685098238942184, 1.3774011905322947] bias = -6.937820330155267 ---->\n",
      "Epoch : 1165   loss = 9.40689299014041  weights = [0.951326109684604, 1.3978555164291815] bias = -6.912820571755794 ---->\n",
      "Epoch : 1166   loss = 9.364588719982676  weights = [0.24905478384381685, 1.3864919231863326] bias = -6.937820496133592 ---->\n",
      "Epoch : 1167   loss = 0.8378284282616303  weights = [-0.13481884187658455, 1.3820946203224138] bias = -6.948516522447126 ---->\n",
      "Epoch : 1168   loss = 6.19360185879276  weights = [1.083290029392768, 1.402546154352935] bias = -6.923519957231969 ---->\n",
      "Epoch : 1169   loss = 10.57294511423833  weights = [0.3810174246902496, 1.391182521960923] bias = -6.948519950594038 ---->\n",
      "Epoch : 1170   loss = 2.257950708631432  weights = [-0.265414345481802, 1.3811890847755697] bias = -6.9707414961852825 ---->\n",
      "Epoch : 1171   loss = 9.386802274234327  weights = [0.9527627512947504, 1.4016434109606075] bias = -6.945741737454935 ---->\n",
      "Epoch : 1172   loss = 9.36517283909099  weights = [0.2504914312637564, 1.390279817850106] bias = -6.970741661519122 ---->\n",
      "Epoch : 1173   loss = 0.8421506166354313  weights = [-0.13380425708492788, 1.3858794604030567] bias = -6.981451156741583 ---->\n",
      "Epoch : 1174   loss = 6.183801306365146  weights = [1.0843050932912546, 1.406331018178703] bias = -6.956454563985015 ---->\n",
      "Epoch : 1175   loss = 10.569652354030124  weights = [0.3820324900621237, 1.3949673858297547] bias = -6.981454557267434 ---->\n",
      "Epoch : 1176   loss = 2.257195767208151  weights = [-0.2639762695962007, 1.3849849184660827] bias = -7.003654725778471 ---->\n",
      "Epoch : 1177   loss = 9.36666928368764  weights = [0.954200831606409, 1.4054392449272632] bias = -6.978654966730739 ---->\n",
      "Epoch : 1178   loss = 9.365775232216562  weights = [0.25192951735772184, 1.3940756519477382] bias = -7.0036548904828155 ---->\n",
      "Epoch : 1179   loss = 0.8464897378333902  weights = [-0.13279028204832422, 1.3896721726171213] bias = -7.01437801518921 ---->\n",
      "Epoch : 1180   loss = 6.174008508162202  weights = [1.0853195397504463, 1.410123753843322] bias = -6.989381395226872 ---->\n",
      "Epoch : 1181   loss = 10.566358558727792  weights = [0.38304693801257883, 1.3987601215378873] bias = -7.014381388428678 ---->\n",
      "Epoch : 1182   loss = 2.2564425455827855  weights = [-0.2625367675034267, 1.388788687733282] bias = -7.036560078950824 ---->\n",
      "Epoch : 1183   loss = 9.346494361233141  weights = [0.955640337850016, 1.4092430144586832] bias = -7.011560319599098 ---->\n",
      "Epoch : 1184   loss = 9.366395736211553  weights = [0.2533690293560512, 1.3978794216087622] bias = -7.036560243040572 ---->\n",
      "Epoch : 1185   loss = 0.8508456691663144  weights = [-0.1317769812017065, 1.3934727526049202] bias = -7.047297157731157 ---->\n",
      "Epoch : 1186   loss = 6.164225065664137  weights = [1.0863333044637518, 1.4139243569932125] bias = -7.0223005108915375 ---->\n",
      "Epoch : 1187   loss = 10.563063695564795  weights = [0.3840607042354034, 1.402560724731751] bias = -7.047300504011746 ---->\n",
      "Epoch : 1188   loss = 2.255690207016055  weights = [-0.26109585095749943, 1.3926003897157673] bias = -7.069457613221655 ---->\n",
      "Epoch : 1189   loss = 9.32627782316993  weights = [0.9570812582726047, 1.4130547166935454] bias = -7.044457853579234 ---->\n",
      "Epoch : 1190   loss = 9.367034225009922  weights = [0.2548099555056551, 1.401691123971853] bias = -7.069457776711621 ---->\n",
      "Epoch : 1191   loss = 0.8552182978683077  weights = [-0.13076441789198245, 1.3972811969883263] bias = -7.080208641878903 ---->\n",
      "Epoch : 1192   loss = 6.154452552231803  weights = [1.087346324207453, 1.41773282425613] bias = -7.055211968483599 ---->\n",
      "Epoch : 1193   loss = 10.559766806548058  weights = [0.3850737255072667, 1.406369192039111] bias = -7.080211961521205 ---->\n",
      "Epoch : 1194   loss = 2.2549379321031955  weights = [-0.2596535307191662, 1.3964200225357106] bias = -7.102347383687703 ---->\n",
      "Epoch : 1195   loss = 9.306019959983894  weights = [0.9585235821142944, 1.4168743497540932] bias = -7.07734762376781 ---->\n",
      "Epoch : 1196   loss = 9.367690570558446  weights = [0.25625228504650743, 1.4055107571592504] bias = -7.102347546592633 ---->\n",
      "Epoch : 1197   loss = 0.8596075208933254  weights = [-0.1297526543796419, 1.4010975033465485] bias = -7.113112522785965 ---->\n",
      "Epoch : 1198   loss = 6.1446925131914645  weights = [1.0883585368392799, 1.4215491532169475] bias = -7.08811582314994 ---->\n",
      "Epoch : 1199   loss = 10.55646739182389  weights = [0.3860859396862938, 1.4101855210448504] bias = -7.113115816103919 ---->\n",
      "Epoch : 1200   loss = 2.2541849187568737  weights = [-0.25820981657919606, 1.4002475852739982] bias = -7.135229443096001 ---->\n",
      "Epoch : 1201   loss = 9.28572103696185  weights = [0.9599672995849947, 1.4207019127212757] bias = -7.110229682911784 ---->\n",
      "Epoch : 1202   loss = 9.368364684965531  weights = [0.2576960081883496, 1.4093383202518994] bias = -7.135229605430575 ---->\n",
      "Epoch : 1203   loss = 0.8640132447137955  weights = [-0.12874175184231135, 1.404921670192566] bias = -7.146008853318432 ---->\n",
      "Epoch : 1204   loss = 6.134946465966132  weights = [1.0893698812950279, 1.4253733423940966] bias = -7.121012127750266 ---->\n",
      "Epoch : 1205   loss = 10.553164963990845  weights = [0.38709728570868285, 1.4140097102674105] bias = -7.146012120619568 ---->\n",
      "Epoch : 1206   loss = 2.253430382092861  weights = [-0.25676471738138174, 1.4040830779460716] bias = -7.168103841915431 ---->\n",
      "Epoch : 1207   loss = 9.265381294797587  weights = [0.9614124018414064, 1.4245374056105902] bias = -7.143104081479976 ---->\n",
      "Epoch : 1208   loss = 9.3690564431115  weights = [0.25914111608769097, 1.4131738132652925] bias = -7.1681040036942765 ---->\n",
      "Epoch : 1209   loss = 0.8684353851222341  weights = [-0.12773177038013483, 1.4087536969502001] bias = -7.178897684124297 ---->\n",
      "Epoch : 1210   loss = 6.125215900250552  weights = [1.09038029758335, 1.4292053912166465] bias = -7.153900932926419 ---->\n",
      "Epoch : 1211   loss = 10.549858668281374  weights = [0.38810770358349767, 1.417841759135871] bias = -7.178900925709977 ---->\n",
      "Epoch : 1212   loss = 2.2526735542846534  weights = [-0.2553182410451942, 1.4079265014784548] bias = -7.200970628407003 ---->\n",
      "Epoch : 1213   loss = 9.24500095018857  weights = [0.9628588809643699, 1.4283808293486095] bias = -7.175970867733336 ---->\n",
      "Epoch : 1214   loss = 9.369765759922341  weights = [0.2605876008251584, 1.4170172371259973] bias = -7.2009707896447015 ---->\n",
      "Epoch : 1215   loss = 0.8728738670359658  weights = [-0.12672276902282542, 1.4125935839318118] bias = -7.211779063701556 ---->\n",
      "Epoch : 1216   loss = 6.115502278226012  weights = [1.0913897267788775, 1.4330453000020085] bias = -7.18678228717048 ---->\n",
      "Epoch : 1217   loss = 10.546548358181196  weights = [0.38911713438578754, 1.4216816679676534] bias = -7.211782279867201 ---->\n",
      "Epoch : 1218   loss = 2.2519136844022065  weights = [-0.2538703945880332, 1.411777857685944] bias = -7.2338298486927854 ---->\n",
      "Epoch : 1219   loss = 9.22458019642184  weights = [0.9643067299366135, 1.432232185750171] bias = -7.208830087793889 ---->\n",
      "Epoch : 1220   loss = 9.370492549086805  weights = [0.2620354553832438, 1.4208685936488448] bias = -7.233830009403887 ---->\n",
      "Epoch : 1221   loss = 0.8773286243056976  weights = [-0.12571480573824328, 1.4164413323165963] bias = -7.244653038465069 ---->\n",
      "Epoch : 1222   loss = 6.105807034811497  weights = [1.0923981110138072, 1.4368930699342382] bias = -7.219656236891619 ---->\n",
      "Epoch : 1223   loss = 10.543233250532147  weights = [0.3901255202481769, 1.425529437946824] bias = -7.244656229500387 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1224   loss = 2.251150038258902  weights = [-0.25242118414702475, 1.415637149249435] bias = -7.266681546823514 ---->\n",
      "Epoch : 1225   loss = 9.204119203947933  weights = [0.9657559426209597, 1.4360914774962044] bias = -7.241681785712328 ---->\n",
      "Epoch : 1226   loss = 9.371236740200944  weights = [0.26348467362451056, 1.4247278855147578] bias = -7.266681707022539 ---->\n",
      "Epoch : 1227   loss = 0.8817995995281965  weights = [-0.12470793744239289, 1.420296944129462] bias = -7.2775196528121535 ---->\n",
      "Epoch : 1228   loss = 6.096131577948526  weights = [1.0934053934680739, 1.4407487030429191] bias = -7.252522826481674 ---->\n",
      "Epoch : 1229   loss = 10.53991284365073  weights = [0.39113280435103537, 1.4293850711029767] bias = -7.277522819001351 ---->\n",
      "Epoch : 1230   loss = 2.2503818982252315  weights = [-0.2509706150003229, 1.4195043796943687] bias = -7.299525764844833 ---->\n",
      "Epoch : 1231   loss = 9.183618120941823  weights = [0.9672065137390214, 1.4399587081121779] bias = -7.274526003534265 ---->\n",
      "Epoch : 1232   loss = 9.37199827792676  weights = [0.2649352502702911, 1.4285951162491977] bias = -7.299525924546288 ---->\n",
      "Epoch : 1233   loss = 0.8862867438634247  weights = [-0.12370222001069964, 1.424160422220468] bias = -7.31037894918691 ---->\n",
      "Epoch : 1234   loss = 6.086477288916327  weights = [1.094411518358236, 1.4446122021826096] bias = -7.285382098379477 ---->\n",
      "Epoch : 1235   loss = 10.536586661352011  weights = [0.3921389309113642, 1.4332485702906814] bias = -7.3103820908089 ---->\n",
      "Epoch : 1236   loss = 2.249608563042388  weights = [-0.24951869158787698, 1.4233795533697746] bias = -7.33236254286219 ---->\n",
      "Epoch : 1237   loss = 9.163077073849902  weights = [0.9686584388504372, 1.4438338819471417] bias = -7.307362781365124 ---->\n",
      "Epoch : 1238   loss = 9.372777084971517  weights = [0.2663871808799211, 1.4324702902012065] bias = -7.33236270208057 ---->\n",
      "Epoch : 1239   loss = 0.8907900168565628  weights = [-0.12269770829045967, 1.4280317702448007] bias = -7.343230968143269 ---->\n",
      "Epoch : 1240   loss = 6.076845522674716  weights = [1.0954164309251861, 1.448483571012823] bias = -7.318234093133892 ---->\n",
      "Epoch : 1241   loss = 10.533253942895204  weights = [0.39314384517050904, 1.437119939169462] bias = -7.343234085471874 ---->\n",
      "Epoch : 1242   loss = 2.248829347568383  weights = [-0.24806541753162703, 1.42726267542788] bias = -7.36519191910437 ---->\n",
      "Epoch : 1243   loss = 9.142496167922118  weights = [0.9701117143326754, 1.4477170041533363] bias = -7.340192157433672 ---->\n",
      "Epoch : 1244   loss = 9.373573133064541  weights = [0.26784046183054455, 1.436353412523016] bias = -7.365192077854174 ---->\n",
      "Epoch : 1245   loss = 0.8953093862651376  weights = [-0.12169445611435914, 1.4319109926432598] bias = -7.376075748406768 ---->\n",
      "Epoch : 1246   loss = 6.067237608232208  weights = [1.0964200774207948, 1.4523628139785218] bias = -7.351078849465581 ---->\n",
      "Epoch : 1247   loss = 10.529914230649878  weights = [0.3941474933808008, 1.4409991821842927] bias = -7.37607884171091 ---->\n",
      "Epoch : 1248   loss = 2.2480435826117073  weights = [-0.24661079565509847, 1.4311537518042665] bias = -7.398013929985674 ---->\n",
      "Epoch : 1249   loss = 9.12187548772858  weights = [0.9715663373614378, 1.4516080806663498] bias = -7.373014168154201 ---->\n",
      "Epoch : 1250   loss = 9.374386365386256  weights = [0.2692950902975175, 1.4402444891502055] bias = -7.398014088281409 ---->\n",
      "Epoch : 1251   loss = 0.899844827891446  weights = [-0.12069251631495365, 1.4357980946232431] bias = -7.408913326935042 ---->\n",
      "Epoch : 1252   loss = 6.057654849036672  weights = [1.0974224050935835, 1.4562499362911085] bias = -7.38391640432749 ---->\n",
      "Epoch : 1253   loss = 10.526567490602684  weights = [0.3951498227912308, 1.4448863045465872] bias = -7.40891639647893 ---->\n",
      "Epoch : 1254   loss = 2.2472506146096385  weights = [-0.2451548280023672, 1.43505278919855] bias = -7.43082861016674 ---->\n",
      "Epoch : 1255   loss = 9.101215097659926  weights = [0.9730223058916985, 1.4555071181857988] bias = -7.405828848187346 ---->\n",
      "Epoch : 1256   loss = 9.375216769192598  weights = [0.2707510642354466, 1.4441435267823814] bias = -7.430828768022929 ---->\n",
      "Epoch : 1257   loss = 0.9043963254208333  weights = [-0.11969194074003298, 1.4396930821401945] bias = -7.441743738977042 ---->\n",
      "Epoch : 1258   loss = 6.048098523386719  weights = [1.0984233621735193, 1.4601449439098784] bias = -7.416746792964061 ---->\n",
      "Epoch : 1259   loss = 10.523212578232949  weights = [0.39615078163224504, 1.4487813122156523] bias = -7.441746785020349 ---->\n",
      "Epoch : 1260   loss = 2.246449805441319  weights = [-0.24369751585636834, 1.4389597950555524] bias = -7.463635992614021 ---->\n",
      "Epoch : 1261   loss = 9.080515042410838  weights = [0.9744796186393894, 1.4594141241564982] bias = -7.438636230499563 ---->\n",
      "Epoch : 1262   loss = 9.376064307830639  weights = [0.27220838235987566, 1.4480505328643487] bias = -7.463636150045213 ---->\n",
      "Epoch : 1263   loss = 0.9089638702656586  weights = [-0.11869278026876456, 1.4435959618794962] bias = -7.474567018130994 ---->\n",
      "Epoch : 1264   loss = 6.038569884861276  weights = [1.0994228978560185, 1.4640478435239193] bias = -7.449570048969183 ---->\n",
      "Epoch : 1265   loss = 10.519849440917772  weights = [0.3971503190997484, 1.452684211880588] bias = -7.47457004092903 ---->\n",
      "Epoch : 1266   loss = 2.245640532148519  weights = [-0.24223885975653248, 1.4428747775469466] bias = -7.496436108657929 ---->\n",
      "Epoch : 1267   loss = 9.059775347446292  weights = [0.9759382750637661, 1.4633291067501077] bias = -7.471436346421279 ---->\n",
      "Epoch : 1268   loss = 9.376928971142302  weights = [0.27366704412965104, 1.4519655155677564] bias = -7.4964362656787085 ---->\n",
      "Epoch : 1269   loss = 0.9135474614152131  weights = [-0.1176950848285474, 1.4475067412387845] bias = -7.5073831964010935 ---->\n",
      "Epoch : 1270   loss = 6.029070162765654  weights = [1.1004209622852472, 1.4679586425344322] bias = -7.48238620434288 ---->\n",
      "Epoch : 1271   loss = 10.516477744506723  weights = [0.3981483853384047, 1.4565950109426073] bias = -7.507386196204971 ---->\n",
      "Epoch : 1272   loss = 2.244822186724733  weights = [-0.2407788595157242, 1.4467977455533463] bias = -7.529228988049659 ---->\n",
      "Epoch : 1273   loss = 9.03899601945  weights = [0.9773982753504676, 1.4672520748472215] bias = -7.504229225703706 ---->\n",
      "Epoch : 1274   loss = 9.377810748319147  weights = [0.27512704972998214, 1.455888483773187] bias = -7.529229144674652 ---->\n",
      "Epoch : 1275   loss = 0.9181471052921719  weights = [-0.116698903412506, 1.4514254283106567] bias = -7.5401923042529635 ---->\n",
      "Epoch : 1276   loss = 6.019600562592431  weights = [1.1014175065367722, 1.4718773490374446] bias = -7.515195289546764 ---->\n",
      "Epoch : 1277   loss = 10.513096248465892  weights = [0.3991449314242881, 1.46051371749775] bias = -7.540195281309755 ---->\n",
      "Epoch : 1278   loss = 2.2439941757011246  weights = [-0.23931751423646652, 1.4507287086468137] bias = -7.562014659016696 ---->\n",
      "Epoch : 1279   loss = 9.018177046754584  weights = [0.9788596203952902, 1.4711830380198756] bias = -7.537014896574357 ---->\n",
      "Epoch : 1280   loss = 9.378709647676388  weights = [0.2765884000562149, 1.4598194470526644] bias = -7.56201481526058 ---->\n",
      "Epoch : 1281   loss = 0.9227628156150555  weights = [-0.11570428409755362, 1.4553520318657538] bias = -7.5729943706678755 ---->\n",
      "Epoch : 1282   loss = 6.010162266495451  weights = [1.102412482599644, 1.4758039718068976] bias = -7.5479973335582455 ---->\n",
      "Epoch : 1283   loss = 10.509705427231767  weights = [0.40013990934696697, 1.4644403403199697] bias = -7.572997325220766 ---->\n",
      "Epoch : 1284   loss = 2.243155920023018  weights = [-0.2378548223264395, 1.4546676770737617] bias = -7.594793148317037 ---->\n",
      "Epoch : 1285   loss = 8.997318399753299  weights = [0.9803223117886865, 1.47512200651445] bias = -7.569793385791263 ---->\n",
      "Epoch : 1286   loss = 9.379625649132066  weights = [0.2780510966983316, 1.4637584156525567] bias = -7.594793304194551 ---->\n",
      "Epoch : 1287   loss = 0.9273946132674683  weights = [-0.11471127406296294, 1.4592865613361865] bias = -7.605789423195752 ---->\n",
      "Epoch : 1288   loss = 6.000756433775416  weights = [1.103405843357969, 1.4797385202780786] bias = -7.580792363923534 ---->\n",
      "Epoch : 1289   loss = 10.506304562608898  weights = [0.4011332719910755, 1.4683748888445662] bias = -7.6057923554841835 ---->\n",
      "Epoch : 1290   loss = 2.2423068546997715  weights = [-0.23639078151324222, 1.4586146617382245] bias = -7.627564481292133 ---->\n",
      "Epoch : 1291   loss = 8.976420031292996  weights = [0.9817863518010024, 1.4790689912349397] bias = -7.602564718695914 ---->\n",
      "Epoch : 1292   loss = 9.380558796343601  weights = [0.27951514192618787, 1.4677054004768457] bias = -7.6275646368180805 ---->\n",
      "Epoch : 1293   loss = 0.9320425261738358  weights = [-0.11371991960938288, 1.4632290267992871] bias = -7.638577488006976 ---->\n",
      "Epoch : 1294   loss = 5.991384201375639  weights = [1.1043975425720332, 1.483681004531378] bias = -7.613580406809439 ---->\n",
      "Epoch : 1295   loss = 10.502892822000307  weights = [0.40212497311743767, 1.4723173731519432] bias = -7.638580398266791 ---->\n",
      "Epoch : 1296   loss = 2.241446428530137  weights = [-0.23492538885839154, 1.462569674185471] bias = -7.660328681918583 ---->\n",
      "Epoch : 1297   loss = 8.955481877047735  weights = [0.9832517433684742, 1.4830240037265678] bias = -7.635328919264959 ---->\n",
      "Epoch : 1298   loss = 9.381509089964181  weights = [0.2809805386755089, 1.471660413070741] bias = -7.660328837107843 ---->\n",
      "Epoch : 1299   loss = 0.9367065891818861  weights = [-0.11273026617827031, 1.4671794389616575] bias = -7.671358589943019 ---->\n",
      "Epoch : 1300   loss = 5.982046684387205  weights = [1.1053875348590094, 1.4876314352763422] bias = -7.646361487053994 ---->\n",
      "Epoch : 1301   loss = 10.49946992271242  weights = [0.4031149673437756, 1.4762678039516601] bias = -7.67136147840659 ---->\n",
      "Epoch : 1302   loss = 2.2405741037735583  weights = [-0.23345864077056855, 1.4665327265859354] bias = -7.693085772858578 ---->\n",
      "Epoch : 1303   loss = 8.934503855873311  weights = [0.9847184900799799, 1.486987056159716] bias = -7.668086010160643 ---->\n",
      "Epoch : 1304   loss = 9.382476560545616  weights = [0.28244729053464357, 1.47562346560461] bias = -7.693085927726116 ---->\n",
      "Epoch : 1305   loss = 0.9413868439522024  weights = [-0.1117423583716744, 1.471137809143493] bias = -7.704132752565907 ---->\n",
      "Epoch : 1306   loss = 5.972744976561987  weights = [1.1063757756733092, 1.4915898238360028] bias = -7.679135628215915 ---->\n",
      "Epoch : 1307   loss = 10.49603595056151  weights = [0.40410321012506034, 1.4802261925667617] bias = -7.704135619462267 ---->\n",
      "Epoch : 1308   loss = 2.2396893559331947  weights = [-0.23199053301808603, 1.4705038317194394] bias = -7.725835775509152 ---->\n",
      "Epoch : 1309   loss = 8.913485870142091  weights = [0.9861865961645708, 1.4909581613141474] bias = -7.700836012780062 ---->\n",
      "Epoch : 1310   loss = 9.383461244875944  weights = [0.28391540173209306, 1.4795945708582021] bias = -7.725835930070024 ---->\n",
      "Epoch : 1311   loss = 0.9460833388543864  weights = [-0.11075623997233974, 1.475104149263156] bias = -7.736899998206546 ---->\n",
      "Epoch : 1312   loss = 5.96348015083282  weights = [1.1073622212866137, 1.4955561821314554] bias = -7.71190285262292 ---->\n",
      "Epoch : 1313   loss = 10.492590147046409  weights = [0.40508965773354433, 1.4841925509183573] bias = -7.736902843761509 ---->\n",
      "Epoch : 1314   loss = 2.2387916733455806  weights = [-0.23052106074057788, 1.4744830029596863] bias = -7.758578710050222 ---->\n",
      "Epoch : 1315   loss = 8.892427806058175  weights = [0.9876560664797736, 1.4949373325634994] bias = -7.7335789473032035 ---->\n",
      "Epoch : 1316   loss = 9.384463185037456  weights = [0.28538487712481553, 1.4835737422051394] bias = -7.758578864319583 ---->\n",
      "Epoch : 1317   loss = 0.950796128870563  weights = [-0.10977195396408623, 1.4790784718219767] bias = -7.7696603480119295 ---->\n",
      "Epoch : 1318   loss = 5.954253259839718  weights = [1.1083468287676275, 1.4995305226666646] bias = -7.744663181418931 ---->\n",
      "Epoch : 1319   loss = 10.489131809377017  weights = [0.4060742672385148, 1.4881668915104256] bias = -7.769663172448206 ---->\n",
      "Epoch : 1320   loss = 2.2378805570080713  weights = [-0.22905021845989915, 1.478470254258993] bias = -7.791314595491468 ---->\n",
      "Epoch : 1321   loss = 8.871329533952638  weights = [0.9891269065006906, 1.498924583860017] bias = -7.766314832739824 ---->\n",
      "Epoch : 1322   loss = 9.385482412586127  weights = [0.286855722187325, 1.4875609935976513] bias = -7.7913147494845845 ---->\n",
      "Epoch : 1323   loss = 0.9555252755059258  weights = [-0.10878954255245449, 1.4830607898892563] bias = -7.802413821991252 ---->\n",
      "Epoch : 1324   loss = 5.945065336461971  weights = [1.109329555961561, 1.5035128585134732] bias = -7.777416634610183 ---->\n",
      "Epoch : 1325   loss = 10.485661042006736  weights = [0.4070569964857763, 1.4921492274148227] bias = -7.802416625528564 ---->\n",
      "Epoch : 1326   loss = 2.236955520223214  weights = [-0.22757800009022866, 1.4824656001332446] bias = -7.824043449718075 ---->\n",
      "Epoch : 1327   loss = 8.85019090855871  weights = [0.9905991223098906, 1.5029199297195062] bias = -7.7990436869751925 ---->\n",
      "Epoch : 1328   loss = 9.386518992267218  weights = [0.2883279430015835, 1.491556339551528] bias = -7.8240436034503285 ---->\n",
      "Epoch : 1329   loss = 0.9602708467063903  weights = [-0.10780904718556766, 1.4870511170874494] bias = -7.835160439060949 ---->\n",
      "Epoch : 1330   loss = 5.935917394354866  weights = [1.1103103614693997, 1.5075032032967877] bias = -7.810163231110257 ---->\n",
      "Epoch : 1331   loss = 10.48217712824242  weights = [0.40803780407692103, 1.4961395722564703] bias = -7.83516322191613 ---->\n",
      "Epoch : 1332   loss = 2.2360160882775615  weights = [-0.22610439894737233, 1.486469055647045] bias = -7.856765289535332 ---->\n",
      "Epoch : 1333   loss = 8.829011769266804  weights = [0.9920727205881017, 1.5069233852064852] bias = -7.8317655268146895 ---->\n",
      "Epoch : 1334   loss = 9.387572982966217  weights = [0.28980154624769283, 1.4955597951312718] bias = -7.856765443022231 ---->\n",
      "Epoch : 1335   loss = 0.9650329167837554  weights = [-0.10683050857520088, 1.4910494675775066] bias = -7.8679002170886765 ---->\n",
      "Epoch : 1336   loss = 5.926810428490921  weights = [1.1112892046269593, 1.5115015711799262] bias = -7.84290298878406 ---->\n",
      "Epoch : 1337   loss = 10.478679785831153  weights = [0.4090166493483832, 1.5001379401987007] bias = -7.867902979475774 ---->\n",
      "Epoch : 1338   loss = 2.2350617981185374  weights = [-0.22462940775725382, 1.4904806363990368] bias = -7.889480130712156 ---->\n",
      "Epoch : 1339   loss = 8.80779194035915  weights = [0.9935477086057135, 1.5109349659195037] bias = -7.864480368027332 ---->\n",
      "Epoch : 1340   loss = 9.388644443622175  weights = [0.29127653919539864, 1.4995713759354155] bias = -7.889480283969342 ---->\n",
      "Epoch : 1341   loss = 0.9698115663480729  weights = [-0.10585396671803216, 1.4950558560443459] bias = -7.900633172936286 ---->\n",
      "Epoch : 1342   loss = 5.917745415704945  weights = [1.1122660454837603, 1.515507976850095] bias = -7.875635924490783 ---->\n",
      "Epoch : 1343   loss = 10.475168711678696  weights = [0.40999349235031524, 1.504144345928735] bias = -7.900635915066659 ---->\n",
      "Epoch : 1344   loss = 2.2340921981223683  weights = [-0.22315301866359105, 1.4945003585073728] bias = -7.922187988023536 ---->\n",
      "Epoch : 1345   loss = 8.786531231223986  weights = [0.9950240942150981, 1.5149546879766154] bias = -7.897188225388216 ---->\n",
      "Epoch : 1346   loss = 9.389733427202303  weights = [0.2927529296964084, 1.503591098081995] bias = -7.922188141066795 ---->\n",
      "Epoch : 1347   loss = 0.9746068822475789  weights = [-0.10487946091706946, 1.499070297682441] bias = -7.933359322501779 ---->\n",
      "Epoch : 1348   loss = 5.90872331524286  weights = [1.1132408447817248, 1.51952243550398] bias = -7.908362054125865 ---->\n",
      "Epoch : 1349   loss = 10.471643684814723  weights = [0.41096829382528344, 1.5081588046432743] bias = -7.933362044584186 ---->\n",
      "Epoch : 1350   loss = 2.2331068477724982  weights = [-0.22167522323475253, 1.4985282385953145] bias = -7.954888875291924 ---->\n",
      "Epoch : 1351   loss = 8.765229436549198  weights = [0.9965018858437433, 1.5189825680009745] bias = -7.929889112719907 ---->\n",
      "Epoch : 1352   loss = 9.390840044253812  weights = [0.29423072617752954, 1.5076189781941478] bias = -7.954889028137192 ---->\n",
      "Epoch : 1353   loss = 0.9794189575161627  weights = [-0.10390702980322902, 1.5030928081814978] bias = -7.966078680760293 ---->\n",
      "Epoch : 1354   loss = 5.899745069313679  weights = [1.1142135639337185, 1.5235449628334279] bias = -7.9410813926619594 ---->\n",
      "Epoch : 1355   loss = 10.468104024052165  weights = [0.4119410151868117, 1.5121813320341804] bias = -7.966081383000972 ---->\n",
      "Epoch : 1356   loss = 2.2321053173235774  weights = [-0.2201960124697805, 1.5025642937769323] bias = -7.987582805427604 ---->\n",
      "Epoch : 1357   loss = 8.743886336495116  weights = [0.9979810924882272, 1.523018623106538] bias = -7.962583042932813 ---->\n",
      "Epoch : 1358   loss = 9.391964344447079  weights = [0.2957099376346387, 1.5116550333858123] bias = -7.987582958090977 ---->\n",
      "Epoch : 1359   loss = 0.9842478913283018  weights = [-0.1029367113570725, 1.5071234037121974] bias = -7.998791261804125 ---->\n",
      "Epoch : 1360   loss = 5.890811603644849  weights = [1.1151841650019332, 1.527575575011194] bias = -7.973793954188967 ---->\n",
      "Epoch : 1361   loss = 10.464549441551883  weights = [0.4129116184977629, 1.5162119442742246] bias = -7.998793944406884 ---->\n",
      "Epoch : 1362   loss = 2.2310871874923413  weights = [-0.218715376803584, 1.5066085416428936] bias = -8.02026979046807 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1363   loss = 8.722501696846507  weights = [0.9994617237090141, 1.5270628708838514] bias = -7.995270028064557 ---->\n",
      "Epoch : 1364   loss = 9.393106436207733  weights = [0.29719057362748214, 1.5156992812475156] bias = -8.020269942965815 ---->\n",
      "Epoch : 1365   loss = 0.989093788962013  weights = [-0.10196854293067875, 1.5111621009119902] bias = -8.031497078881845 ---->\n",
      "Epoch : 1366   loss = 5.881923828040405  weights = [1.1161526106761346, 1.5316142886767394] bias = -8.006499751953134 ---->\n",
      "Epoch : 1367   loss = 10.460979705785176  weights = [0.4138800664485893, 1.520250658002884] bias = -8.031499742048132 ---->\n",
      "Epoch : 1368   loss = 2.230052049186318  weights = [-0.21723330611128477, 1.5106610002463072] bias = -8.052949841616424 ---->\n",
      "Epoch : 1369   loss = 8.70107526914349  weights = [1.0009437896261029, 1.5311153293858948] bias = -8.02795007931838 ---->\n",
      "Epoch : 1370   loss = 9.394266414260938  weights = [0.29867264427532114, 1.5197517398322191] bias = -8.052949993964983 ---->\n",
      "Epoch : 1371   loss = 0.9939567617694235  weights = [-0.10100256126966661, 1.5152089168709126] bias = -8.064196144436483 ---->\n",
      "Epoch : 1372   loss = 5.8730826369423275  weights = [1.1171188642517542, 1.5356611209220528] bias = -8.039198798395239 ---->\n",
      "Epoch : 1373   loss = 10.457394546477714  weights = [0.4148463223354222, 1.5242974903121633] bias = -8.064198788365454 ---->\n",
      "Epoch : 1374   loss = 2.2289995031888266  weights = [-0.2157497897117141, 1.5147216880886136] bias = -8.085622969278813 ---->\n",
      "Epoch : 1375   loss = 8.679606790791187  weights = [1.0024273009155213, 1.5351760171139721] bias = -8.060623207100576 ---->\n",
      "Epoch : 1376   loss = 9.395444344434967  weights = [0.30015616025342906, 1.5238124276412075] bias = -8.085623121494821 ---->\n",
      "Epoch : 1377   loss = 0.9988369271552898  weights = [-0.10003880253536296, 1.5192638691174143] bias = -8.096888470142856 ---->\n",
      "Epoch : 1378   loss = 5.864288909995002  weights = [1.118082889607841, 1.5397160892774806] bias = -8.071891105187914 ---->\n",
      "Epoch : 1379   loss = 10.453793744603958  weights = [0.4158103500380256, 1.5283524587324255] bias = -8.096891095031445 ---->\n",
      "Epoch : 1380   loss = 2.2279291598217643  weights = [-0.21426481637005368, 1.5187906241054958] bias = -8.118289183100963 ---->\n",
      "Epoch : 1381   loss = 8.658095985148142  weights = [1.0039122688066757, 1.5392449530036216] bias = -8.093289421057028 ---->\n",
      "Epoch : 1382   loss = 9.396640359831396  weights = [0.30164113279043825, 1.5278813636099993] bias = -8.118289335201249 ---->\n",
      "Epoch : 1383   loss = 1.003734408563372  weights = [-0.09907730232710144, 1.5233269756041676] bias = -8.129574066944015 ---->\n",
      "Epoch : 1384   loss = 5.855543512612448  weights = [1.119044651184871, 1.5437792116975413] bias = -8.104576683272091 ---->\n",
      "Epoch : 1385   loss = 10.45017628473771  weights = [0.41677211399760583, 1.532415581218206] bias = -8.129576672986998 ---->\n",
      "Epoch : 1386   loss = 2.2268406387140476  weights = [-0.21277837429960422, 1.5228678276527898] bias = -8.150948492003788 ---->\n",
      "Epoch : 1387   loss = 8.636542561592941  weights = [1.0053987050805744, 1.543322156410527] bias = -8.125948730108814 ---->\n",
      "Epoch : 1388   loss = 9.397854573368404  weights = [0.3031275736665655, 1.5319585670942582] bias = -8.15094864400539 ---->\n",
      "Epoch : 1389   loss = 1.0086493354713886  weights = [-0.09811809570469376, 1.527398254693848] bias = -8.162252945086891 ---->\n",
      "Epoch : 1390   loss = 5.846847296549353  weights = [1.1200041139623953, 1.5478505065467085] bias = -8.137255542892637 ---->\n",
      "Epoch : 1391   loss = 10.446542723873394  weights = [0.41773157919446013, 1.5364868761339956] bias = -8.16225553247694 ---->\n",
      "Epoch : 1392   loss = 2.2257335683496993  weights = [-0.2112904511626812, 1.5269533184923814] bias = -8.183600904218137 ---->\n",
      "Epoch : 1393   loss = 8.614946215569212  weights = [1.0068866220689183, 1.547407647096413] bias = -8.158601142486955 ---->\n",
      "Epoch : 1394   loss = 9.399087077835828  weights = [0.30461549521270204, 1.5360440578556882] bias = -8.18360105613831 ---->\n",
      "Epoch : 1395   loss = 1.0135818433937986  weights = [-0.09716121721103965, 1.5314777251448597] bias = -8.194925114157105 ---->\n",
      "Epoch : 1396   loss = 5.838201100475083  weights = [1.1209612434365372, 1.5519299925851409] bias = -8.169927693633163 ---->\n",
      "Epoch : 1397   loss = 10.44289202647313  weights = [0.41868871112547423, 1.5405663622399703] bias = -8.19492768308484 ---->\n",
      "Epoch : 1398   loss = 2.2246075859874073  weights = [-0.20980103407062223, 1.5310471167780633] bias = -8.216246427318662 ---->\n",
      "Epoch : 1399   loss = 8.593306628608524  weights = [1.008376032654086, 1.5515014452149032] bias = -8.191246665766286 ---->\n",
      "Epoch : 1400   loss = 9.400337991806008  weights = [0.306104910310398, 1.5401378560478922] bias = -8.216246579174886 ---->\n",
      "Epoch : 1401   loss = 1.0185320738932078  weights = [-0.09620670089491817, 1.5355654060969923] bias = -8.227590583113003 ---->\n",
      "Epoch : 1402   loss = 5.829605750551774  weights = [1.1219160055973139, 1.556017688954343] bias = -8.202593144450057 ---->\n",
      "Epoch : 1403   loss = 10.439224418449202  weights = [0.41964347578144334, 1.544654058677653] bias = -8.227593133767046 ---->\n",
      "Epoch : 1404   loss = 2.223462337110322  weights = [-0.2083101095828921, 1.5351492430413434] bias = -8.248885068256884 ---->\n",
      "Epoch : 1405   loss = 8.57162346833091  weights = [1.009866950270016, 1.5556035712973268] bias = -8.223885306898522 ---->\n",
      "Epoch : 1406   loss = 9.401607472281793  weights = [0.3075958323927457, 1.5442399822021786] bias = -8.24888522006688 ---->\n",
      "Epoch : 1407   loss = 1.0235001746001484  weights = [-0.09525458033395862, 1.5396613170569897] bias = -8.260249360318937 ---->\n",
      "Epoch : 1408   loss = 5.821062061016446  weights = [1.1228683669057753, 1.5601136151627364] bias = -8.235251903705763 ---->\n",
      "Epoch : 1409   loss = 10.435539593838941  weights = [0.42059583962421376, 1.5487499849554829] bias = -8.260251892885957 ---->\n",
      "Epoch : 1410   loss = 2.2222974753200497  weights = [-0.20681766370528398, 1.5392597181771779] bias = -8.281516833393418 ---->\n",
      "Epoch : 1411   loss = 8.549896388423015  weights = [1.0113593889039918, 1.559714046238453] bias = -8.256517072244478 ---->\n",
      "Epoch : 1412   loss = 9.402895606338435  weights = [0.3090882754461648, 1.5483504572132945] bias = -8.281516985175154 ---->\n",
      "Epoch : 1413   loss = 1.0284862992416572  weights = [-0.09430488865779396, 1.5437654778840113] bias = -8.292901453577798 ---->\n",
      "Epoch : 1414   loss = 5.81257083476724  weights = [1.1238182942709602, 1.5642177910711257] bias = -8.267903979201295 ---->\n",
      "Epoch : 1415   loss = 10.431836673800928  weights = [0.4215457695636373, 1.5528541609342834] bias = -8.292903968242545 ---->\n",
      "Epoch : 1416   loss = 2.221112661871719  weights = [-0.20532368188718841, 1.5433785634296193] bias = -8.314141728529417 ---->\n",
      "Epoch : 1417   loss = 8.52812502859316  weights = [1.012853363099361, 1.563832891282137] bias = -8.28914196760552 ---->\n",
      "Epoch : 1418   loss = 9.40420256148926  weights = [0.31058225401311934, 1.5524693023250735] bias = -8.314141880301122 ---->\n",
      "Epoch : 1419   loss = 1.0334906076787616  weights = [-0.09335765857143491, 1.5478779087749717] bias = -8.32554687016283 ---->\n",
      "Epoch : 1420   loss = 5.804132863954724  weights = [1.1247657550266297, 1.5683302368780412] bias = -8.300549378208068 ---->\n",
      "Epoch : 1421   loss = 10.428115786956651  weights = [0.4224932329343061, 1.5569666068126038] bias = -8.325549367108179 ---->\n",
      "Epoch : 1422   loss = 2.2199075654522926  weights = [-0.20382814901793145, 1.5475058003773599] bias = -8.346759758937264 ---->\n",
      "Epoch : 1423   loss = 8.50630901450337  weights = [1.0143488879591829, 1.5679601280068651] bias = -8.321759998254253 ---->\n",
      "Epoch : 1424   loss = 9.405528478242065  weights = [0.31207778319576707, 1.5565965391159795] bias = -8.346759910717434 ---->\n",
      "Epoch : 1425   loss = 1.0385132659529115  weights = [-0.09241292237886084, 1.5519986302497415] bias = -8.358185616848756 ---->\n",
      "Epoch : 1426   loss = 5.795748930578184  weights = [1.1257107169077827, 1.5724509731049425] bias = -8.333188107499007 ---->\n",
      "Epoch : 1427   loss = 10.424376393009204  weights = [0.4234381974720691, 1.561087343111923] bias = -8.358188096255741 ---->\n",
      "Epoch : 1428   loss = 2.2186818618915343  weights = [-0.20233104942214974, 1.5516414509191552] bias = -8.379370929390477 ---->\n",
      "Epoch : 1429   loss = 8.484447957677649  weights = [1.0158459791508372, 1.5720957783111766] bias = -8.354371168964432 ---->\n",
      "Epoch : 1430   loss = 9.40687348816381  weights = [0.31357487866056855, 1.560732189484529] bias = -8.3793710811979 ---->\n",
      "Epoch : 1431   loss = 1.0435544463414514  weights = [-0.09147071200686552, 1.5561276631361913] bias = -8.390817699942232 ---->\n",
      "Epoch : 1432   loss = 5.787419807087871  weights = [1.1266531480269193, 1.5765800205812668] bias = -8.365820173378998 ---->\n",
      "Epoch : 1433   loss = 10.42061867137926  weights = [0.4243806312902957, 1.5652163906616976] bias = -8.390820161990066 ---->\n",
      "Epoch : 1434   loss = 2.2174352337674708  weights = [-0.20083236685420502, 1.555785537259113] bias = -8.41197524419293 ---->\n",
      "Epoch : 1435   loss = 8.4625414553865  weights = [1.0173446529115937, 1.576239864398952] bias = -8.386975484040171 ---->\n",
      "Epoch : 1436   loss = 9.40823775657172  weights = [0.3150735566438546, 1.564876275634579] bias = -8.411975396046683 ---->\n",
      "Epoch : 1437   loss = 1.0486143274230366  weights = [-0.09053105902914754, 1.5602650285550639] bias = -8.423443125311634 ---->\n",
      "Epoch : 1438   loss = 5.779146256992941  weights = [1.127593016850056, 1.5807174004293036] bias = -8.398445581714677 ---->\n",
      "Epoch : 1439   loss = 10.416842026667874  weights = [0.4253205028558904, 1.5693537705842375] bias = -8.423445570177746 ---->\n",
      "Epoch : 1440   loss = 2.2161673701265134  weights = [-0.19933208449160078, 1.5599380818918318] bias = -8.444572707207334 ---->\n",
      "Epoch : 1441   loss = 8.440589090506883  weights = [1.018844926055181, 1.5803924087645527] bias = -8.41957294734444 ---->\n",
      "Epoch : 1442   loss = 9.409621426250519  weights = [0.31657383395839656, 1.5690288200604685] bias = -8.444572859126803 ---->\n",
      "Epoch : 1443   loss = 1.0536930941520815  weights = [-0.08959399469070783, 1.5644107479046627] bias = -8.456061898416234 ---->\n",
      "Epoch : 1444   loss = 5.770929035476634  weights = [1.1285302921724325, 1.584863134048887] bias = -8.4310643379636 ---->\n",
      "Epoch : 1445   loss = 10.413045952905854  weights = [0.4262577809650019, 1.573499504279397] bias = -8.456064326276286 ---->\n",
      "Epoch : 1446   loss = 2.214877966272609  weights = [-0.1978301849273968, 1.564099107587379] bias = -8.477163321883031 ---->\n",
      "Epoch : 1447   loss = 8.418590431357448  weights = [1.0203468159793512, 1.5845534341777967] bias = -8.452163562326849 ---->\n",
      "Epoch : 1448   loss = 9.411024673848855  weights = [0.31807572800097017, 1.5731898455319913] bias = -8.477163473887924 ---->\n",
      "Epoch : 1449   loss = 1.058790937943514  weights = [-0.08865954993253339, 1.568564842845337] bias = -8.488674024334754 ---->\n",
      "Epoch : 1450   loss = 5.7627688900182275  weights = [1.1294649430939343, 1.5890172431018832] bias = -8.463676447202786 ---->\n",
      "Epoch : 1451   loss = 10.40923059838858  weights = [0.4271924347184456, 1.5776536134090637] bias = -8.488676435362656 ---->\n",
      "Epoch : 1452   loss = 2.2135667232271348  weights = [-0.19632665016158912, 1.5682686373760866] bias = -8.509747091283142 ---->\n",
      "Epoch : 1453   loss = 8.396545031508326  weights = [1.021850340674479, 1.5887229636687563] bias = -8.484747332050798 ---->\n",
      "Epoch : 1454   loss = 9.412447662551784  weights = [0.3195792567609548, 1.577359375079195] bias = -8.509747243393498 ---->\n",
      "Epoch : 1455   loss = 1.063908056767451  weights = [-0.08772775541662031, 1.5727273352837512] bias = -8.521279507793329 ---->\n",
      "Epoch : 1456   loss = 5.7546665610230185  weights = [1.1303969389941753, 1.5931797494964641] bias = -8.496281914156691 ---->\n",
      "Epoch : 1457   loss = 10.405395435811414  weights = [0.42812443349678575, 1.5818161198814307] bias = -8.521281902161261 ---->\n",
      "Epoch : 1458   loss = 2.212233347670051  weights = [-0.19482146159144464, 1.5724466945331614] bias = -8.542324018111026 ---->\n",
      "Epoch : 1459   loss = 8.374452429565169  weights = [1.0233555187332124, 1.5929010205123655] bias = -8.517324259219944 ---->\n",
      "Epoch : 1460   loss = 9.413890567236157  weights = [0.3210844388299834, 1.5815374319769895] bias = -8.54232417034724 ---->\n",
      "Epoch : 1461   loss = 1.0690446552544604  weights = [-0.08679864155135353, 1.576898247356928] bias = -8.553878353192905 ---->\n",
      "Epoch : 1462   loss = 5.746622782460833  weights = [1.131326249507222, 1.5973506753711524] bias = -8.52888074322459 ---->\n",
      "Epoch : 1463   loss = 10.401540265030333  weights = [0.4290537469350627, 1.585987045835042] bias = -8.553880731071322 ---->\n",
      "Epoch : 1464   loss = 2.2108775513734216  weights = [-0.19331460000075518, 1.5766333025630899] bias = -8.574894104736135 ---->\n",
      "Epoch : 1465   loss = 8.352312148926677  weights = [1.0248623693611907, 1.5970876282128257] bias = -8.549894346204043 ---->\n",
      "Epoch : 1466   loss = 9.415353578699191  weights = [0.3225912934126609, 1.5857240397295513] bias = -8.57489425711896 ---->\n",
      "Epoch : 1467   loss = 1.0742009448113257  weights = [-0.0858722385172545, 1.581077601416045] bias = -8.586470564636082 ---->\n",
      "Epoch : 1468   loss = 5.738638282513314  weights = [1.1322528444959505, 1.6015300430786221] bias = -8.561472938507421 ---->\n",
      "Epoch : 1469   loss = 10.397664965440931  weights = [0.4299803448971482, 1.5901664136225944] bias = -8.586472926193727 ---->\n",
      "Epoch : 1470   loss = 2.209499051095195  weights = [-0.19180604554799385, 1.5808284851838295] bias = -8.607457353219228 ---->\n",
      "Epoch : 1471   loss = 8.330123697515118  weights = [1.0263709123888693, 1.6012828104877963] bias = -8.582457595064177 ---->\n",
      "Epoch : 1472   loss = 9.416836880101858  weights = [0.32409984033838835, 1.5899192220545146] bias = -8.607457505769794 ---->\n",
      "Epoch : 1473   loss = 1.079377143747952  weights = [-0.08494857629314534, 1.5852654200099798] bias = -8.619056145953413 ---->\n",
      "Epoch : 1474   loss = 5.730713784231177  weights = [1.1331766940259866, 1.6057178751692462] bias = -8.594058503834082 ---->\n",
      "Epoch : 1475   loss = 10.393768647634998  weights = [0.43090419744968755, 1.5943542457944835] bias = -8.619058491357315 ---->\n",
      "Epoch : 1476   loss = 2.208097568100993  weights = [-0.1902957777533425, 1.585032266310773] bias = -8.640013765336995 ---->\n",
      "Epoch : 1477   loss = 8.307886567479143  weights = [1.0278811682844644, 1.6054865912523584] bias = -8.615014007577372 ---->\n",
      "Epoch : 1478   loss = 9.418340642228697  weights = [0.3256101000743069, 1.5941230028669346] bias = -8.64001391807683 ---->\n",
      "Epoch : 1479   loss = 1.0845734774152427  weights = [-0.08402768468273247, 1.5894617258685835] bias = -8.651635100729216 ---->\n",
      "Epoch : 1480   loss = 5.722850006201582  weights = [1.1340977683392284, 1.6099141943743729] bias = -8.626637442787235 ---->\n",
      "Epoch : 1481   loss = 10.38985186692382  weights = [0.4318252748356217, 1.5985505650820808] bias = -8.651637430144694 ---->\n",
      "Epoch : 1482   loss = 2.2066728279638745  weights = [-0.18878377548456393, 1.5892446700404739] bias = -8.672563342606093 ---->\n",
      "Epoch : 1483   loss = 8.28560023486829  weights = [1.0293931581680575, 1.6096989946027391] bias = -8.647563585260636 ---->\n",
      "Epoch : 1484   loss = 9.4198650933984  weights = [0.3271220937394036, 1.5983354062630126] bias = -8.672563495557135 ---->\n",
      "Epoch : 1485   loss = 1.0897901783552006  weights = [-0.0831095933416594, 1.5936665418856752] bias = -8.684207432326856 ---->\n",
      "Epoch : 1486   loss = 5.715047663226758  weights = [1.1350160378268952, 1.614119023589324] bias = -8.659209758728592 ---->\n",
      "Epoch : 1487   loss = 10.38591371500317  weights = [0.43274354744723975, 1.6027553943807318] bias = -8.68420974591752 ---->\n",
      "Epoch : 1488   loss = 2.2052245600498073  weights = [-0.1872700169416862, 1.5934657206341256] bias = -8.705106086306612 ---->\n",
      "Epoch : 1489   loss = 8.263264159278341  weights = [1.0309069038268803, 1.613920044799791] bias = -8.680106329394427 ---->\n",
      "Epoch : 1490   loss = 9.421410431020492  weights = [0.3286358431197941, 1.6025564565035748] bias = -8.705106239491224 ---->\n",
      "Epoch : 1491   loss = 1.0950274864629206  weights = [-0.08219433180503144, 1.5978798911017447] bias = -8.716773143913572 ---->\n",
      "Epoch : 1492   loss = 5.707307467014033  weights = [1.1359314730021088, 1.6183323858560994] bias = -8.691775454823734 ---->\n",
      "Epoch : 1493   loss = 10.381954436621006  weights = [0.43365898579875717, 1.6069687567324606] bias = -8.716775441841314 ---->\n",
      "Epoch : 1494   loss = 2.2037524973875318  weights = [-0.1857544796404681, 1.5976954425007812] bias = -8.737641997504983 ---->\n",
      "Epoch : 1495   loss = 8.240877783466793  weights = [1.032422427731822, 1.6181497662522104] bias = -8.712642241045561 ---->\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1496   loss = 9.422976843573586  weights = [0.33015137068523015, 1.6067861779972905] bias = -8.737642150945979 ---->\n",
      "Epoch : 1497   loss = 1.1002856491600808  weights = [-0.0812819295154652, 1.6021017966863507] bias = -8.749332238484847 ---->\n",
      "Epoch : 1498   loss = 5.699630126878541  weights = [1.1368440444719488, 1.622554304345779] bias = -8.724334534066474 ---->\n",
      "Epoch : 1499   loss = 10.377973492782148  weights = [0.4345715604983742, 1.6111906753083722] bias = -8.749334520909827 ---->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.4345715604983742, 1.6111906753083722], -8.749334520909827)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train, y_train, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c7608",
   "metadata": {},
   "source": [
    "# Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9934243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y,_y):\n",
    "    y = list(y)\n",
    "    _y = [1 if i>0.5 else 0 for i in _y]\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == _y[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return count/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b2f43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation for ANN model's prediction:\n",
    "y_pred = model.predict(X_test)\n",
    "evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2f8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation for our hand written Gradient Descent algo\n",
    "y_pred = prediction(X_test,[5.868356261585161, 2.673946264110486],-4.467408155959375)\n",
    "evaluation(y_test,model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
